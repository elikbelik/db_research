{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Search for Interesting Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this project is to find an interesting db, that gives much better results on deep networks than on shallow ones, but that is not too \"expensive\" to use like imagenet, for example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Autocomplete\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, time, glob\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras import models, layers\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import InputLayer, Dense, Conv2D, BatchNormalization, MaxPooling2D, Activation, Flatten, Dropout, Dense\n",
    "from keras.initializers import glorot_normal, RandomNormal\n",
    "from keras.callbacks import EarlyStopping\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding project's file\n",
    "import metric as M\n",
    "from visualization import visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (10000, 28, 28, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1)\n",
    "test_images = test_images.reshape(test_images.shape[0], 28, 28, 1)\n",
    "\n",
    "train_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_norm = train_images.astype(\"float32\") / 255.0\n",
    "test_images_norm = test_images.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((60000, 32, 32, 1), (10000, 32, 32, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images_pad = np.zeros((train_images_norm.shape[0], 32, 32, 1), dtype=train_images_norm.dtype)\n",
    "test_images_pad = np.zeros((test_images_norm.shape[0], 32, 32, 1), dtype=test_images_norm.dtype)\n",
    "train_images_pad[:,2:30, 2:30, :] = train_images_norm\n",
    "test_images_pad[:,2:30, 2:30, :] = test_images_norm\n",
    "\n",
    "train_images_pad.shape, test_images_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fmnist():\n",
    "    fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "    (train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "    \n",
    "    train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\n",
    "    test_images = test_images.reshape(test_images.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\n",
    "    \n",
    "    train_images_pad = np.zeros((train_images.shape[0], 32, 32, 1), dtype=train_images.dtype)\n",
    "    test_images_pad = np.zeros((test_images.shape[0], 32, 32, 1), dtype=test_images.dtype)\n",
    "    train_images_pad[:,2:30, 2:30, :] = train_images\n",
    "    test_images_pad[:,2:30, 2:30, :] = test_images\n",
    "    \n",
    "    return train_images_pad, train_labels, test_images_pad, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cifar():\n",
    "    cifar = tf.keras.datasets.cifar10\n",
    "    (train_images, train_labels), (test_images, test_labels) = cifar.load_data()\n",
    "    \n",
    "    train_images = train_images.astype(\"float32\") / 255.0\n",
    "    test_images = test_images.astype(\"float32\") / 255.0\n",
    "    \n",
    "    train_labels = np.squeeze(train_labels)\n",
    "    test_labels = np.squeeze(test_labels)\n",
    "\n",
    "    return train_images, train_labels, test_images, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 32, 32, 3), (10000, 32, 32, 3))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x,train_y,test_x,test_y = create_cifar()\n",
    "train_x.shape, test_x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taken from here: https://www.kaggle.com/paultimothymooney/breast-histopathology-images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BC_LOCATION = r'D:\\code\\image_datasets\\Breast_Cancer\\IDC_regular_ps50_idx5'\n",
    "\n",
    "def create_bcancer (location=BC_LOCATION, seed=0, limit_data=50000):\n",
    "    \"\"\"\n",
    "    set limit_data to -1 in order not to limit the data size\n",
    "    \"\"\"\n",
    "    \n",
    "    image_patches = glob.glob(os.path.join(location, r'**/*.png'), recursive=True)\n",
    "    data = np.zeros((0,50,50,3))\n",
    "    labels = np.zeros((0,1))\n",
    "    \n",
    "    num_samples = len(image_patches)\n",
    "    np.random.seed(seed)\n",
    "    randperm = np.random.permutation(num_samples)\n",
    "    \n",
    "    for idx in tqdm(randperm[:limit_data]):\n",
    "        try:\n",
    "            f = image_patches[idx]\n",
    "            img = np.reshape(plt.imread(f), (1,50,50,3))\n",
    "        except ValueError:\n",
    "            continue # edge patches with unorthodox size\n",
    "        data = np.append(data, img, axis=0)\n",
    "        if f.endswith(\"class0.png\"):\n",
    "            labels = np.append(labels, [0])\n",
    "        else:\n",
    "            labels = np.append(labels, [1])\n",
    "            \n",
    "    # Split to train and test\n",
    "    num_samples = labels.size\n",
    "    train_x = data[:(num_samples*4//5), :, :, :]\n",
    "    train_y = labels[:(num_samples*4//5)]\n",
    "    test_x = data[(num_samples*4//5):, :, :, :]\n",
    "    test_y = labels[(num_samples*4//5):]\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "418d919b6c1e4f1f9addd93c5feda5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 10h 6min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((39652, 50, 50, 3), (39652,), (9913, 50, 50, 3), (9913,), 11341.0, 2823.0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# verify breast_cancer dataset\n",
    "bc_train_x,bc_train_y,bc_test_x,bc_test_y = create_bcancer()\n",
    "bc_train_x.shape, bc_train_y.shape, bc_test_x.shape, bc_test_y.shape, bc_train_y.sum(), bc_test_y.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lenet(input_shape):\n",
    "    lenet = keras.Sequential()\n",
    "\n",
    "    lenet.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "    lenet.add(layers.AveragePooling2D())\n",
    "    lenet.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "    lenet.add(layers.AveragePooling2D())\n",
    "    lenet.add(layers.Flatten())\n",
    "    lenet.add(layers.Dense(units=120, activation='relu'))\n",
    "    lenet.add(layers.Dense(units=84, activation='relu'))\n",
    "    lenet.add(layers.Dense(units=10, activation = 'softmax'))\n",
    "    \n",
    "    return lenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(28,28,1)\n",
    "input_shape_pad=(32,32,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_48 (Conv2D)           (None, 26, 26, 6)         60        \n",
      "_________________________________________________________________\n",
      "average_pooling2d_32 (Averag (None, 13, 13, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_49 (Conv2D)           (None, 11, 11, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_33 (Averag (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_18 (Flatten)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 60,074\n",
      "Trainable params: 60,074\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet = create_lenet(input_shape)\n",
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_minivgg(input_shape):\n",
    "    minivgg = Sequential()\n",
    "    # first CONV => RELU => CONV => RELU => POOL layer set\n",
    "    minivgg.add(Conv2D(32, (3, 3), padding=\"same\",\n",
    "        input_shape=input_shape))\n",
    "    minivgg.add(Activation(\"relu\"))\n",
    "    minivgg.add(BatchNormalization(axis=-1))\n",
    "    minivgg.add(Conv2D(32, (3, 3), padding=\"same\"))\n",
    "    minivgg.add(Activation(\"relu\"))\n",
    "    minivgg.add(BatchNormalization(axis=-1))\n",
    "    minivgg.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    minivgg.add(Dropout(0.25))\n",
    "    # second CONV => RELU => CONV => RELU => POOL layer set\n",
    "    minivgg.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    minivgg.add(Activation(\"relu\"))\n",
    "    minivgg.add(BatchNormalization(axis=-1))\n",
    "    minivgg.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
    "    minivgg.add(Activation(\"relu\"))\n",
    "    minivgg.add(BatchNormalization(axis=-1))\n",
    "    minivgg.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    minivgg.add(Dropout(0.25))\n",
    "    # first (and only) set of FC => RELU layers\n",
    "    minivgg.add(Flatten())\n",
    "    minivgg.add(Dense(512))\n",
    "    minivgg.add(Activation(\"relu\"))\n",
    "    minivgg.add(BatchNormalization())\n",
    "    minivgg.add(Dropout(0.5))\n",
    "    # softmax classifier\n",
    "    minivgg.add(Dense(10))\n",
    "    minivgg.add(Activation(\"softmax\"))\n",
    "    \n",
    "    return minivgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 32)        320       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28, 28, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 28, 28, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 14, 14, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 7, 7, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3136)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               1606144   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,679,082\n",
      "Trainable params: 1,677,674\n",
      "Non-trainable params: 1,408\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "minivgg = create_minivgg(input_shape)\n",
    "minivgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mobilenmetv2(input_shape):\n",
    "    mobilenetv2 = tf.keras.applications.MobileNetV2(input_shape=input_shape,\n",
    "                                                include_top=True,\n",
    "                                                weights=None,\n",
    "                                                classes=10,\n",
    "                                                classifier_activation=\"softmax\")\n",
    "    return mobilenetv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"mobilenetv2_1.00_32\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 33, 33, 1)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 16, 16, 32)   288         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 16, 16, 32)   128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 16, 16, 32)   0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 16, 16, 32)   288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 16, 16, 32)   128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 16, 16, 32)   0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 16, 16, 16)   512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 16, 16, 16)   64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 16, 16, 96)   1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 16, 16, 96)   384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 16, 16, 96)   0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 17, 17, 96)   0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 8, 8, 96)     864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 8, 8, 96)     384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 8, 8, 96)     0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 8, 8, 24)     2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 8, 8, 24)     96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 8, 8, 144)    3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 8, 8, 144)    1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 8, 8, 144)    576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 8, 8, 144)    0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 8, 8, 24)     3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 8, 8, 24)     96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 8, 8, 24)     0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 8, 8, 144)    3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 8, 8, 144)    576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 8, 8, 144)    0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 9, 9, 144)    0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 4, 4, 144)    1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 4, 4, 144)    576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 4, 4, 144)    0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 4, 4, 32)     4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 4, 4, 32)     128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 4, 4, 192)    6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 4, 4, 32)     6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 4, 4, 32)     128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 4, 4, 32)     0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 4, 4, 192)    6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 4, 4, 192)    1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 4, 4, 192)    768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 4, 4, 192)    0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 4, 4, 32)     6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 4, 4, 32)     128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 4, 4, 32)     0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 4, 4, 192)    6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 4, 4, 192)    768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 4, 4, 192)    0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 5, 5, 192)    0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 2, 2, 192)    1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 2, 2, 192)    768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 2, 2, 192)    0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 2, 2, 64)     12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 2, 2, 64)     256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 2, 2, 384)    24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 2, 2, 64)     24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 2, 2, 64)     256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 2, 2, 64)     0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 2, 2, 384)    24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 2, 2, 64)     24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 2, 2, 64)     256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 2, 2, 64)     0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 2, 2, 384)    24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 2, 2, 384)    1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 2, 2, 384)    0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 2, 2, 384)    3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 2, 2, 384)    1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 2, 2, 384)    0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 2, 2, 64)     24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 2, 2, 64)     256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 2, 2, 64)     0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 2, 2, 384)    24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 2, 2, 384)    1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 2, 2, 384)    0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 2, 2, 384)    3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 2, 2, 384)    1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 2, 2, 384)    0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 2, 2, 96)     36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 2, 2, 96)     384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 2, 2, 576)    55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 2, 2, 96)     55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 2, 2, 96)     384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 2, 2, 96)     0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 2, 2, 576)    55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 2, 2, 576)    5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 2, 2, 576)    2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 2, 2, 576)    0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 2, 2, 96)     55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 2, 2, 96)     384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 2, 2, 96)     0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 2, 2, 576)    55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 2, 2, 576)    2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 2, 2, 576)    0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 3, 3, 576)    0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 1, 1, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 1, 1, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 1, 1, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 1, 1, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 1, 1, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 1, 1, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 1, 1, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 1, 1, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 1, 1, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 1, 1, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 1, 1, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 1, 1, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 1, 1, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 1, 1, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 1, 1, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 1, 1, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 1, 1, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 1, 1, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 1, 1, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 1, 1, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 1, 1, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 1, 1, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 1, 1, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 1, 1, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 10)           12810       global_average_pooling2d[0][0]   \n",
      "==================================================================================================\n",
      "Total params: 2,270,218\n",
      "Trainable params: 2,236,106\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mobilenetv2 = create_mobilenmetv2(input_shape_pad)\n",
    "mobilenetv2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet Kernel - Convolutional SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of this model is to pre-train LeNet using MNist, and then run it as a kernel for SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv_SVM:\n",
    "    def __init__ (self, input_shape=(32,32,1), location = r'D:\\code\\Daniely\\Models\\LeNetKer'):\n",
    "        self.location = location\n",
    "        self.input_shape = input_shape\n",
    "        self._load_model()\n",
    "        self.clf = None\n",
    "\n",
    "    def _load_model(self):\n",
    "        if not os.path.exists(self.location):\n",
    "            mnist = tf.keras.datasets.mnist\n",
    "            (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "            train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype(\"float32\") / 255.0\n",
    "            train_images_pad = np.zeros((train_images_norm.shape[0], 32, 32, 1), dtype=train_images_norm.dtype)\n",
    "            train_images_pad[:,2:30, 2:30, :] = train_images\n",
    "\n",
    "            init_lr = 1e-2\n",
    "            num_epochs = 100\n",
    "            lenet_model = create_lenet((32,32,1))\n",
    "            opt = keras.optimizers.SGD(lr=init_lr, momentum=0.9, decay=init_lr / num_epochs)\n",
    "            lenet_model.compile(optimizer=opt,\n",
    "                                loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                                metrics=['accuracy'])\n",
    "\n",
    "            model.history = lenet_model.fit(x=train_images_pad, y=train_labels,\n",
    "                                            batch_size = 32, verbose=1, epochs=num_epochs)\n",
    "\n",
    "            lenet_model.save(self.location)\n",
    "        else:\n",
    "            lenet_model = keras.models.load_model(self.location)\n",
    "            \n",
    "        # Update the model to the input shape\n",
    "        input_shape = self.input_shape\n",
    "        json = lenet_model.to_json()\n",
    "        json = json.replace('\"batch_input_shape\": [null, 32, 32, 1]', '\"batch_input_shape\": [null, %d, %d, %d]'\n",
    "                            %(input_shape[0],input_shape[1],input_shape[2]))\n",
    "        crop_x = (input_shape[0]-2)//4-7\n",
    "        crop_y = (input_shape[1]-2)//4-7\n",
    "        json = json.replace('{\"class_name\": \"Flatten\",',\n",
    "                            '{\"class_name\": \"Cropping2D\", \"config\": {\"name\": \"cropping2d\", \"trainable\": true, \"dtype\": \"float32\", \"cropping\": [[%d, %d], [%d, %d]], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Flatten\",'\n",
    "                           %(crop_x//2, crop_x-crop_x//2, crop_y//2, crop_y-crop_y//2))\n",
    "        new_model = keras.models.model_from_json(json)\n",
    "        \n",
    "        # Update the weights\n",
    "        new_weights = [K.repeat_elements(lenet_model.layers[0].weights[0], input_shape[2], 2).numpy(),\n",
    "                      lenet_model.layers[0].weights[1].numpy()]\n",
    "        new_model.layers[0].set_weights(new_weights)\n",
    "        for layer in new_model.layers[1:]:\n",
    "            try:\n",
    "                layer.set_weights(lenet_model.get_layer(name=layer.name).get_weights())\n",
    "            except ValueError: # for new added layer\n",
    "                pass\n",
    "        \n",
    "        self.model = new_model\n",
    "        \n",
    "        \n",
    "    def _map_to_feat_space(self, xdata):\n",
    "        features = keras.Model(self.model.input, self.model.get_layer(index=-2).output)\n",
    "        res = features.predict(xdata)\n",
    "        return res\n",
    "    \n",
    "    def accuracy (self, x, y):\n",
    "        if self.clf is None:\n",
    "            raise Exception('Need to fit some data first')\n",
    "        y_pred = self.clf.predict(x)\n",
    "        return (y_pred == y).sum() / y.size\n",
    "        \n",
    "    def compile(self, **args):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, x, y, validation_data, **args):\n",
    "        self.clf = svm.SVC(decision_function_shape='ovr')\n",
    "        \n",
    "        # instead of using smart kernel, we just map to the new feature space\n",
    "        x_train_feat = self._map_to_feat_space(x)\n",
    "        self.clf.fit(x_train_feat, y)\n",
    "        \n",
    "        x_test_feat = self._map_to_feat_space(validation_data[0])\n",
    "        history = {'accuracy': [self.accuracy(x_train_feat, y)],\n",
    "                   'val_accuracy': [self.accuracy(x_test_feat, validation_data[1])]}\n",
    "        \n",
    "        return namedtuple(\"History\", \"history\")(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_convsvm(input_shape):\n",
    "    if input_shape[0] < 32 or input_shape[1] < 32:\n",
    "        raise Exception('Input edge must be at least 32, got %s'%input_shape[0])\n",
    "    return Conv_SVM(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(History(history={'accuracy': [0.8441833333333333], 'val_accuracy': [0.8277]}),\n",
       " 370.8115990161896)"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainx, trainy, testx, testy = create_fmnist()\n",
    "csvm = evaluate_model('convsvm', trainx, trainy, testx, testy)\n",
    "csvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_model = keras.models.load_model(r'D:\\code\\Daniely\\Models\\LeNetKer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 30, 30, 6)         168       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 15, 15, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 13, 13, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 6, 6, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 120)               69240     \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 81,302\n",
      "Trainable params: 81,302\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_shape = [32,32,3]\n",
    "json = lenet_model.to_json()\n",
    "json = json.replace('\"batch_input_shape\": [null, 32, 32, 1]', '\"batch_input_shape\": [null, %d, %d, %d]'\n",
    "                    %(input_shape[0],input_shape[1],input_shape[2]))\n",
    "keras.models.model_from_json(json).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = [50,50,3]\n",
    "json = lenet_model.to_json()\n",
    "json = json.replace('\"batch_input_shape\": [null, 32, 32, 1]', '\"batch_input_shape\": [null, %d, %d, %d]'\n",
    "                    %(input_shape[0],input_shape[1],input_shape[2]))\n",
    "new_model = keras.models.model_from_json(json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "json2 = json.replace('\"strides\": [1, 1]', '\"strides\": [2, 2]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = keras.Sequential()\n",
    "\n",
    "lenet.add(layers.Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
    "lenet.add(layers.AveragePooling2D())\n",
    "lenet.add(layers.Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\n",
    "lenet.add(layers.AveragePooling2D())\n",
    "lenet.add(layers.Cropping2D(cropping=((0,0),(0,0))))\n",
    "lenet.add(layers.Flatten())\n",
    "lenet.add(layers.Dense(units=120, activation='relu'))\n",
    "lenet.add(layers.Dense(units=84, activation='relu'))\n",
    "lenet.add(layers.Dense(units=10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 48, 48, 6)         168       \n",
      "_________________________________________________________________\n",
      "average_pooling2d (AveragePo (None, 24, 24, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 22, 22, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "cropping2d (Cropping2D)      (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1936)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 120)               232440    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 244,502\n",
      "Trainable params: 244,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 50, 50, 3], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"conv2d_input\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d\", \"trainable\": true, \"batch_input_shape\": [null, 50, 50, 3], \"dtype\": \"float32\", \"filters\": 6, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"AveragePooling2D\", \"config\": {\"name\": \"average_pooling2d\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_1\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 16, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"AveragePooling2D\", \"config\": {\"name\": \"average_pooling2d_1\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Cropping2D\", \"config\": {\"name\": \"cropping2d\", \"trainable\": true, \"dtype\": \"float32\", \"cropping\": [[0, 0], [0, 0]], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 120, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_1\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 84, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_2\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenet.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_9\", \"layers\": [{\"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 50, 50, 3], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"conv2d_22_input\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_22\", \"trainable\": true, \"batch_input_shape\": [null, 50, 50, 3], \"dtype\": \"float32\", \"filters\": 6, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"AveragePooling2D\", \"config\": {\"name\": \"average_pooling2d_14\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Conv2D\", \"config\": {\"name\": \"conv2d_23\", \"trainable\": true, \"dtype\": \"float32\", \"filters\": 16, \"kernel_size\": [3, 3], \"strides\": [1, 1], \"padding\": \"valid\", \"data_format\": \"channels_last\", \"dilation_rate\": [1, 1], \"groups\": 1, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"AveragePooling2D\", \"config\": {\"name\": \"average_pooling2d_15\", \"trainable\": true, \"dtype\": \"float32\", \"pool_size\": [2, 2], \"padding\": \"valid\", \"strides\": [2, 2], \"data_format\": \"channels_last\"}}, {\"class_name\": \"Flatten\", \"config\": {\"name\": \"flatten_9\", \"trainable\": true, \"dtype\": \"float32\", \"data_format\": \"channels_last\"}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_25\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 120, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_26\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 84, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}, {\"class_name\": \"Dense\", \"config\": {\"name\": \"dense_27\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 10, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}}, \"bias_initializer\": {\"class_name\": \"Zeros\", \"config\": {}}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}}]}, \"keras_version\": \"2.4.0\", \"backend\": \"tensorflow\"}'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 48, 48, 6)         168       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 24, 24, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 22, 22, 16)        880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 11, 11, 16)        0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 1936)              0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 120)               232440    \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 244,502\n",
      "Trainable params: 244,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.model_from_json(json)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 24, 24, 6)         168       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_14 (Averag (None, 12, 12, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 5, 5, 16)          880       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_15 (Averag (None, 2, 2, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 120)               7800      \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_27 (Dense)             (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 19,862\n",
      "Trainable params: 19,862\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model = keras.models.model_from_json(json2)\n",
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No such layer: cropping2d.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-d9c36624e7d5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mConv_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-63-072bb69cd5a9>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, location)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-63-072bb69cd5a9>\u001b[0m in \u001b[0;36m_load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlenet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mget_layer\u001b[1;34m(self, name, index)\u001b[0m\n\u001b[0;32m   2396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2397\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2398\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No such layer: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2399\u001b[0m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Provide either a layer name or layer index.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: No such layer: cropping2d."
     ]
    }
   ],
   "source": [
    "Conv_SVM([32,32,3]).model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (1936, 120) not compatible with provided weight shape (576, 120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-b522e7089d6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-b5d399a681b7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, location)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b5d399a681b7>\u001b[0m in \u001b[0;36m_load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlenet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1822\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1824\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m   1825\u001b[0m               \u001b[1;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m               'shape %s' % (ref_shape, weight.shape))\n",
      "\u001b[1;31mValueError\u001b[0m: Layer weight shape (1936, 120) not compatible with provided weight shape (576, 120)"
     ]
    }
   ],
   "source": [
    "cs = Conv_SVM([50,50,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (1936, 120) not compatible with provided weight shape (576, 120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-dc31402e0df2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcsvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'convsvm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-82190025da37>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model_name, trainx, trainy, testx, testy, num_epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_mobilenmetv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'convsvm'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_convsvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-27136d912557>\u001b[0m in \u001b[0;36mcreate_convsvm\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_convsvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mConv_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-b5d399a681b7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, location)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b5d399a681b7>\u001b[0m in \u001b[0;36m_load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlenet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1822\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1824\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m   1825\u001b[0m               \u001b[1;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m               'shape %s' % (ref_shape, weight.shape))\n",
      "\u001b[1;31mValueError\u001b[0m: Layer weight shape (1936, 120) not compatible with provided weight shape (576, 120)"
     ]
    }
   ],
   "source": [
    "csvm = evaluate_model('convsvm', data[0], data[1], data[2], data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usefull Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model_name, trainx, trainy, testx, testy, num_epochs=50):\n",
    "    \"\"\"\n",
    "    model_name is either vgg, mobilenet, lenet, convsvm\n",
    "    \"\"\"\n",
    "    \n",
    "    init_lr = 1e-2\n",
    "    input_shape = trainx.shape[1:]\n",
    "    \n",
    "    if model_name.lower() == 'lenet':\n",
    "        model = create_lenet(input_shape)\n",
    "    elif model_name.lower() == 'vgg':\n",
    "        model = create_minivgg(input_shape)\n",
    "    elif model_name.lower() == 'mobilenet':\n",
    "        model = create_mobilenmetv2(input_shape)\n",
    "    elif model_name.lower() == 'convsvm':\n",
    "        model = create_convsvm(input_shape)\n",
    "    else:\n",
    "        model = model_name\n",
    "        \n",
    "    t = time.time()\n",
    "    opt = keras.optimizers.SGD(lr=init_lr, momentum=0.9, decay=init_lr / num_epochs)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x=trainx, y=trainy, validation_data=(testx, testy),\n",
    "                        batch_size = 32, verbose=1, epochs=num_epochs)\n",
    "    \n",
    "    total_time = time.time()-t\n",
    "    return history, total_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_dataset(db_name, num_epochs=50):\n",
    "    \"\"\"\n",
    "    Returns a table with the following information:\n",
    "    name # either fmnist, cifar10, bcancer\n",
    "    shape\n",
    "    train size\n",
    "    test size\n",
    "    lenet test err\n",
    "    vgg test err\n",
    "    mobilenet test err\n",
    "    lenet runtime\n",
    "    vgg runtime\n",
    "    mobilenet runtime\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(db_name) == str:\n",
    "        if db_name.lower() == 'fmnist':\n",
    "            trainx, trainy, testx, testy = create_fmnist()\n",
    "        elif db_name.lower() == 'cifar10':\n",
    "            trainx, trainy, testx, testy = create_cifar()\n",
    "        elif db_name.lower() == 'bcancer':\n",
    "            trainx, trainy, testx, testy = create_bcancer()\n",
    "        else:\n",
    "            raise AttributeError('Unknown db name %s'%db_name)\n",
    "    elif len(db_name) == 4:\n",
    "        trainx, trainy, testx, testy = db_name\n",
    "    else:\n",
    "        raise AttributeError('Unknown db')\n",
    "    \n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data={'name' : [db_name],\n",
    "                            'shapey' : [trainx.shape[1]],\n",
    "                            'shapex' : [trainx.shape[2]],\n",
    "                            'shapez' : [trainx.shape[3]],\n",
    "                            'train size' : [trainx.shape[0]],\n",
    "                            'test size' : [testx.shape[0]],\n",
    "                            'num epochs' : [num_epochs]})\n",
    "    \n",
    "    history, df['lenet runtime'] = evaluate_model('lenet', trainx, trainy, testx, testy, num_epochs=num_epochs)\n",
    "    df['lenet test err'] = [history.history['val_accuracy'][-1]]\n",
    "    df['lenet history'] = [history.history]\n",
    "    \n",
    "    history, df['vgg runtime'] = evaluate_model('vgg', trainx, trainy, testx, testy, num_epochs=num_epochs)\n",
    "    df['vgg test err'] = [history.history['val_accuracy'][-1]]\n",
    "    df['vgg history'] = [history.history]\n",
    "    \n",
    "    history, df['mobilenet runtime'] = evaluate_model('mobilenet', trainx, trainy, testx, testy, num_epochs=num_epochs)\n",
    "    df['mobilenet test err'] = [history.history['val_accuracy'][-1]]\n",
    "    df['mobilenet history'] = [history.history]\n",
    "    \n",
    "    history, df['convsvm runtime'] = evaluate_model('convsvm', trainx, trainy, testx, testy, num_epochs=num_epochs)\n",
    "    df['convsvm test err'] = [history.history['val_accuracy'][-1]]\n",
    "    df['convsvm history'] = [history.history]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6655 - accuracy: 0.7500 - val_loss: 0.5335 - val_accuracy: 0.7971\n",
      "Epoch 2/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.4469 - accuracy: 0.8343 - val_loss: 0.4281 - val_accuracy: 0.8450\n",
      "Epoch 3/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3938 - accuracy: 0.8526 - val_loss: 0.4060 - val_accuracy: 0.8502\n",
      "Epoch 4/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3590 - accuracy: 0.8658 - val_loss: 0.3821 - val_accuracy: 0.8589\n",
      "Epoch 5/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.3361 - accuracy: 0.8745 - val_loss: 0.3734 - val_accuracy: 0.8602\n",
      "Epoch 6/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3217 - accuracy: 0.8806 - val_loss: 0.3517 - val_accuracy: 0.8727\n",
      "Epoch 7/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3074 - accuracy: 0.8857 - val_loss: 0.3535 - val_accuracy: 0.8683\n",
      "Epoch 8/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2972 - accuracy: 0.8879 - val_loss: 0.3471 - val_accuracy: 0.8721\n",
      "Epoch 9/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2879 - accuracy: 0.8917 - val_loss: 0.3276 - val_accuracy: 0.8795\n",
      "Epoch 10/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2799 - accuracy: 0.8956 - val_loss: 0.3298 - val_accuracy: 0.8792\n",
      "Epoch 11/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2738 - accuracy: 0.8963 - val_loss: 0.3301 - val_accuracy: 0.8784\n",
      "Epoch 12/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2666 - accuracy: 0.9000 - val_loss: 0.3245 - val_accuracy: 0.8800\n",
      "Epoch 13/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2615 - accuracy: 0.9017 - val_loss: 0.3194 - val_accuracy: 0.8841\n",
      "Epoch 14/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2565 - accuracy: 0.9030 - val_loss: 0.3258 - val_accuracy: 0.8801\n",
      "Epoch 15/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2515 - accuracy: 0.9052 - val_loss: 0.3234 - val_accuracy: 0.8824\n",
      "Epoch 16/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2469 - accuracy: 0.9071 - val_loss: 0.3152 - val_accuracy: 0.8844\n",
      "Epoch 17/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.2438 - accuracy: 0.9074 - val_loss: 0.3177 - val_accuracy: 0.8815\n",
      "Epoch 18/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2386 - accuracy: 0.9099 - val_loss: 0.3253 - val_accuracy: 0.8830\n",
      "Epoch 19/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2349 - accuracy: 0.9114 - val_loss: 0.3228 - val_accuracy: 0.8827\n",
      "Epoch 20/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2311 - accuracy: 0.9121 - val_loss: 0.3146 - val_accuracy: 0.8886\n",
      "Epoch 21/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2274 - accuracy: 0.9135 - val_loss: 0.3164 - val_accuracy: 0.8854\n",
      "Epoch 22/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2250 - accuracy: 0.9148 - val_loss: 0.3150 - val_accuracy: 0.8883\n",
      "Epoch 23/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2205 - accuracy: 0.9156 - val_loss: 0.3099 - val_accuracy: 0.8867\n",
      "Epoch 24/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2180 - accuracy: 0.9183 - val_loss: 0.3115 - val_accuracy: 0.8879\n",
      "Epoch 25/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2158 - accuracy: 0.9181 - val_loss: 0.3182 - val_accuracy: 0.8868\n",
      "Epoch 26/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2128 - accuracy: 0.9201 - val_loss: 0.3159 - val_accuracy: 0.8880\n",
      "Epoch 27/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2107 - accuracy: 0.9205 - val_loss: 0.3227 - val_accuracy: 0.8866\n",
      "Epoch 28/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2069 - accuracy: 0.9224 - val_loss: 0.3177 - val_accuracy: 0.8883\n",
      "Epoch 29/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2047 - accuracy: 0.9222 - val_loss: 0.3148 - val_accuracy: 0.8924\n",
      "Epoch 30/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2032 - accuracy: 0.9234 - val_loss: 0.3180 - val_accuracy: 0.8885\n",
      "Epoch 31/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2010 - accuracy: 0.9244 - val_loss: 0.3247 - val_accuracy: 0.8869\n",
      "Epoch 32/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1976 - accuracy: 0.9258 - val_loss: 0.3168 - val_accuracy: 0.8870\n",
      "Epoch 33/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1955 - accuracy: 0.9268 - val_loss: 0.3159 - val_accuracy: 0.8892\n",
      "Epoch 34/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1932 - accuracy: 0.9278 - val_loss: 0.3183 - val_accuracy: 0.8912\n",
      "Epoch 35/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1912 - accuracy: 0.9280 - val_loss: 0.3175 - val_accuracy: 0.8920\n",
      "Epoch 36/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1896 - accuracy: 0.9287 - val_loss: 0.3199 - val_accuracy: 0.8906\n",
      "Epoch 37/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1873 - accuracy: 0.9297 - val_loss: 0.3204 - val_accuracy: 0.8920\n",
      "Epoch 38/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1853 - accuracy: 0.9309 - val_loss: 0.3213 - val_accuracy: 0.8911\n",
      "Epoch 39/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1836 - accuracy: 0.9317 - val_loss: 0.3220 - val_accuracy: 0.8921\n",
      "Epoch 40/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1819 - accuracy: 0.9316 - val_loss: 0.3267 - val_accuracy: 0.8901\n",
      "Epoch 41/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1801 - accuracy: 0.9321 - val_loss: 0.3256 - val_accuracy: 0.8890\n",
      "Epoch 42/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1783 - accuracy: 0.9327 - val_loss: 0.3246 - val_accuracy: 0.8896\n",
      "Epoch 43/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1766 - accuracy: 0.9338 - val_loss: 0.3288 - val_accuracy: 0.8877\n",
      "Epoch 44/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1755 - accuracy: 0.9341 - val_loss: 0.3311 - val_accuracy: 0.8916\n",
      "Epoch 45/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1742 - accuracy: 0.9341 - val_loss: 0.3344 - val_accuracy: 0.8909\n",
      "Epoch 46/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1709 - accuracy: 0.9360 - val_loss: 0.3392 - val_accuracy: 0.8870\n",
      "Epoch 47/50\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1704 - accuracy: 0.9358 - val_loss: 0.3265 - val_accuracy: 0.8932\n",
      "Epoch 48/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1688 - accuracy: 0.9370 - val_loss: 0.3323 - val_accuracy: 0.8889\n",
      "Epoch 49/50\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1677 - accuracy: 0.9379 - val_loss: 0.3347 - val_accuracy: 0.8910\n",
      "Epoch 50/50\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.1663 - accuracy: 0.9377 - val_loss: 0.3407 - val_accuracy: 0.8882\n",
      "Wall time: 7min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "history_lnt, t_lnt = evaluate_model('lenet', train_images_norm, train_labels, test_images_norm, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1080x288 with 2 Axes>,\n",
       " array([<AxesSubplot:title={'center':'loss'}>,\n",
       "        <AxesSubplot:title={'center':'accuracy'}>], dtype=object))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAEICAYAAAAuiAdzAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAABnUklEQVR4nO3dd5zcVb3/8ddny2zvLZvdbDa9QRLCEkIz9CZdwCCgoIigiNiuXO/v2r0Xr6igoIiKlSLSldA70pJASCW9bTbZ3ns5vz/OJNlsdpNNspvZ2byfj8c8Zubb5jPfTPY7nznnfI455xAREREREZGhIyLUAYiIiIiIiMjulKiJiIiIiIgMMUrUREREREREhhglaiIiIiIiIkOMEjUREREREZEhRomaiIiIiIjIEKNETWQAmNlGMzs91HGIiIiIyPCgRE1ERERERGSIUaImIiIiIkOSefq+KoclffBFBpCZxZjZHWZWErzdYWYxwXWZZvYvM6sxsyoze2PHxcfMvmVmW82s3sxWmdlpoX0nIiIiu5jZrWa2LnidWmFmF3db93kzW9lt3azg8lFm9piZlZtZpZndFVz+PTP7W7f9C83MmVlU8PmrZvZjM/s30ASMNbNru73GejP7Qo/4LjSzxWZWF4zzbDO7zMwW9dju62b2xKCdKJEBFBXqAESGmf8C5gAzAQc8Cfw/4L+BrwPFQFZw2zmAM7NJwE3AMc65EjMrBCIPbdgiIiJ7tQ44CdgOXAb8zczGAycC3wMuAhYC44B2M4sE/gW8DFwNdAJF+/F6VwPnAKsAAyYB5wHrgY8Bz5jZAufc+2Y2G/gLcCnwEpALJAEbgN+a2RTn3Mrgca8CfnQA71/kkFOLmsjAuhL4gXOuzDlXDnwff7EBaMdfPEY759qdc2845xz+4hUDTDWzaOfcRufcupBELyIi0gvn3D+ccyXOuS7n3N+BNcBs4Drg/5xzC5y31jm3KbhuJPBN51yjc67FOffmfrzkn5xzy51zHcFr5tPOuXXB13gNeB6fOAJ8DrjPOfdCML6tzrmPnHOtwN/xyRlmNg0oxCeQIkOeEjWRgTUS2NTt+abgMoCfAmuB54PdNm4FcM6tBW7B/yJZZmYPmdlIREREhggz+3Swa2GNmdUARwCZwCh8a1tPo4BNzrmOA3zJLT1e/xwzeyc4dKAGODf4+jteq68fOP8MfMrMDP/D6cPBBE5kyFOiJjKwSoDR3Z4XBJfhnKt3zn3dOTcWOB/42o6xaM65B5xzJwb3dcBPDm3YIiIivTOz0cDv8N30M5xzqcAyfJfELfjujj1tAQp2jDvroRGI7/Z8RC/buG6vHwM8CtwO5ARff37w9Xe8Vm8x4Jx7B2jDt759Cvhrb9uJDEVK1EQG1oPA/zOzLDPLBL4D/A3AzM4zs/HBX/Xq8F0eO81skpmdGrwQtQDNwXUiIiJDQQI+cSoHMLNr8S1qAL8HvmFmRwcrNI4PJnbvAduA28wswcxizeyE4D6LgY+ZWYGZpQD/uY/XD+CHCJQDHWZ2DnBmt/V/AK41s9PMLMLM8sxscrf1fwHuAjr2s/ulSEgpURMZWD/CD6ZeAiwF3mfXoOUJwItAA/A28Gvn3Kv4i89tQAV+kHY28O1DGrWIiEgfnHMrgJ/hr12lwJHAv4Pr/gH8GHgAqAeeANKdc5343iPjgc34YlqfDO7zAn7s2BJgEfsYM+acqwduBh4GqvEtY091W/8ecC3wC6AWeI3de7f8FZ9YqjVNwor5WgYiIiIiIsOPmcUBZcAs59yaUMcj0l9qURMRERGR4exGYIGSNAk3mkdNRERERIYlM9uILzpyUWgjEdl/6vooIiIiIiIyxKjro4iIiIiIyBATsq6PmZmZrrCwMFQvLyIih9CiRYsqnHNZoY4jXOgaKSJyeNjb9TFkiVphYSELFy4M1cuLiMghZGabQh1DONE1UkTk8LC366O6PoqIiIiIiAwxStRERERERESGGCVqIiIiIiIiQ4zmURORw1Z7ezvFxcW0tLSEOpRhIzY2lvz8fKKjo0MdyrCjz+vA0mdVRIY6JWoictgqLi4mKSmJwsJCzCzU4YQ95xyVlZUUFxczZsyYUIcz7OjzOnD0WRWRcKCujyJy2GppaSEjI0NfegeImZGRkaEWn0Giz+vA0WdVRMKBEjUROazpS+/A0vkcXDq/A0fnUkSGurDt+ripspFHFhVzxewCRqbGhTocEREREREJc3Ut7WyubGJTZRObq5po7egkEBVBIDKCQFQE0ZH+FoiKID8tjlkFaYMWS9gmattrW/jVy2s5dkyGEjURCUs1NTU88MADfPGLX9yv/c4991weeOABUlNTBycwkV7o8yoiw0Vnl2NjZSOrttezans9Gyoa2VTVxObKRqqb2vt9nPNnjFSi1puMxAAAlY2tIY5EROTA1NTU8Otf/3qPL76dnZ1ERkb2ud/8+fMHOzSRPejzKiJDUVeXY8nWWv69toK2ji5ioiOIiYokJiqC2Gh/Hx1pbKlq5qPt9awqrWNNaQOtHV0ARBjkpcUxOj2Bc47MZXR6PKMz4ilIT6AgI5646EjaO7to6+yiraOL9s4u2jscbZ1dxAX6/ts3EMI2UUuL94laVWNbiCMRETkwt956K+vWrWPmzJlER0eTmJhIbm4uixcvZsWKFVx00UVs2bKFlpYWvvKVr3D99dcDUFhYyMKFC2loaOCcc87hxBNP5K233iIvL48nn3ySuDj1MpCBp8+riAwV9S3tvLGmgpc/KuPVVWVUNPQvH8hKimHyiCSunjOaybnJTB6RxPjsRGKj955wRUZE7nObwRC2iVpqfAAzJWoiMjC+/8/lrCipG9BjTh2ZzHfPn9bn+ttuu41ly5axePFiXn31VT7+8Y+zbNmyneXC77vvPtLT02lubuaYY47hE5/4BBkZGbsdY82aNTz44IP87ne/4/LLL+fRRx/lqquuGtD3IUOPPq8iEq5qm9vZVNlIfUsHja0dNLV10tjWQVOrv29u68TMiIowIiL8fWTwvr2zi7fXV/LehiraOx3JsVGcPCmbUydnM3diFilx0bR1dtHa3kVrRyetHV20tPv7kalxpCcEQv3290vYJmqREUZafIBKJWoiMkzMnj17tzmdfvnLX/L4448DsGXLFtasWbPHF98xY8Ywc+ZMAI4++mg2btx4qMKVw5w+ryLSl64uR0VDK2vLGlhb3uDvyxpYU9ZAef3ehy3FREXg8OPIOrvcHusnZCfy2RPHcNrkHGYVpBIVuXsR+9idrV/hP5l92CZqAOkJAar62dQpIrI3e2tJOFQSEhJ2Pn711Vd58cUXefvtt4mPj+fkk0/udc6nmJiYnY8jIyNpbm4+JLFKaOnzKiKHWleXo7a5naqmNqob26huaqeyoZWy+lbK6lsorQs+rmuhvL6Vjm5JVlJMFOOyE5k7MYsJ2YmMyUwgNT5AfCCShJgoEgKRxMdEERcdSWTErqkznPPJWkeXo8s5nIOEmLBOX/ZLWL/T9IQAVU1K1EQkPCUlJVFfX9/rutraWtLS0oiPj+ejjz7inXfeOcTRiexOn1eR8NXV5dhW18KWKl9yvriqiS3VzWypamJLdRNVjW1ERUQQFWkEguXno6OM6MgIcFDT3E5NUxu9NHABkBYfTXZSLNnJMYzPyiQnOYYRKbGMzUxkQk4i2UkxBzR3oZkRFWlEHfrhYUNCWCdqGQkB1pQ1hDoMEZEDkpGRwQknnMARRxxBXFwcOTk5O9edffbZ3HPPPUyfPp1JkyYxZ86cEEYqos+rSDhwzlFa18qq0npWb6/396X1rCltoLm9c+d2ZpCbHMuo9HhOmpBFZmIMXc7tqmrY2UVHp69sCJAaH016fIC0hABpwXv/PJqspBhiDtdMapCFdaKWnhBQMRERCWsPPPBAr8tjYmJ45plnel23Y1xPZmYmy5Yt27n8G9/4xoDHJ9KdPq8iQ0NdSzsbKxrZUNHIxoomNlY2srGykXVlDdS1dOzcLisphkk5SVwxu4Bx2QkUpMczKi2ekalxBKIi9vIKMhSEdaKWkRCguqmNzi63W39WEREREZFw1NnlqGlqo6Smha01zZTsuNU2s7XGd1/s2VAxMiWWwswELpg5kkk5SUwM3tLCrMqh7C6sE7X0hADOQU1TGxmJMfveQURERETkEKpvaWdjRRPrKxrYWNHEhooGNlQ2UdPUtrOrYVuHn1C5vbP3Soex0RGMTI0jLzWOs6blUJiRQGFmAoUZCYzOiA/JHF8y+MI6UdvxK0FVoxI1ERE5eGZ2NnAnEAn83jl3W4/1acB9wDigBfisc26ZmY0C/gKMALqAe51zdwb3+R7weaA8eJhvO+fmH4K3IyKHSEdnF8XVzawrb2B9eePO+/UVjVQ07CpHbwYjU+IYk5nAmIx4AlHBwh2REQSiInYW8kiOiyIvNY6RwVtafPQBFeOQ8BbWiVpGgk/OKhvbmBDiWEREJLyZWSRwN3AGUAwsMLOnnHMrum32bWCxc+5iM5sc3P40oAP4unPufTNLAhaZ2Qvd9v2Fc+72Q/duRGSw1LW0s6y4lg+La1m6tYbVpQ1sqmykvXNXS1hGQoBxWYmcNjmbMVm+5Wtslh8jptYv6a+wTtTSu7WoiYiIHKTZwFrn3HoAM3sIuBDonqhNBf4XwDn3kZkVmlmOc24bsC24vN7MVgJ5PfYVkTDinKOysY315Y0s21rLkuIalmytZX15485tRqXHMWVEMqdPyWFcVgJjsxIZl+XnCBM5WGGdqGUk+v8ElUrURETk4OUBW7o9LwaO7bHNh8AlwJtmNhsYDeQDpTs2MLNC4Cjg3W773WRmnwYW4lveqnu+uJldD1wPUFBQcLDvRUT6qa2ja2fFxPUV3botlu9eQTEnOYbp+alcclQeR+anMj0vRcU6ZFCFdaKWFvy1olqJmogcJhITE2loaKCkpISbb76ZRx55ZI9tTj75ZG6//XaKior6PM4dd9zB9ddfT3x8PADnnnsuDzzwAKmpqYMVejjobQBIz1H9twF3mtliYCnwAb7boz+AWSLwKHCLc64uuPg3wA+Dx/oh8DPgs3u8kHP3AvcCFBUV9TGtbPjQZ1UONecc2+taaO9wwUmSjejgJM7RkRGYwZaqJlaXNuycW2xVaT0bKxrp6FbAY0RyLGOzfAXFsZmJjMlKYGpuMjnJsSF8d3I4CutELRAVQVJslLo+ishhZ+TIkb1+8e2vO+64g6uuumrnl9/581XbAt+CNqrb83ygpPsGweTrWgDzI/s3BG+YWTQ+SbvfOfdYt326t7b9DvjXIMU/JOmzKoOprqWdt9ZW8PqaCl5fXU5xdXO/9jODgvR4JmQncda0HCbmJDEuK5ExmQkkxIT112MZRsL+k5iREFDXRxEJW9/61rcYPXo0X/ziFwH43ve+h5nx+uuvU11dTXt7Oz/60Y+48MILd9tv48aNnHfeeSxbtozm5mauvfZaVqxYwZQpU2hu3vVF5cYbb2TBggU0Nzdz6aWX8v3vf59f/vKXlJSUcMopp5CZmckrr7xCYWEhCxcuJDMzk5///Ofcd999AFx33XXccsstbNy4kXPOOYcTTzyRt956i7y8PJ588kni4uIO3ckafAuACWY2BtgKzAM+1X0DM0sFmpxzbcB1wOvOubpg0vYHYKVz7uc99skNjmEDuBhYRhjSZ1VCqbPLUd/STl1zB6X1Lby9rpLXV5fzwZYaOrsciTFRHDcug8+dOIak2Gg6Orto73J0dHbR0elo7+qis9MxMjWOSSN8UhYXUFEPGdrCPlFLTwhQ1di67w1FRPbmmVth+9KBPeaII+Gc2/a6ybx587jlllt2fvl9+OGHefbZZ/nqV79KcnIyFRUVzJkzhwsuuKDP0sy/+c1viI+PZ8mSJSxZsoRZs2btXPfjH/+Y9PR0Ojs7Oe2001iyZAk333wzP//5z3nllVfIzMzc7ViLFi3ij3/8I++++y7OOY499ljmzp1LWloaa9as4cEHH+R3v/sdl19+OY8++ihXXXXVQZ6kocM512FmNwHP4cvz3+ecW25mNwTX3wNMAf5iZp34QiGfC+5+AnA1sDTYLRJ2leH/PzObie/6uBH4wkEHG4LPqz6rMticc3y0vZ6XVpbyzvoqKhvbqGtup665nfrWjt22NYMj81K4ce44TpqQyazRaURHRoQocpHBMSwStf42c4uIDDVHHXUUZWVllJSUUF5eTlpaGrm5uXz1q1/l9ddfJyIigq1bt1JaWsqIESN6Pcbrr7/OzTffDMD06dOZPn36znUPP/ww9957Lx0dHWzbto0VK1bstr6nN998k4svvpiEhAQALrnkEt544w0uuOACxowZw8yZMwE4+uij2bhx48CchCEkmFjN77Hsnm6P34Y9Z4Rxzr1J72PccM5dPcBhhoQ+qzIYWjs6eWd9FS+tLOWllWVsrfHf6abmJpOXGseU3CRS4qJJjo0mJc7fUuOjOaogbWf1b5HhalgkakuKa0MdhoiEu320fA2mSy+9lEceeYTt27czb9487r//fsrLy1m0aBHR0dEUFhbS0tKy12P01oKxYcMGbr/9dhYsWEBaWhrXXHPNPo/jXN81LGJiYnY+joyM3K3bmhxiIfq86rMq/bW6tJ4H3t3M66vLiYwwYqMjiY2OIDY6kpioSGKiI2ht7+TtdZU0tnUSGx3BieOz+PKp4zl1cjbZKtwhQti3EacnxFDd1LbXP9giIkPZvHnzeOihh3jkkUe49NJLqa2tJTs7m+joaF555RU2bdq01/0/9rGPcf/99wOwbNkylixZAkBdXR0JCQmkpKRQWlrKM888s3OfpKQk6uvrez3WE088QVNTE42NjTz++OOcdNJJA/huJZzpsyp709rRyZOLt3L5PW9z5i9e54F3NzM2K4Hx2YlkJgaIioigobWDrTXNrCypY31FIxcelcd91xSx+Dtn8vvPFDFvdoGSNJGgsG9Ry0gI0N7pqGvpICUuOtThiIjst2nTplFfX09eXh65ublceeWVnH/++RQVFTFz5kwmT5681/1vvPFGrr32WqZPn87MmTOZPXs2ADNmzOCoo45i2rRpjB07lhNOOGHnPtdffz3nnHMOubm5vPLKKzuXz5o1i2uuuWbnMa677jqOOuoodR0TQJ9V6d2mykYeeG8z/1hYTFVjG6Mz4vnPcyZz6dH5ZCTG7PsAItIr609LlJmdDdyJH1z9e+fcHn0uzOxk4A4gGqhwzs3d2zGLiorcwoUL9z/iHh5dVMzX//Ehr37jZAozEw76eCJy+Fi5ciVTpkwJdRjDTm/n1cwWOef6nixLdtPbNVKf14Gnc9o/ja0drCtvoKSmma01LZTUNO+61bZQXt9KZIRx+pRsrjx2NCeOzyQioveCMiKyu71dH/fZomZmkcDdwBn4OWYWmNlTzrkV3bZJBX4NnO2c22xm2QMSeT+kJ/qBpJWNbUrURERERA6Qc47SulZWbKtlRUkdK7bVsaKkjk1VTXT/XT82OoKRqXHkpcYxeUQyY7ISuGhmHiNS1GVRZCD1p+vjbGCtc249gJk9BFyIL0u8w6eAx5xzmwGcc2UDHWhfMoIVfzTptYiIiEj/VTe2sbi4hsWba/hgSw3Lttbu9n1qdEY8U3OTuWRWPhNzkshP88lZanx0n1MwiMjA6U+ilgds6fa8GDi2xzYTgWgzexVIAu50zv2l54HM7HrgeoCCgoIDiXcP6TsTNc2lJiL7zzmnLxwDSIWdBpc+rwPncPqsNrV1sK22he21Lawta2Dxlho+2FzNxsomACIMJuYkccaUHKblJTM1N5lJI5JIitXYf5FQ6k+i1tsVoedftyjgaOA0IA5428zecc6t3m0n5+4F7gXf/37/w91TRoIfpFqpFjUR2U+xsbFUVlaSkZGhL78DwDlHZWUlsbHq/jQY9HkdOMPxs9ra0cmyrXV8sLmatWUNOxOzbbXN1LXsPll0dlIMM0el8sljCpg5KpXp+SkkxIR9fTmRYac//yuLgVHdnucDJb1sU+GcawQazex1YAawmkEWF/DzclQ1KFETkf2Tn59PcXEx5eXloQ5l2IiNjSU/Pz/UYQxL+rwOrHD/rG6vbeH9zdUs2lTN+5urWb61jrbOLgAyEwOMTI1jdEY8c8amMyIljtyUWEakxFKQHk9uSqySfZEw0J9EbQEwwczGAFuBefgxad09CdxlZlFAAN818hcDGejeZCTEaIyaiOy36OhoxowZE+owRPpFn1cpq2vh8Q+28uj7xawubQAgEBXB9LwUrjmhkFkFqcwqSNM8ZCLDxD4TNedch5ndBDyHL89/n3NuuZndEFx/j3NupZk9CywBuvAl/JcNZuDdpScE1PVRREREhp2W9k5eWFHKI4uKeWNNOV0Ojh6dxv/7+BSKCtOZmptMICoi1GGKyCDoV4dk59x8YH6PZff0eP5T4KcDF1r/pScEqG5SoiYiIiLho62ji5rmNlraumhu7/S3tk5a2jtpbOvgrXWV/PPDEupbOhiZEssXTx7PJbPyGJuVGOrQReQQGBYjRzMSAqwtawh1GCIiIiJ9cs6xoaKR11eX8/qaCt5eV0lze2ef28dFR3LOESP4xNH5HDc2Q5NIixxmhkWilp4Q0Bg1ERERGXLqW9p5a10lr68u57XV5RRXNwNQmBHPZUX5TMhOJC4QRXwgkrjoSGKjI4kLPs5Pi1M1RpHD2LD435+eGNjZXSAuEBnqcEREROQwVtvczosrSnlm2TZeX11BW2cXCYFIjh+fyRfmjmPuhCwKMuJDHaaIDHHDIlHLCE56XdnYSn5Af/hERETk0Kptauf5Fdt5Ztl23lhTTnunY2RKLFcfN5ozpuYwqyBNRT9EZL8Mi0QtLd4nalWNbeSnKVETERGRweOcY0tVM0u31rJ0ay1Limt4b0MVHV2OvNQ4rj1hDOccMYKZo1I1X5mIHLBhkahlJO5oUdM4NREROXBmdjZwJ346mt87527rsT4NuA8YB7QAn90xHU1f+5pZOvB3oBDYCFzunKs+FO9HBkZ5fSvvbahiSXENS7fWsmxrLXUtHQBERxoTc5L43IljOPfIXKbnpyg5E5EBMSwStfSEGACqGpSoiYjIgTGzSOBu4AygGFhgZk8551Z02+zbwGLn3MVmNjm4/Wn72PdW4CXn3G1mdmvw+bcO3TuT/VVW18I7G6p4d30l76yvZF15IwCByAgmjUji49NHcmReCkfmpTBxRCIxURofLyIDb5gkaru6PoqIiByg2cBa59x6ADN7CLgQ6J6oTQX+F8A595GZFZpZDjB2L/teCJwc3P/PwKsoURtyttU289vX1vP6mnLWBxOzxJgoigrTuKxoFMeOSWfayBSNMxORQ2ZYJGrJsVFERxpVmvRaREQOXB6wpdvzYuDYHtt8CFwCvGlms4HRQP4+9s1xzm0DcM5tM7Ps3l7czK4HrgcoKCg4uHci/Vbf0s49r63j929swDk4cUImnywaxZyxGUwbmUxUpBIzEQmNYZGomRlp8QF1fRQRkYPR28Ai1+P5bcCdZrYYWAp8AHT0c9+9cs7dC9wLUFRUtF/7yv5r7+ziwfc2c+eLa6hsbOOimSP5xlmTVJRMRIaMYZGoge/+qGIiIiJyEIqBUd2e5wMl3TdwztUB1wKYrxixIXiL38u+pWaWG2xNywXKBid86Q/nHM8tL+X/nv2I9RWNzBmbzh/PncL0/NRQhyYispthk6hlJAaoamwNdRgiIhK+FgATzGwMsBWYB3yq+wZmlgo0OefagOuA151zdWa2t32fAj6Db437DPDkIXgvh7WOzi4qGtoorWvxt/pWyoKPV26rZ+nWWsZnJ3LfNUWcMilbVRpFZEgaNolaWnyArdW1oQ5DRETClHOuw8xuAp7Dl9i/zzm33MxuCK6/B5gC/MXMOvGFQj63t32Dh74NeNjMPgdsBi47lO/rcNLS3slvXl3Hva+vp7m9c7d1EQZZSTGMSInjfy4+ksuL8jX+TESGtGGTqGWo66OIiBwk59x8YH6PZfd0e/w2MKG/+waXVwKnDWyk0p1zjmeXbedHT69ka00z5x45ghPGZ5KTFEtOciw5yTFkJMYQGaGWMxEJH8MmUUtPiKG+pYO2ji6VzhURETlMrCmt53v/XM6/11YyeUQSD10/hzljM0IdlogMFc7B8schdwZkjAt1NPtl+CRqiX4uteqmNnKSY0McjYiIiAymupZ27nxxDX9+ayPxgUi+f8E0rjy2QN0ZpXf1pfD+n2HUsTB2bqij6Vt7C9RthagYSM6D/Rk/2VgBTVWQOgqi4/q3T0sdVK2D9mbIK4KowIHFPVR1dcLTX4NFf4KoWJj7LTj+yxAZHerI+mXYJGoZ3Sa9VqImIiIyPHV0dvHwwmJ+/sIqKhvbmHdMAd88axLpCcPsC6YMjK5OWPAHePmH0Frnl00+D876MaQVhiamznbY8i5sXwa1W6C2eNd9Q+mu7RKyIO9oGDkL8mb5+4Rga3FrPZQshpL3Yev7/r5m8659k0b695c+xt+nFUJ0PFSth8q1ULkOKtfs/nqBJBh/Kkw8GyacCQmZg38uelrzArzzG59UJedCUi4kj4SkEf49JY+E2OT+HaujFR67HlY8Acfd5M/PS9+H5Y/BBb+CkUft+xgttRAVF7IEdtgkaundEjUREREZXpxzvLq6nP+dv5LVpQ0UjU7jj9fM5sj8lFCHJkPV1kXwr6/Ctg9h7Mlw1v/AqmfgjZ/BXbN9y8pJX4NAwuDH0lQFa1/0r7/2JWgNFsCLioWUfEgZ5ZOj1AL/vK3RJ2BbF8Hq59g5LWPqaN9aVr6q27ICn9Ad83lIzPYJSdUGqN4I616B+pLdY4nPhIzxMP4M3xUwYzxYBKx9wb/WiicBg/xjYOJZMP50yJoM0YPYEFK5Dp79T1jznD8XgUTY9G9oqdlz2yMvg9O/Dyl5fR+vtQH+fhWsfwXO/DEcf5NfvvKf8PQ34HenwnFfgpO/DYEecydWrYePnva3ze/4hHXWp+Hoa31r5SFkzoVmTs2ioiK3cOHCATvemtJ6zvjF6/zyiqO4YMbIATuuiIgcPDNb5JwrCnUc4WKgr5HhbkVJHf8zfyVvrq2gMCOeW8+ZzFnTRqisvvSuuRpe+iEsvA8Sc+Ds/4Fpl+zqRlhXAi98F5Y+7FtpzvgBHHnp/nUz7I/y1bDqaZ/8bHkXXBckZMPEM32r1ahjfavZvl63pQ62Ld6VuHW07mphy5u175av9mafvLU1QPpYiEvre1vnfGK7+jlY/axvqQOfyKWN8Qlb1qTg/URIKfDnu7EMGsqgsdzfGsqgvcm/xwln+GSyr/f2+k93taLN/Q849oZdLVhtTdCwHeq2Qf02KPkA3vsdRET6JPu4L++ZQDZVwf2X+W0v+BUcdeXu65tr4MXv+u6QqaPh/Dv8OdmRnJWt8NvlHOkT1bIV/lwATDwHZl8HY08ZsM/L3q6P4ZuotTX6JuOcaRCTSGVDK0f/6EW+d/5UrjlhzMAFKiIiB02J2v5RouaV1rVw+3OreOT9YlLiorn51AlcNWe0ioYdqDUvQPFCKPosJOX0f7/GSij/CHKnQ0zS4MV3sJprfIvJS9+HpkqY/QU45dt9d5Xb/C488x8+CRp1LBxzHRQcd+CtJs75L/UrnvS38o/88hHTfWI28Wzf3S4ijD6/9dt9y1b5Kv9+ylf5rpNdHXvZySA+AyKifJIFkDnJt8xNOB0KjofIAHz4ALz4fZ/kzbwKTvtO/z6X1Rvh+f+GlU/5BPDMH8OU833iVFcCf73Ytyhe9keY/PG+j7Px3/DPm/37AZ+MFhzv95l87u5dY2s2w8I/+nGOTZW+FfKY62DGFRCXuu+Y92J4JmprX4S/fQI+8y8YcxKdXY7x/zWfL58ynq+dOWngAhURkYOmRG3/HM6JWnNbJ6+tLmP+0u08v2I7XV3wmeNHc9MpE0iJD48CAEPSu/f6pAQHkTEw62o4/mZIG933PtuXwbu/gSX/gM5WsEgYcSSMPt4nNAXHQWLWru3bmvyX+dLlPmEpXQa1W/04qe4tMZkTd325dc5/uS5dDmXL/X3pcqjeBJnju43ROtrvHxG56/Va62HT27DxddjwBmxf4lut8o+Bj//cJ5b70tUFi+/3Y9h2jNdKGeXf2+jj/Bf3rEl9t5445193R3JWuRYwGH0CTL3Qf+FPyd93HOGks913Dyz/yP/7xqf7lsHEbN9iGJ8BkVH+3FSs8d/Z177gE6POVj9WLmmEP0b+MXDOT/y/7/5a/xo8e6v/rI35GMz5Esz/pm/hu+JBGHPSvo/R3uKTr0CCby1L2EfF2I5WWP4ELPgdFC/w3VWv/Mf+x97N8EzUarfCL6bCubfD7M8DcNQPnufcI3P58cVHDlCUIiIyEJSo7Z/DLVFrbO3glVVlPLN0Oy9/VEZzeyfpCQHOmjaCG+eOoyAjft8Hkd51dcGL34G3fgWTPu5bmN67FxY/4JOa6ZfDiV/1yQj44hur5sO7v4WNb/hCCjPm+daQbYt9YrR1IXS0+O0zJkDmBP+FvGqdPyb4L+PZU3zlwuoNfv2OfWBXkYjKdbuPQ0oZ5XtLpRb41puSxbvGc0UnwMiZPtHbvtR3bXOdvnUm/xgoPNF/YS84fv9brbo6fYK4+W3Y9Ja/35G4xaX75KOrw2/nOoOPO6CjDdrqfRJbeGIwOTtv/1osDxdtTbDxTZ+4lS7z476OvPzgWhg7O2DRH+HlH/nPUXwGXPVo/wqFHKySxf7znjfroA4zPBM15+C20b5P8Xk/B+C0n73KxJwkfnPVAWTlIiIyaJSo7Z/DJVFbU1rP7c+v4tVV5bR2dJGZGMPZR+Rw7hG5zB6TrlL7B6u9BZ640Ve5O+bzvuViR4tU7VZ4+y4/Tqe9Gaac57/cLvqT7+aVMsr/EH7U1b7FpLuOVv8ldfNbPnGr3uiTtZwjIGeqv08r3L31q6sTajbt3oWubiukj/OJWc4RPrHr2Y2sq8sngDvGZ5W87/fNngKFJ/lWk/zZexaEOFjO+RafTW/58WVtjb4rX0SUf18RkbueZ0/13eVCUSVRvKYq/9mdemHYzZU2PBM1gD+c6f+DXDsfgMvveRsMHv7CcQMQoYiIDBQlavvncEjUHnu/mP96fBmx0RFcODOPc44YQVFhOpERh1GBkLptvstVf8uN74+mKl/1btO/fbGM42/uvfteYwW8e4/vGtla67vsHXsDTDrXd18TkUG1t+tjeP8PzJrsBxI6B2akJwRYV94Q6qhERESkDy3tnXz/n8t58L0tHDsmnV9dcRTZQ33+0/Wv+iqCo2bDybdC7AFOCdDV6VuGVj/jq+qVLvNdBGdcAcd+YVf3w4NVsxn+dqnvcviJP/jeR31JyIRT/x+c8BWftKWrIJvIUBHeiVr2VD8AsKEMknJITwywYKPmURMRERmKNlY08sX732fFtjq+ePI4vnbGxKHdvbF+Ozz3X7DsEV/mfesiWPqIb6GaMa9/5blb62Hdy7DqWVjzPDRV+PFMBcf5uaAq1sAHf4OFf4Bxp8KxN/rxYD3H7XR1+qIJW97zRQwaK3xrXCDBJ3s7HkfFwNt3+/FgVz/ux031R0zS0K7oKHIYCvNEbbK/L18JSTlkJASobmqjq8sRcTh1nRARERninlm6jW8+soTICOO+a4o4dfIQLrbQ1QkLfu8LFHS0wNxb4cRboGwlzP8GPHGDHw9z7k97ryzY1uTnXVr2qC+J39kKsal+PqmJZ/uErPu4rzO+7wsiLPgDPHCZH7d17Bf8vFXF7/nkbOsiPw8W+Mp6KXm+5ay9yS9va/KvA74Qx6ef2vU9SUTCUngnallT/H3ZShh7MukJAboc1DS3k54QCG1sIiIiQltHF//7zEr++O+NzByVyl2fOor8tCFcxbF4EfzrFl9yfdypvrr0juIEebPgcy/C4r/Bi9+De+dC0efg1P/yrVprX/LJ2apnoL3Rt8IVXevneBo1p+8xXwmZ8LFvwvFf8UM63vlNsJQ+wZL4R/jukaNm+1vq6N5b8zo7/OtGJ2h8mcgwEN7/ixOzfcnUspUAO5OzqsZWJWoiIiIh1tDawQ1/XcSbayu45vhCvn3ulIGbrLqjbVf1vYPVWOnLsa+a78vWJ42Ay/4EUy/aMyGKiPBlxaecDy//2HdZXPaob4VrrfXfS6ZfDkd8ws83tj/xRQX8eLIjLw2Wpa/3yWEgoX/7R0ZB5AGOnxORISe8EzUzX541OPP7juSssqGN8dmhDExEROTwVtnQyrV/WsDykjr+79LpXF40auAOvvxxePwG3y0xKi44PiseAom+ZSsmEZJG+omGU0f5+5QC310wOs53Gdz09q7y8hWr/HGjYmHOjXDyf+67EmNcGnz8dp+0vfYTiEn2ydnYuRA5ABNzj5x58McQkbAW3oka+MqPS/8BznVrUVNBERERkVAprm7i0394j601zfz2qqM5feoAjkdb/xo8dj2MmO6LbrQ3+jmu2oJjtdqboKUOKl6D+m27JmDeISYZWuuCj1Og4FhfGGT08X4esaiY/YsndzrMu39g3puISDf9StTM7GzgTiAS+L1z7rYe608GngQ2BBc95pz7wcCFuRfZU/wf3LoSMhIyAKhUoiYiIgegH9e7FOBvQAH+Gnq7c+6PZjYJ+Hu3TccC33HO3WFm3wM+D5QH133bOTd/cN9J6KzaXs+n73uX5rZO/nbdsRxTmL7vnfqrZDE8dCVkjIerHvGtWnvT2Q51JVBbDLVb/K2+FDInwujjfPXogeg6KSIyCPaZqJlZJHA3cAZQDCwws6eccyt6bPqGc+68QYhx77KDBUXKV5JWeAoA1UrURERkP/XzevclYIVz7nwzywJWmdn9zrlVwMxux9kKPN5tv184524/FO8jlBZurOKzf1pAXCCSh284jskjBnAi56r1cP+lEJcKVz267yQNfBfEtNH+JiISZvozonc2sNY5t9451wY8BFw4uGHth52VHz8iJiqSpJgotaiJiMiB6M/1zgFJZmZAIlAFdPTY5jRgnXNu02AHPJS8/FEpV/3hXTISY3jkhuMHNklrKIO/XuwLdlz1GCSPHLhji4gMUf1J1PKALd2eFweX9XScmX1oZs+Y2bTeDmRm15vZQjNbWF5e3tsm+y8hAxKydlV+TAxojJqIiByI/lzv7gKmACXAUuArzvUcBMU84MEey24ysyVmdp+Z9doUNCjXyEPk2WXb+fxfFjEhO4l/3HAco9IHsPx+Sx387RM+WbvyH5A1ceCOLSIyhPUnUett5mjX4/n7wGjn3AzgV8ATvR3IOXevc67IOVeUlZW1X4HuVfYUP+k1vvKjEjURETkA/bnenQUsBkbiuzreZWY7m47MLABcAPyj2z6/AcYFt98G/Ky3Fx+0a+QgW1vWwNcfXsyReSk8eP0cMhP3sxjH3nS0wkOfgrIVcPlfIb9o4I4tIjLE9SdRKwa619TNx/+SuJNzrs451xB8PB+INrPMAYtyX7KmQPkq6OoiIyGgro8iInIg9nm9A67FF8xyzrm1+CJak7utPwd43zlXumOBc67UOdcZbHn7Hb6L5bDQ1NbBF+9fREx0JL+5ahaJMb0MfV/7EvzuVFj74v4dvLPDV3fc+AZceDdMOH1gghYRCRP9SdQWABPMbEzwl8J5wFPdNzCzEcH++pjZ7OBxKwc62D5lT/YleWu3kBYfoKqx9ZC9tIiIDBv7vN4Bm/Fj0DCzHGASsL7b+ivo0e3RzHK7Pb0YWDbAcYeEc45vP7aUNWUN/HLeUeSmxO25UWc7zP8mbF3kuy8+8SVort73wde+CPecCCuegDN+6Mvni4gcZvZZ9dE512FmNwHP4csV3+ecW25mNwTX3wNcCtxoZh1AMzDPOdezu8jgyZ7q78s/Ij2xgKrGNpxzBHNHERGRfern9e6HwJ/MbCm+q+S3nHMVAGYWj68Y+YUeh/4/M5uJ70a5sZf1Yelv727micUlfP2MiZw4oY9ONB/8FarWwWV/hu1L4M07fBJ23i9g8rl7bl++Cp77L1j7AqQVwif/BlPOH8y3ISIyZPVrHrVgd8b5PZbd0+3xXfgB1qGRFex1UraSjITxtHc66ls7SI6NDllIIiISfvpxvSsBzuxj3yYgo5flVw9wmCH34ZYafvjPFZwyKYsvnTK+943aGuHV22DUHJh6IUy7CKZcAE9+CR66Ao64FM75CSRkQlMVvPq/sOAPEEjwrWjHfmH/J58WERlG+pWoDXlxqZCU61vUCi4FoKqhTYmaiIjIAKtubOOL979PVlIMv/jkTCIi+ui98s5voKEULv8L7OjhMnImfP4V+Pcd8Nr/wfpXYMYVvuWttR6OvhZO+bZP3kREDnP9GaMWHrKnQNkKMhICAFQ1qaCIiIjIQOrqcnz14cWU17fym6tmkRof6H3Dpir4950w6VwomLP7uqgAzP0P+MLrkDoa3r4L8orgxrfgvJ8rSRMRCRoeLWrgKz8uvI/0eP+WqhqUqImIiAyku15Zy6uryvnRRUcwPT+17w3f+Jkv8nXad/reJmcqfO4FP4Yta9KAxyoiEu6GUYvaZOhoJqtjO4DmUhMRERlAb62t4Bcvrubio/K48tiCvjes2Qzv3QszPuV7u+xNZJSSNBGRPgyjRM1XfsxoWgugudREREQGSFeX4wf/WsHo9Hh+fPERe6+q/Mr/Agan/Ochi09EZDgaPola8Be5mKrVxEZHaC41ERGRAfLs8u18tL2er54xkfjAXkZNlC6HDx+EY6+HlPxDF6CIyDA0fBK1mCRIGeUrP8YH1KImIiIyADq7HL94YTXjsxM5b/rIvW/80g8gJhlO/NqhCU5EZBgbPokaBCs/riQ9MaAxaiIiIgPg6aXbWFPWwC2nTyCyr1L8AJvehtXPwom3QHz6IYtPRGS4Gl6JWtZkqFhNZnyUEjUREZGD1NnluOPF1UzKSeLcI3L73tA5ePG7fk7TY284dAGKiAxjw6c8P/gWtc42JkaXM78iMdTRiIiIhLWnPtzK+vJG7rlq1p4TW7c1Qeky2PYhbH4HtrwL598JgfjQBCsiMswMr0QtazIAE6yYqsaxIQ5GREQkfHV0dnHni2uYmpvMmVNHQGMFfPiQT8y2L4GK1eC6/MZx6TD9kzDzqtAGLSIyjAyzRG0SYBR0bKSpbTQt7Z3ERkeGOioREZGw8/gHW9lY2cTvPl1ERGcr/O0Sn6QljYTcGTD1Qn8/Yrqv8Li3kv0iIrLfhleiFkiAtNHktm0E5lLZ2EZealyooxIREQkr7Z1d/PLlNRyZl8LpU7Lhn1/xSdq8B2Dyx0MdnojIYWF4FRMByJpCeuN6AKoaVFBERERkfz26qJgtVc187YyJ2OIH4P0/+5L7StJERA6Z4ZeoZU8hoX4D0XRQVt8S6mhERETCSltHF796eS0zR6Vycsp2ePprUHgSnPJfoQ5NROSwMiwTNXMdTIwq5bXV5aGORkREJKw8vHALW2ua+cbcEdjDn4a4NLj0PogcXqMlRESGuuGXqAUrP16UV8/8pdvp7HIhDkhERCQ8tLR3cvcrazm6IJUTlv031G6By/4EidmhDk1E5LAz/BK1zIlgEcxNK6eioZX3NlSFOiIREZGw8PDCLWyrbeFnea9hHz0NZ/wQCuaEOiwRkcPS8EvUomMhfSxj3RZioyOYv3RbqCMSEZEwYWZnm9kqM1trZrf2sj7FzP5pZh+a2XIzu7bbuo1mttTMFpvZwm7L083sBTNbE7xPO1TvZ38457j/nc18KmczoxffDlMvgjk3hjosEZHD1vBL1ACyJhNVsYrTJufwzLJt6v4oIiL7ZGaRwN3AOcBU4Aozm9pjsy8BK5xzM4CTgZ+ZWaDb+lOcczOdc0Xdlt0KvOScmwC8FHw+5KzYVkdV6Wb+u/mnWPoYuOBXmhtNRCSEhmeilj0VqtZz/rR0KhraeHdDZagjEhGRoW82sNY5t9451wY8BFzYYxsHJJmZAYlAFdCxj+NeCPw5+PjPwEUDFvEAevPN1/hHzA+Jdc1w+V8hNjnUIYmIHNaGaaI2GVwnJ2fUEBcdydNL1P1RRET2KQ/Y0u15cXBZd3cBU4ASYCnwFedcV3CdA543s0Vmdn23fXKcc9sAgve9VuYws+vNbKGZLSwvP7RVizs/eIDPrPgcqVHt2FWPQU7PhkQRETnUhmeillcEEVHEvv4/nD45k2eXbaejs2vf+4mIyOGst35+PfvOnwUsBkYCM4G7zGxH09MJzrlZ+K6TXzKzj+3Pizvn7nXOFTnnirKysvYr8APW0Qr/+iqRT97I4q5xLD73SRh93KF5bRER2avhmailjYazb4M1z/GVyH9Q2djGu6r+KCIie1cMjOr2PB/fctbdtcBjzlsLbAAmAzjnSoL3ZcDj+K6UAKVmlgsQvC8btHewP2q2wH1nw8L7eCFtHjdFfpfjZ0wLdVQiIhI0PBM1gGOug1mfZvxH93BRYAH/UvdHERHZuwXABDMbEywQMg94qsc2m4HTAMwsB5gErDezBDNLCi5PAM4ElgX3eQr4TPDxZ4AnB/Vd9Mfal+C3H4PKtTRe/Ge+VH4RH585ikDU8P1aICISbobvX2QzOPd2yJ/NTyJ/w7ql76j7o4iI9Mk51wHcBDwHrAQeds4tN7MbzOyG4GY/BI43s6X4Co7fcs5VADnAm2b2IfAe8LRz7tngPrcBZ5jZGuCM4PPQWfwg/O0TkDQCrn+Vf7bOoq2ji0tm5Yc0LBER2V1UqAMYVFEx8Mm/4u4+idubfsKClXM57oiJoY5KRESGKOfcfGB+j2X3dHtcgm8t67nfemBGH8esJNgKNyQseQgyJ8B1L0Iggcf+8TbjshKYnp8S6shERKSb4duitkPSCGze/YywajKfuQE691VFWUREZBirWg+5MyGQwObKJt7bWMUls/IxzZkmIjKkDP9EDYgpnM0/cr/OhMZFdD7/36EOR0REJDQ6WqG2GNLHAvD4B1sxg4uO6jkLgYiIhNphkagBZJ30Wf7YcRaR7/7a988XERE53NRsBtcF6WNwzvHYB8UcNzaDvNS4UEcmIiI99CtRM7OzzWyVma01s1v3st0xZtZpZpcOXIgD42MTs7gz8jOsTTgK/vkVKPkg1CGJiIgcWlXr/X36WN7fXM2myiYVERERGaL2maiZWSRwN34Cz6nAFWY2tY/tfoKvljXkxEZHcsrUPD7XeBMuIRP+cQ201IY6LBERkUOnaoO/Tx/Lo+9vJS46krOPGBHamEREpFf9aVGbDax1zq13zrUBDwEX9rLdl4FHGSoTefbi40fmsqkljg9m/9xP9PnUzeBcqMMSERE5NKrWQ0wyLdGp/OvDEs4+YgSJMcO7ALSISLjqT6KWB2zp9rw4uGwnM8sDLgbuYS/M7HozW2hmC8vLy/c31oN20sRMkmKieHBbLpz237DiCVh43yGPQ0REJCSq1kP6GF5eVU5dSwefULdHEZEhqz+JWm/1ens2Q92Bn/Szc28Hcs7d65wrcs4VZWVl9TPEgRMTFckZ03J4bvl22o79Mow/A579T9i25JDHIiIicshVrYf0sTz2fjEjkmM5blxGqCMSEZE+9CdRKwZGdXueD5T02KYIeMjMNgKXAr82s4sGIsCB9vEjc6lr6eCV1RVw8T0Qnw6PXAut9aEOTUREZPB0dkDNJpoSR/PqqnIuOiqPyAjNnSYiMlT1J1FbAEwwszFmFgDmAU9138A5N8Y5V+icKwQeAb7onHtioIMdCCdNyCI/LY67X1mLi8+AT/zB/8L4r69pvJqIiAxftVugq4P361Pp6HJcMktzp4mIDGX7TNSccx3ATfhqjiuBh51zy83sBjO7YbADHGiBqAhuPnUCS4preWFFKRSeACd/G5Y+DB/8NdThiYiIDI5gaf53alIYk5nAxJykEAckIiJ706951Jxz851zE51z45xzPw4uu8c5t0fxEOfcNc65RwY60IF0yaw8CjPi+fkLq+nqcnDS12DMXJj/H1C6ItThiYiIDLxgoramPZuc5JgQByMiIvvSr0RtuImKjOArp0/go+31zF+2DSIi4ZLfQUySn19N49VERGS4qd4IUXGsa0kkPSEQ6mhERGQfDstEDeCCGXmMz07kjhfX0NnlICkHPvE7qFgNd86EN34OLXWhDlNERGRgBCs+Vje1kxavRE1EZKg7bBO1yAjjq6dPZG1ZA099uNUvHHsyfO55GDkTXvo+3HEEvPK/0FQVylBFREQOXtV6XPoYqpvayFCLmojIkHfYJmoA5xwxgskjkrjzxTV0dHb5haNmw1WPwudfgcKT4LXb4I4j4YXvQsOhn6RbRETkoHV1QdUGWpMK6XKQpkRNRGTIO6wTtYgI42tnTGRjZROPvb9195V5s2De/XDjWzDxLPj3nT5hW/JwaIIVERE5UPUl0NlKfXw+gMaoiYiEgcM6UQM4Y2oO0/NTuPOlNbR1dO25Qc40uPQ+uGkBjDwKnvwSbHnv0AcqIiKDzszONrNVZrbWzG7tZX2Kmf3TzD40s+Vmdm1w+Sgze8XMVgaXf6XbPt8zs61mtjh4O/dQvidgZ8XHyhglaiIi4eKwT9TMfKva1ppm/r5wS98bZk7wLWzJefDQlVC7te9tRUQk7JhZJHA3cA4wFbjCzKb22OxLwArn3AzgZOBnZhYAOoCvO+emAHOAL/XY9xfOuZnB2/zBfi97CCZqpVEjAVRMREQkDBz2iRrA3IlZHD06jbtfXktLe2ffG8anwxUPQnszPPQpaGs6dEGKiMhgmw2sdc6td861AQ8BF/bYxgFJZmZAIlAFdDjntjnn3gdwztUDK4G8Qxf6PlRtgMgA21w6ABmJStRERIY6JWr4VrWvnzGR7XUtPPDu5r1vnD0FPvF72PYhPHUTOHdoghQRkcGWB3TvWlHMnsnWXcAUoARYCnzFObdbv3kzKwSOAt7ttvgmM1tiZveZWVpvL25m15vZQjNbWF4+wMWrqtZDWiGVTf7HSLWoiYgMfUrUgo4fn8mcsen8+tV1NLftpVUNYNLZcPp3Ydmj8MbPDk2AIiIy2KyXZT1/jTsLWAyMBGYCd5lZ8s4DmCUCjwK3OOd2TMb5G2BccPttQK8XDufcvc65IudcUVZW1oG/i95UbfBzqDW2ER+IJDY6cmCPLyIiA06JWjdfP3MSFQ2t/OLF1fve+IRb4MjL4OUfwkdPD3psIiIy6IqBUd2e5+Nbzrq7FnjMeWuBDcBkADOLxidp9zvnHtuxg3Ou1DnXGWx5+x2+i+Wh49zOya6rGttUSEREJEwoUevmmMJ0rppTwL2vr+fZZdv2vrEZXPArGDkLHrseSlccmiBFRGSwLAAmmNmYYIGQecBTPbbZDJwGYGY5wCRgfXDM2h+Alc65n3ffwcxyuz29GFg2SPH3rqEM2hshbQxVTUrURETCRVSoAxhq/vu8qSzdWsc3/rGECTlJjMtK7Hvj6DhfCfLeU+DBeXDad/wFsWE71G+H+m3+vqEUMibA9E/CEZdAQuahe0MiItIvzrkOM7sJeA6IBO5zzi03sxuC6+8Bfgj8ycyW4rtKfss5V2FmJwJXA0vNbHHwkN8OVnj8PzObie9GuRH4wiF8WzsrPqpFTUQkvJgLUTGMoqIit3DhwpC89r6U1DRz3q/eJDMxwONfPIGEmH3ks8WL4I/nQGerfx4ZgKQRkJQLiTmQkOXnXitdChYJ40/zSdukcyEQP/hvSEQkxMxskXOuKNRxhIsBvUZ+cD88+UX48vuc+PtNzC5M5+efnDkwxxYRkYOyt+ujWtR6MTI1jl/OO4pP3/cutz62lF/Om4nv1dKH/KPhKx9Cc7VP0OLSfNfInkqXw5KHYekj8OjnIJAIk8+DE272E2uLiIgMtOoN/kfC1AKqG9eQphY1EZGwoDFqfThxQiZfP3MS//ywhD+9tXHfOyTnQs5UP9daX0ldzjQ44/twy1K45mnfDXLVM/DHc6HsowGNX0REBPBdH1MLaOmKoLGtU10fRUTChBK1vbhx7jhOn5LDj59eycKNVQN34IgIKDzRFyP5wmsQFQN/uwRqiwfuNUREBkLXPqYrkaEvWPGxuqkNQImaiEiYUKK2FxERxs8un0FeWhxfeuB9yutbB/5F0sfAVY9Caz389WJoGsCEUESGD+egfNWuwhCDqaMVVj0Lj30BfjYJWmoH/zVlcDgHlbtK84MmuxYRCRdK1PYhJS6ae646mtrmdm564H06OrsG/kVGHAlXPATVm+D+y6CtceBfQ0TCT2OFH9P6xJfgF9Pg7tnwqyJ49SfQ2TGwr9U9OfvpeHjwk7D6WZhwlv4mhbPmamithfQxOxO1jEQlaiIi4UDFRPphSm4y/3vJkXz17x9y80MfcPtlM4gPDPCpKzwBLr0PHr4aHv60T9wiowf2NURk6HLOT+mxfSlsfhvWvQzbPvTrYlNh7FwY+02/7tX/8esvuRfSRu//a3W0Qs0WX2SiagNsXeTHy7bW+teacgFMuwjGzIUofakPaz1K84Na1EREwoUStX66+Kh8Khva+J/5K9lQ0cS9Vx/NqPQBLq0/5Tw47w74583wxBfh4t/68WwiMrx0tELFGp+UlS6D7Utg+zJoDnZ9joiCUcfCKf8Pxp0KI2dCRKRfV3QtjD8Dnv4a3HMifPznMP2yvl+rpda3lG160ydl1RuD42G7Tc0SmwpTzldyNhx1T9RWB1vUNEZNRCQsKFHbD9edNJbx2Yl8+cEPuOCuN/n1lUdz3LiMgX2Roz8DjWXw8o/8xNhn/Y+vItnR6r9c1WzyXSRrNvsvYF0dfrB/Vwe44H1XBySOgMnnwugT9aVLJBTqt/sxZTXB/687/t/WbPLrdiRKUbGQPcX/UJNzJIw4wneHjknq+9jTL4NRs+Gx6+Gx62DtC3DuTyE2xa9vqoKPnoYVT8L6V6GrHeLSIWM8jD4e0gohbYwfI5s2BhKz+65WK+Gtaj1gkDqa6sZNRBgkx6m3hohIOFCitp9OnpTNUzedyOf/spCr/vAu3zlvKp8+bvTe51nbXyd9AxrK4Z1fw8Y3/DiV+m27b2OREJcKEdH+1/eIiOB9lF+39iVY8DuISYGJZ8Hkj8P40yEmceDiFBkOWupgy7vQ2eYTne63QFL/WrWdg8q1sOkt2PwObH7Lt1ztYBGQnA+pBb6FLLXAJ00jjoT0cRB5AH+K00b7aT7e+Bm89hPfJfKY6/z//Y1v+h9uUgtgzg0w5ULIO1ot9Iejqg2Qkg/RsVQ1tZEaHyAyQkm5iEg4UKJ2AMZkJvD4F4/nq39fzHefWs6Kkjp+cNE0YqIiB+YFzODs23xL2NYPYMR0/4UrtQBSR/v7pNy9f7lrb4Z1r/hf1VfNh6UPQ2SM/5I4+VyftCWP3HcsTVWw/HE/UXfpckgd1e2X+MJdj1MLBm5MXXMNfPA3H3tCJmSM819mM8ZB+lhIzNGv/wOpo9UXjajZDEde5idtH8462mDrQt/StP5VKF7ok5peGcQm+x88YpKCj5N2v1Vt8MlZU4XfJT4TCubAMZ/3iVjaaEjOG5wxp5FRcPK3YNwp8Oh18MJ3fAJ44i1+nFnuDP1fOdxVrfd/o4GqxjaV5hcRCSNK1A5QUmw0915dxC9eXM2vXl7LmrJ67rnqaLKTYwfmBSIi4MwfHfj+0XE+IZt8rq8Ot/ltn/h89C9Y/YzfJucIn7BNOMOPh9nxRbK9BdY8Bx/+HdY877tNZU2GGZ+EuhJ/4V/3MnQ073q9QCLM+gzMudEncweifBW8+1v48EFob/IJamOZTzS7ulW4CyT6pG3GFXDU1cOrlbCry7eifvigT7bHner/jVLyBvZ1nIOSD2DxA7DsEV8ZDuClH/hkbc4XfRe8oc45X5GwtR7aGqC1zp+3HbeOFv9Zam/x2xS/Bxv/De2NvpVr5Cw48asw5mM+CWupDd7quj2u8fu21vvjN5RB5bpdz5NGwIQzfXI2+nifKB3q5GjUbPjiO9BQ6n9AUXImO1St991qCSZqKiQiIhI2zDm3760GQVFRkVu4cGFIXnugzV+6ja8//CHJcVH85qqjmVWQFuqQ+uYclK2ANS/A2hd9AtfV4bt4jZ3riwqs/Kev/pY4Ao68FKZ/0rcMdP/y55z/Uli1wVeOW/8qLHvUrzviE3D8zf37ot/V5cfXvPMbWP+Kb/WbfhnM/gLkTvfbdHZA7RaoWufnA6pa71tEihf4eI+5Do79gh9nE65qNvukafH9/nFMCgQSoL7Er8+eCuNP80UkCub4SdIPRP123zq6+AEoX+nHR03+OMz8lG+tfe9e35rZ3uSLShx3k08UD7TLXEeb/wFgb4lDZwfUFe/6LFVt8P/e7S2+O2JnG3S2d7tv3ZWctdazW1GMfcmYAGNP9rfCE333YTkkzGyRc64o1HGEiwG5RrbUwm0FcPr34cRbOPMXrzEmM4HfXq1/BhGRoWJv10clagNk5bY6rv/rQkprW/nBhdOYN7sg1CH1T0sdbHhtV+LWUuurv02/3H9Rj9iP7pw1W3zC9f6ffevGuFPhhK/44wA0lvskq2qDv6/e4JOt6o2QNBKO+RwcfY3v7tgfW96Df9/pWwojAzDzCjjuy5A5fvftnPOtInXbfAtddLx/jfhM33VtMFofKtf5VrElf/dJxY5uq2nBrquphb7lcdsS+OCvsOF1v9/YuTDzKv8LeFQslH+0699m01u+dTM6AUYdA1lTIGuSb+3MmgTx6bvH0FQVrCi4zHdbLV3qH7tOyJ/tk7NpF++ZrDRV+X/Dd3/rx0ZmTvQtl0kjfPIYSPCJ/Y7HFuELZOxItKo37nrcVOnXBxL9ttHxwf0Sfbe9mi0+KeveYhoZ489NIMH/u0YGfLLX/XEgAWKS/XG6d0MMJEIgHqLiIDrWv15UrG9h3nGTkFCitn8G5BpZshjunQuX/xWmXkDRj17kjKk5/O8lRw5IjCIicvCUqB0iNU1tfPnBD3hjTQVXzSngO+dNIxAVRoP3nfO3gy040FwNC/8I797jW92S8/2y9m6T5loEpIzyScDMT/nk8EDH8FSshbd/BYsf9K0uE8/yX+TrtvlEo3777t00u4sM+IQtIQMSsnxXuAlnQF7R/hd4aK33VfY+uN8Xk7AIn6ymjNpVrbN2i4+xu9QCn5zNvMI/7vP4Db5b5JoX/LxXFat9y9cOCdk+YYuK9YnZjtY48O8t5wjIL/ItpJkT9v1+OtpgxRPw1q98+fj+sAhfuGDH2MXkPP9+2xp98t7WCG1N/nFHq+/S2b36YPoYn7Sr6MWwo0Rt/wzINXLZY/DItXDDv3E50xj/X89ww9yxfPOsyQMTpIiIHDQlaodQR2cXP31uFb99fT3HFKZx95WzyE4aoHFr4aaj1bcorXnBf2FPH+OLgaQFi48M9LQBDWW+FWjxA75rYPJI3wqUlOtvybm+EEl7s2/da6zwBSAaK/39jsmGXZfvUjnuVJ+0jT99z26VHa3+9RrLfEK4oxR6e6MfozTzSpgxb8+CLV1d0LB9V7n25Fw/hcKBJCZdXT7xK1/lW9523He0QM604C1Y6v1guoU659/rjnFgbY27J15d7ZBS4P99U0ZpOgjplRK1/TMg18jXb4eXfwjfLqG2I8CMHzzPf583lc+dOGZgghQRkYO2t+ujiokMsKjICP7z3ClMy0vhPx75kAt+9W/uufpoZo5KDXVoh15UDMz6tL8dConZcNp/+9uBaq721TLXvuhvyx/zy0dM993qGsv81AmttbvvF0jy4/mOugryj+m7O2VEhE/ekkf6sWYHIyLCd6VMGw0Tzzy4Y+2NGSTl+JuIhI/qDX6scSCBqjrfoyE9QXOoiYiECyVqg+SCGSMZn5XI9X9dyOX3vM1/nD2JTx9XGF5dIQ9HcWlwxCX+1tXlx3WtecEXS3FdvoVqXLbvZpiY5VvoErL9hMWB+FBHLyKyS9UG34sBqGpsBSBNVR9FRMJGvxI1MzsbuBOIBH7vnLutx/oLgR8CXUAHcItz7s0BjjXsTB2ZzD9vOpGv/+NDfvT0Sh54dzP/9fEpnDo5e2AnyJbBERHh56HKnQEf+0aooxGRQ6Af17sU4G9AAf4aertz7o9729fM0oG/A4XARuBy51z1oL+ZqvUw7jT/sLEdgIyEA6wYKyIih9w+m3fMLBK4GzgHmApcYWZTe2z2EjDDOTcT+Czw+wGOM2ylJQT4w2eKuO+aIjD43J8XcvUf3uOj7XWhDk1ERLrp5/XuS8AK59wM4GTgZ2YW2Me+twIvOecm4K+Xtw76m2lr9ONug5NdVzf6IkZp6vooIhI2+tMPbzaw1jm33jnXBjwEXNh9A+dcg9tVlSSB/ZrYaPgzM06dnMNzt3yM750/laVbazn3zjf49uNLqWhoDXV4IiLi7fN6h7++JZnvFpEIVOF7kuxt3wuBPwcf/xm4aFDfBfhpMmBnolYZTNTSE9T1UUQkXPQnUcsDtnR7Xhxcthszu9jMPgKexreq7cHMrjezhWa2sLy8/EDiDWvRkRFcc8IYXvvmyXz6uEIeXrCFU376Kr9+dS1NbR37PoCIiAym/lzv7gKmACXAUuArzrmufeyb45zbBhC877UM64BeI6vW+/vgGLXqpjZioyOID2houohIuOhPotbbYKo9Wsycc4875ybjfyn8YW8Hcs7d65wrcs4VZWVl7Vegw0lqfIDvXTCNZ2/5GLPHpPN/z65i7k9f5S9vb6StoyvU4YmIHK76c707C1gMjARmAneZWXI/992rAb1G7kjU0nyLWlVjG+kqJCIiElb6k6gVA6O6Pc/H/5LYK+fc68A4M8s8yNiGvfHZifzhmmN45IbjGJOZwHeeXM6pP3uVRxYV09ml3qMiIodYf6531wKPOW8tsAGYvI99S80sFyB4XzYIse+uaj3EZ0Bcqn/a2EZ6ohI1EZFw0p9EbQEwwczGmFkAmAc81X0DMxsf7K+Pmc0CAkDlQAc7XBUVpvP36+fwl8/OJi0+wDf+8SFn3fE6zy7bRqgmJBcROQzt83oHbAZOAzCzHGASsH4f+z4FfCb4+DPAk4P6LmC30vzgEzWV5hcRCS/77KzunOsws5uA5/Alh+9zzi03sxuC6+8BPgF82szagWbgk04Zxn4xMz42MYuTJmTy7LLt3P78Km742/tMyU3muhPHcP6MkZqDTURkEPXzevdD4E9mthTf3fFbzrkKgN72DR76NuBhM/scPtG7bNDfzGV/gpaanU+rGtsYnaG5HkVEwomFKp8qKipyCxcuDMlrh4POLscTH2zlt6+vY3VpA9lJMXzm+EKuPLaAVP0qKiJhxswWOeeKQh1HuBjoa+SR332OS4vy+e750wbsmCIicvD2dn1U+achKjLC+MTR+VwyK4/X11Tw+zfW89PnVnHXy2u5rCifz54whsLMhFCHKSIiQ1xbRxf1rR0qJiIiEmaUqA1xZsbciVnMnZjFR9vr+MMbG3jovS389Z1NzJ2YxQUzRnLG1BySYjWJqYiI7Km6acdk10rURETCiRK1MDJ5RDI/vWwG3zx7En99exOPvb+Vrz38IYGoCE6ZlMV500dy2pRszZMjIiI7VQUnu85QoiYiElb0jT4MZSfF8vUzJ/G1Myby/uYa/rWkhKeXbOO55aXERUdy2pRsLpqZx8mTsoiKVAESEZHD2Y5ETS1qIiLhRYlaGDMzjh6dxtGj0/h/H5/Kgo1V/PPDEp5Ztp1/LdlGbkos844pYN7sUeQkx4Y6XBERCQG1qImIhCclasNEZIQxZ2wGc8Zm8L0LpvHSyjLuf3cTv3hxNb98eQ1nTMnhyjkFnDAuk4gIC3W4IiJyiGiMmohIeFKiNgxFR0Zw9hEjOPuIEWysaOTBBZv5x8Jinl2+ndEZ8Vx2dD6nTM5mam4ywXnKRURkmKps8IlaapyKTomIhBMlasNcYWYC/3nOFL52xkSeXbad+9/ZzO3Pr+b251eTkxzDyROzOXlSFidMyCRZlSNFRIad6qY2UuOjNWZZRCTMKFE7TMRERXLhzDwunJlHWX0Lr60q59VV5cxfto2/L9xCVIQf73bypGzmTsxiSm6SWttERIaBqsY2zaEmIhKGlKgdhrKTYrmsaBSXFY2io7OL9zfX8OqqMl5ZVc5Pnv2Inzz7EdlJMZw0IYu5k7I4aXymxjaIiISpqsY2/Q0XEQlDStQOc1GREcwek87sMen8x9mTKa1r4fXV5by2upyXPirl0feLMYPp+ak7J96eOSqVSBUkEREJC1WNbYxKjw91GCIisp+UqMlucpJ3tbZ1djmWFNfw2upyXl9dzl0vr+GXL60hJS6aEydkMndiFidPzCJbpf9FRIasqsY2ZuSnhjoMERHZT0rUpE+REcZRBWkcVZDGLadPpKapjTfXVvDqKt/i9vSSbQBMyU3mYxMzOX5cJscUphEf0MdKRGQocM5R3dRGeqK6PoqIhBt9o5Z+S40PcN70kZw3fSTOOVZuq+e11eW8trqMP7yxgd++tp6oCGPGqFSOH5fBcWMzmDU6jdjoyFCHLiJyWGpo7aC906mYiIhIGFKiJgfEzJg6MpmpI5O58eRxNLV1sHBjNW+vr+StdZXc/cpafvXyWgJREczMT2VKbhKTRiQzaUQiE3KSNBWAiMghUNWoya5FRMKVEjUZEPGBKD42MYuPTcwCoL6lnQUbq3h7XSULN1XzyKJiGts6d24/MiWWSSOSmJybzEkTMjmmMJ1ozfEjIjKgdiRqGUrURETCjhI1GRRJsdGcOjmHUyfnANDV5dha08zq0no+2l7P6tJ6Vm2v5821Ffzm1XUkxfhE75TJfgLuzMSYEL8DEZHwpxY1EZHwpURNDomICGNUejyj0uM5bUrOzuUNrR28uaaCVz4q4+VVZTy9dBtmMCM/lVMmZXP06DSOzE8hJU5dJUVk8JnZ2cCdQCTwe+fcbT3WfxO4Mvg0CpgCZAVvf++26VjgO865O8zse8DngfLgum875+YP2pvoZkeipjFqIiLhR4mahFRiTBRnHzGCs48YQVeXY3lJHS8Hk7ZfvLh653aFGfFMz09len4K0/NTOSIvWdUlRWRAmVkkcDdwBlAMLDCzp5xzK3Zs45z7KfDT4PbnA191zlUBVcDMbsfZCjze7fC/cM7dfijeR3fVTcFETVUfRUTCjr7pypAREWEcmZ/CkfkpfOX0CdQ2tbNkaw1LimtZUlzDgo1VPPVhid/WYGJOEjPyU5lZkMqM/FQm5iQSpXFuInLgZgNrnXPrAczsIeBCYEUf218BPNjL8tOAdc65TYMS5X6obGwjEBlBQkDVd0VEwo0SNRmyUuKjOWlCFidNyNq5rKy+haXFtXxYXMuHW2p4bsV2/r5wCwBx0ZEcmZfCjFEpzBjlk7f8tDjMLFRvQUTCSx6wpdvzYuDY3jY0s3jgbOCmXlbPY88E7iYz+zSwEPi6c6764MPdt+rGNtITAvo7KCIShpSoSVjJTorltCmxO8e5OefYXNXE4i01LN5Sw4dbavjz25toe2MDAOkJAabnpzAjP5UZo3y3SRUqEZE+9JbNuD62PR/4d7Db464DmAWAC4D/7Lb4N8APg8f6IfAz4LN7vLjZ9cD1AAUFBfsbe6+qGttVSEREJEwpUZOwZmaMzkhgdEYCF87MA6Cto4vVpfUs3lLDkuIaPtxSy2ur1+CCX7dS46MZHSxsMjojntHpCRRk+McjkmP1y7PI4asYGNXteT5Q0se2vbWaAZwDvO+cK92xoPtjM/sd8K/eDuicuxe4F6CoqKivBHG/VDW2kp6gYkwiIuFIiZoMO4GoCI7IS+GIvBRgNACNrR0s21rL0q21bKhoZHNVE0uKa3lm2XY6u3Z9H8pOimHO2AzmjM3guHEZFGbEK3ETOXwsACaY2Rh8MZB5wKd6bmRmKcBc4KpejrHHuDUzy3XObQs+vRhYNpBB7011Uzt5afGH6uVERGQAKVGTw0JCTBTHjs3g2LEZuy1v7+yipKaZzVVNbKhoZOHGat5eX7mzaMmI5FjmjE1nztgMpo5MZnRGgqYKEBmmnHMdZnYT8By+PP99zrnlZnZDcP09wU0vBp53zjV23z84bu0M4As9Dv1/ZjYT3/VxYy/rB01lQyvp8fqbJSISjpSoyWEtOjJiZ9fJkyZk8enjCnHOsb6ikXfWV/L2ukreXFvJE4t39X5KTwgwOiOewowERmfEMyYzgfy0OPJS48lOiiEiQi1wIuEqOL/Z/B7L7unx/E/An3rZtwnI6GX51QMaZD+1d3ZR19JBeoLG5YqIhCMlaiI9mBnjshIZl5XIlceO3pm4rS1rYGNFIxsrm9hU2ch7G6p4YvHWnWPfAKIjjdyUOPJS48hL8/djMhOYkOOPFxutEtkicmjUNLUDaIyaiEiYUqImsg/dE7eeWto72VLVRHF1M8U1zWytbmZrTTMlNc28uaaC0vqWnYlchMHojAQmZCcyaUQSE3KSGJuZQF5qHKnx0RoLJyIDqqrRT3atqo8iIuFJiZrIQYiNjmRCjk+6etPW0cXGykZWl9azurSB1dvrWV1Wz4srS+lWw4T4QORurXB5aXGMy0pk5qhUcpJjD9G7EZHhZEeilq5ETUQkLClRExlEgagIJuYkMbFHItfS3sn68kY2VzVSHGyF29Eat3hLzc4uSwA5yTHBeeD8JN5H5qeooImI7JMSNRGR8NavRM3MzgbuxFfB+r1z7rYe668EvhV82gDc6Jz7cCADFRlOYqMjmToymakjk3td39DawerSej4MTuK9pLiW51fsnIqJvNQ4X8AkLY78YAtcflo8ealxjEiJ1Vg4EaGqKZioxStRExEJR/tM1MwsErgbX3K4GFhgZk8551Z022wDMNc5V21m5+An7Dx2MAIWORwkxkQxqyCNWQVpO5fVNrWzZKtP3NaWNbC1ppm311VSWteyWzdKgKSYKDISA2QkxpCR4O8zEwNkJ8UwslsXy6RYtcyJDFfVGqMmIhLW+tOiNhtY65xbD2BmDwEXAjsTNefcW922fwfIH8ggRQRS4qM5aUIWJ03I2m15e2cX22tbfEGT6iZK61qoaGijsrGNyoZWNlU28f7maqoa2/ZI6JJjo8gLtsSNzohn2shkjshLYWxmAlGREYfw3YnIQKtqbCMpNopo/V8WEQlL/UnU8oAt3Z4Xs/fWss8BzxxMUCLSf9GREYxKj2dUejy9TOG0U2eXo7KhdbfqlDvut1Q18caaclo7ugCIjY5gSm4yR4xMYdrIZKbkJpOXFkdGQkDVKUXCRFVjGxlqTRMRCVv9SdR6+1bmelmGmZ2CT9RO7GP99cD1AAUFBf0MUUQGQmSEkZ0cS3Zy7G5dKnfo6OxifUUjy7bWsmxrHctLann8g6389Z1NO7cJREUwMiWW3JQ4RqbGMTI1lpHB8XKj0uIZmRpHIEq/3osMBVWNber2KCISxvqTqBUDo7o9zwdKem5kZtOB3wPnOOcqezuQc+5e/Pg1ioqKek32RCQ0oiJ3Vai8ZJZf1tXl2FzVxKrSerbVNFNS20JJTTPbalt4a13FHuPjIgxGJMeSnx7PqLR4RqX7hC4vNY7cFJ/UqdCJyKFR1dhGboqm9xARCVf9SdQWABPMbAywFZgHfKr7BmZWADwGXO2cWz3gUYpISEREGIWZCRRmJvS6vqOzi+11fnzc5qomiqua2FLtu1K+ubac0rrWPfbJSAiQm+pb5TITY8hK3FHsJIaMxEBwWQzJcVHqZilyEKqb2pjWR2VZEREZ+vaZqDnnOszsJuA5fHn++5xzy83shuD6e4Dv4AfH/Dr4xarDOVc0eGGLyFAQFRlBflo8+WnxzBm75/i4lvZOSuta2FrTzLaaFrbVNrM1eL+5sokPNldT2diG66V9PTEmivzgtAP+Po5R6f5xXmocKXHRSuRE+uCco7KxTXOoiYiEsX7No+acmw/M77Hsnm6PrwOuG9jQRCTcxUZHMjojgdEZvbfIgS9yUtXYRmVjKxX1/r6srpWtNb6KZXF1E2+vq6CxrXO3/eIDkTu7U44MjpnLTY0lJzmWrMQYspJiSE8IEBmhZE4OP01tnbR1dGmMmohIGOtXoiYiMlgiI4ysJJ9YMaL3bZxz1DS1s6W6iS1VzWyrbaakZsd4uWZWbqunomHPbpYRBhnBrpQ7XiMraffnmcHHybHqainDR1VwDjW1qImIhC8laiIy5JkZaQkB0hICTM9P7XWb1o5OSmtbKatvoby+lfKGVn8fvJXVt7K6tJ7y+lY6ek4oB8RERZCTHEtOcgzZybHkJPnHOcmxZCfHkB18nhijhE6Gvp2JWrwSNRGRcKVETUSGhZioSAoy4inIiN/rdl1djtrmdip2JHINvqtleUMrpXUtlNa1sLKkjlfqymjq0d0SfJfLnORYspN8QpedFBN87JM5/zxWxVAkpKqagolaohI1EZFwpURNRA4rERG7Wucm5CTtdduG1g6217ZQVt9CWZ1vrSut8wldWV0rS4prKKtrpbl9z4QuEBVBenyA5LgokmOjSYqNIjkumuTY6J3L0uIDpMT7+9T4aFLjokmND2guOjloVQ1qURMRCXdK1ERE+pAYE8X47ETGZyf2uY1zjsa2TsrqWigLdrH0XS1bqGlsp67F3yoa2lhf0Uh9Swd1ze29dr/cITMxwJTcZKaOTGZqbjLTRqYwJjNBhVGk36qDLWoqJiIiEr6UqImIHAQzIzEmisSsRMZm9Z3QdbcjuatpaqOmqd3fmtuobmqnprGNLdVNLC+p4743N9De6RO62OgIJo9IZnRGPIHICKKjIghERhCIiiA60oiOjCA+EElWsOvljqIpqfGaxmB/mNnZwJ346Wh+75y7rcf6bwJXBp9GAVOALOdclZltBOqBTrpNU2Nm6cDfgUJgI3C5c656MN9HVWMbURFGcqwu8yIi4Up/wUVEDrGdyV1MFPlpfW/X1tHFuvIGlpfUsaKkjuUltby/uZqOTkd7ZxdtHV20dzraOrvo7KOFLjrSyEqMISM4ifjObpix0SR164aZHuwOmhYfTVpCgKTDsGiKmUUCdwNnAMXAAjN7yjm3Ysc2zrmfAj8Nbn8+8FXnXFW3w5zinKvocehbgZecc7eZ2a3B598axLdCVWMbaQmBw+7fUERkOFGiJiIyRAWiIpiSm8yU3GQ4eu/bdnY5Gts6qOhW5bJ79cvKhlbqWzpYV99AXXMH9S3te8xN113UjrF88dH8+bOzyU2JG+B3NyTNBtY659YDmNlDwIXAij62vwJ4sB/HvRA4Ofj4z8CrHIJETePTRETCmxI1EZFhIDLCfKGS2Oh+d8Hs6OyivqWD2uZ2qpvaqG5qo6qxnerGtm7P20iIOWwuFXnAlm7Pi4Fje9vQzOKBs4Gbui12wPNm5oDfOufuDS7Pcc5tA3DObTOz7D6OeT1wPUBBQcHBvA9mjEpl3F7GVoqIyNB32Fx9RURkd1GRETsrYBaSEOpwhoLe+gn2VfXlfODfPbo9nuCcKwkmYi+Y2UfOudf7++LBxO5egKKior6rzfTDl04ZfzC7i4jIEKAa0CIiIl4xMKrb83ygpI9t59Gj26NzriR4XwY8ju9KCVBqZrkAwfuyAYxZRESGKSVqIiIi3gJggpmNMbMAPhl7qudGZpYCzAWe7LYswcySdjwGzgSWBVc/BXwm+Pgz3fcTERHpi7o+ioiIAM65DjO7CXgOX57/PufccjO7Ibj+nuCmFwPPO+cau+2eAzwerLIYBTzgnHs2uO424GEz+xywGbhs8N+NiIiEOyVqIiIiQc65+cD8Hsvu6fH8T8CfeixbD8zo45iVwGkDGaeIiAx/6vooIiIiIiIyxChRExERERERGWKUqImIiIiIiAwxStRERERERESGGHPuoObUPPAXNisHNh3kYTKBigEIZzjSuembzk3vdF76pnPTu/05L6Odc1mDGcxwomvkoNO56Z3OS990bnqn89K3/p6bPq+PIUvUBoKZLXTOFYU6jqFI56ZvOje903npm85N73Rehjb9+/RN56Z3Oi9907npnc5L3wbi3Kjro4iIiIiIyBCjRE1ERERERGSICfdE7d5QBzCE6dz0TeemdzovfdO56Z3Oy9Cmf5++6dz0Tuelbzo3vdN56dtBn5uwHqMmIiIiIiIyHIV7i5qIiIiIiMiwo0RNRERERERkiAnbRM3MzjazVWa21sxuDXU8oWRm95lZmZkt67Ys3cxeMLM1wfu0UMYYCmY2ysxeMbOVZrbczL4SXK5zYxZrZu+Z2YfBc/P94PLD/twAmFmkmX1gZv8KPtd5Acxso5ktNbPFZrYwuEznZojR9XEXXR/7pmtk73R93DtdH3s3WNfHsEzUzCwSuBs4B5gKXGFmU0MbVUj9CTi7x7JbgZeccxOAl4LPDzcdwNedc1OAOcCXgp8TnRtoBU51zs0AZgJnm9kcdG52+AqwsttznZddTnHOzew2N4zOzRCi6+Me/oSuj33RNbJ3uj7una6PfRvw62NYJmrAbGCtc269c64NeAi4MMQxhYxz7nWgqsfiC4E/Bx//GbjoUMY0FDjntjnn3g8+rsf/YclD5wbnNQSfRgdvDp0bzCwf+Djw+26LD/vzshc6N0OLro/d6PrYN10je6frY990fdxvB31uwjVRywO2dHteHFwmu+Q457aB/2MMZIc4npAys0LgKOBddG6And0XFgNlwAvOOZ0b7w7gP4Cubst0XjwHPG9mi8zs+uAynZuhRdfHfdNntgddI3en62Of7kDXx74MyvUxagADPJSsl2WaZ0B6ZWaJwKPALc65OrPePj6HH+dcJzDTzFKBx83siBCHFHJmdh5Q5pxbZGYnhzicoegE51yJmWUDL5jZR6EOSPag66PsF10j96Tr4550fdynQbk+hmuLWjEwqtvzfKAkRLEMVaVmlgsQvC8LcTwhYWbR+AvQ/c65x4KLdW66cc7VAK/ix3Ec7ufmBOACM9uI7zJ2qpn9DZ0XAJxzJcH7MuBxfDc7nZuhRdfHfdNnNkjXyL3T9XE3uj7uxWBdH8M1UVsATDCzMWYWAOYBT4U4pqHmKeAzwcefAZ4MYSwhYf5nwT8AK51zP++2SufGLCv4SyFmFgecDnzEYX5unHP/6ZzLd84V4v+uvOycu4rD/LwAmFmCmSXteAycCSxD52ao0fVx3/SZRdfIvuj62DtdH/s2mNdHcy48e0SY2bn4vrKRwH3OuR+HNqLQMbMHgZOBTKAU+C7wBPAwUABsBi5zzvUcUD2smdmJwBvAUnb1p/42vg/+4X5upuMHtkbif7B52Dn3AzPL4DA/NzsEu3Z8wzl3ns4LmNlY/K+E4LvNP+Cc+7HOzdCj6+Muuj72TdfI3un6uG+6Pu5uMK+PYZuoiYiIiIiIDFfh2vVRRERERERk2FKiJiIiIiIiMsQoURMRERERERlilKiJiIiIiIgMMUrUREREREREhhglaiIiIiIiIkOMEjUREREREZEh5v8DrT3/oCGVctcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(history_lnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MiniVGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 170s 91ms/step - loss: 0.5649 - accuracy: 0.8102 - val_loss: 0.3942 - val_accuracy: 0.8581\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.3493 - accuracy: 0.8743 - val_loss: 0.2805 - val_accuracy: 0.8952\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 170s 91ms/step - loss: 0.2996 - accuracy: 0.8921 - val_loss: 0.8729 - val_accuracy: 0.8231\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.2756 - accuracy: 0.9008 - val_loss: 0.2441 - val_accuracy: 0.9093\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.2623 - accuracy: 0.9045 - val_loss: 0.2499 - val_accuracy: 0.9078\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.2470 - accuracy: 0.9115 - val_loss: 0.2337 - val_accuracy: 0.9144\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.2411 - accuracy: 0.9125 - val_loss: 0.2243 - val_accuracy: 0.9182\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 170s 91ms/step - loss: 0.2305 - accuracy: 0.9161 - val_loss: 0.2134 - val_accuracy: 0.9217\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 170s 91ms/step - loss: 0.2263 - accuracy: 0.9182 - val_loss: 0.2202 - val_accuracy: 0.9204\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.2203 - accuracy: 0.9210 - val_loss: 0.2112 - val_accuracy: 0.9251\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 170s 91ms/step - loss: 0.2134 - accuracy: 0.9224 - val_loss: 0.2077 - val_accuracy: 0.9241\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.2089 - accuracy: 0.9236 - val_loss: 0.2041 - val_accuracy: 0.9266\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 169s 90ms/step - loss: 0.2078 - accuracy: 0.9242 - val_loss: 0.2060 - val_accuracy: 0.9247\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 168s 90ms/step - loss: 0.2013 - accuracy: 0.9271 - val_loss: 0.2049 - val_accuracy: 0.9248\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 174s 93ms/step - loss: 0.2002 - accuracy: 0.9277 - val_loss: 0.2001 - val_accuracy: 0.9271\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 173s 92ms/step - loss: 0.1988 - accuracy: 0.9272 - val_loss: 0.2047 - val_accuracy: 0.9239\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 168s 89ms/step - loss: 0.1941 - accuracy: 0.9295 - val_loss: 0.2021 - val_accuracy: 0.9252\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 179s 95ms/step - loss: 0.1925 - accuracy: 0.9296 - val_loss: 0.2004 - val_accuracy: 0.9264\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 176s 94ms/step - loss: 0.1908 - accuracy: 0.9302 - val_loss: 0.1968 - val_accuracy: 0.9277\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 168s 89ms/step - loss: 0.1864 - accuracy: 0.9313 - val_loss: 0.1954 - val_accuracy: 0.9284\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 170s 91ms/step - loss: 0.1861 - accuracy: 0.9321 - val_loss: 0.2003 - val_accuracy: 0.9266\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 182s 97ms/step - loss: 0.1853 - accuracy: 0.9313 - val_loss: 0.1926 - val_accuracy: 0.9295\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 174s 93ms/step - loss: 0.1836 - accuracy: 0.9327 - val_loss: 0.1927 - val_accuracy: 0.9300\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 171s 91ms/step - loss: 0.1786 - accuracy: 0.9347 - val_loss: 0.1928 - val_accuracy: 0.9291\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 170s 91ms/step - loss: 0.1791 - accuracy: 0.9351 - val_loss: 0.1923 - val_accuracy: 0.9309\n",
      "Wall time: 1h 11min 19s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "init_lr = 1e-2\n",
    "num_epochs = 25\n",
    "opt = keras.optimizers.SGD(lr=init_lr, momentum=0.9, decay=init_lr / num_epochs)\n",
    "minivgg.compile(loss=\"sparse_categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n",
    "history_vgg = minivgg.fit(x=train_images_norm, y=train_labels, validation_data=(test_images_norm, test_labels),\n",
    "                          batch_size=32, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1080x288 with 2 Axes>,\n",
       " array([<AxesSubplot:title={'center':'loss'}>,\n",
       "        <AxesSubplot:title={'center':'accuracy'}>], dtype=object))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(history_vgg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "1875/1875 [==============================] - 184s 98ms/step - loss: 0.6208 - accuracy: 0.7833 - val_loss: 2.5979 - val_accuracy: 0.1000\n",
      "Epoch 2/25\n",
      "1875/1875 [==============================] - 181s 97ms/step - loss: 0.3776 - accuracy: 0.8641 - val_loss: 2.2313 - val_accuracy: 0.2763\n",
      "Epoch 3/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.3207 - accuracy: 0.8813 - val_loss: 0.5716 - val_accuracy: 0.8556\n",
      "Epoch 4/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.2892 - accuracy: 0.8927 - val_loss: 0.3843 - val_accuracy: 0.8663\n",
      "Epoch 5/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.2669 - accuracy: 0.9008 - val_loss: 0.3100 - val_accuracy: 0.8837\n",
      "Epoch 6/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.2496 - accuracy: 0.9058 - val_loss: 0.3415 - val_accuracy: 0.8678\n",
      "Epoch 7/25\n",
      "1875/1875 [==============================] - 181s 97ms/step - loss: 0.2340 - accuracy: 0.9125 - val_loss: 0.3085 - val_accuracy: 0.8862\n",
      "Epoch 8/25\n",
      "1875/1875 [==============================] - 179s 95ms/step - loss: 0.2203 - accuracy: 0.9171 - val_loss: 0.3051 - val_accuracy: 0.8871\n",
      "Epoch 9/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.2125 - accuracy: 0.9207 - val_loss: 0.2930 - val_accuracy: 0.8921\n",
      "Epoch 10/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.2009 - accuracy: 0.9240 - val_loss: 0.2894 - val_accuracy: 0.8934\n",
      "Epoch 11/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.1922 - accuracy: 0.9272 - val_loss: 0.2908 - val_accuracy: 0.8988\n",
      "Epoch 12/25\n",
      "1875/1875 [==============================] - 178s 95ms/step - loss: 0.1855 - accuracy: 0.9289 - val_loss: 0.2827 - val_accuracy: 0.8993\n",
      "Epoch 13/25\n",
      "1875/1875 [==============================] - 179s 95ms/step - loss: 0.1767 - accuracy: 0.9324 - val_loss: 0.2895 - val_accuracy: 0.8972\n",
      "Epoch 14/25\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 0.1685 - accuracy: 0.9357 - val_loss: 0.2869 - val_accuracy: 0.8992\n",
      "Epoch 15/25\n",
      "1875/1875 [==============================] - 179s 95ms/step - loss: 0.1635 - accuracy: 0.9379 - val_loss: 0.2933 - val_accuracy: 0.8989\n",
      "Epoch 16/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.1547 - accuracy: 0.9409 - val_loss: 0.2978 - val_accuracy: 0.9023\n",
      "Epoch 17/25\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 0.1503 - accuracy: 0.9436 - val_loss: 0.2974 - val_accuracy: 0.8988\n",
      "Epoch 18/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.1461 - accuracy: 0.9437 - val_loss: 0.3094 - val_accuracy: 0.8942\n",
      "Epoch 19/25\n",
      "1875/1875 [==============================] - 179s 95ms/step - loss: 0.1388 - accuracy: 0.9477 - val_loss: 0.3183 - val_accuracy: 0.8952\n",
      "Epoch 20/25\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 0.1352 - accuracy: 0.9475 - val_loss: 0.2958 - val_accuracy: 0.9000\n",
      "Epoch 21/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.1285 - accuracy: 0.9507 - val_loss: 0.3316 - val_accuracy: 0.8936\n",
      "Epoch 22/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.1262 - accuracy: 0.9514 - val_loss: 0.3240 - val_accuracy: 0.8959\n",
      "Epoch 23/25\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 0.1195 - accuracy: 0.9548 - val_loss: 0.3260 - val_accuracy: 0.8959\n",
      "Epoch 24/25\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 0.1161 - accuracy: 0.9552 - val_loss: 0.3346 - val_accuracy: 0.8917\n",
      "Epoch 25/25\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 0.1117 - accuracy: 0.9575 - val_loss: 0.3458 - val_accuracy: 0.8937\n",
      "Wall time: 1h 14min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "init_lr = 1e-2\n",
    "num_epochs = 25\n",
    "opt = keras.optimizers.SGD(lr=init_lr, momentum=0.9, decay=init_lr / num_epochs)\n",
    "mobilenetv2.compile(optimizer=opt,\n",
    "                    loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "history_mob = mobilenetv2.fit(x=train_images_pad, y=train_labels, validation_data=(test_images_pad, test_labels),\n",
    "                              batch_size = 32, verbose=1, epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<Figure size 1080x288 with 2 Axes>,\n",
       " array([<AxesSubplot:title={'center':'loss'}>,\n",
       "        <AxesSubplot:title={'center':'accuracy'}>], dtype=object))"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize(history_mob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fashion MNist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.6234 - accuracy: 0.7678 - val_loss: 0.4382 - val_accuracy: 0.8365\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3879 - accuracy: 0.8568 - val_loss: 0.3834 - val_accuracy: 0.8621\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3359 - accuracy: 0.8736 - val_loss: 0.3339 - val_accuracy: 0.8781\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.3051 - accuracy: 0.8863 - val_loss: 0.3243 - val_accuracy: 0.8801\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2837 - accuracy: 0.8945 - val_loss: 0.3158 - val_accuracy: 0.8840\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2678 - accuracy: 0.9004 - val_loss: 0.2921 - val_accuracy: 0.8942\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2554 - accuracy: 0.9033 - val_loss: 0.2896 - val_accuracy: 0.8946\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2440 - accuracy: 0.9074 - val_loss: 0.2790 - val_accuracy: 0.9009\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2348 - accuracy: 0.9119 - val_loss: 0.2995 - val_accuracy: 0.8886\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2257 - accuracy: 0.9168 - val_loss: 0.2720 - val_accuracy: 0.9011\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2171 - accuracy: 0.9184 - val_loss: 0.2707 - val_accuracy: 0.9013\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2106 - accuracy: 0.9213 - val_loss: 0.2740 - val_accuracy: 0.9011\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2046 - accuracy: 0.9238 - val_loss: 0.2642 - val_accuracy: 0.9048\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1998 - accuracy: 0.9262 - val_loss: 0.2650 - val_accuracy: 0.9033\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1936 - accuracy: 0.9274 - val_loss: 0.2760 - val_accuracy: 0.9008\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1886 - accuracy: 0.9293 - val_loss: 0.2606 - val_accuracy: 0.9061\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1837 - accuracy: 0.9317 - val_loss: 0.2634 - val_accuracy: 0.9080\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1790 - accuracy: 0.9326 - val_loss: 0.2784 - val_accuracy: 0.9032\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1749 - accuracy: 0.9342 - val_loss: 0.2602 - val_accuracy: 0.9070\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1701 - accuracy: 0.9369 - val_loss: 0.2663 - val_accuracy: 0.9067\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1669 - accuracy: 0.9373 - val_loss: 0.2642 - val_accuracy: 0.9048\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1635 - accuracy: 0.9384 - val_loss: 0.2710 - val_accuracy: 0.9092\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1601 - accuracy: 0.9413 - val_loss: 0.2822 - val_accuracy: 0.9042\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1567 - accuracy: 0.9406 - val_loss: 0.2663 - val_accuracy: 0.9098\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1531 - accuracy: 0.9429 - val_loss: 0.2633 - val_accuracy: 0.9113\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1498 - accuracy: 0.9443 - val_loss: 0.2744 - val_accuracy: 0.9060\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1466 - accuracy: 0.9457 - val_loss: 0.2773 - val_accuracy: 0.9099\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1437 - accuracy: 0.9466 - val_loss: 0.2690 - val_accuracy: 0.9096\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1405 - accuracy: 0.9479 - val_loss: 0.2752 - val_accuracy: 0.9093\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1370 - accuracy: 0.9499 - val_loss: 0.2757 - val_accuracy: 0.9096\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1349 - accuracy: 0.9497 - val_loss: 0.2764 - val_accuracy: 0.9112\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1328 - accuracy: 0.9511 - val_loss: 0.2770 - val_accuracy: 0.9092\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1300 - accuracy: 0.9525 - val_loss: 0.2819 - val_accuracy: 0.9094\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1271 - accuracy: 0.9537 - val_loss: 0.2826 - val_accuracy: 0.9081\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1252 - accuracy: 0.9540 - val_loss: 0.2792 - val_accuracy: 0.9106\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1232 - accuracy: 0.9546 - val_loss: 0.2857 - val_accuracy: 0.9089\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1204 - accuracy: 0.9556 - val_loss: 0.2827 - val_accuracy: 0.9105\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1176 - accuracy: 0.9572 - val_loss: 0.2891 - val_accuracy: 0.9081\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1154 - accuracy: 0.9576 - val_loss: 0.2904 - val_accuracy: 0.9097\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1139 - accuracy: 0.9582 - val_loss: 0.2911 - val_accuracy: 0.9097\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1114 - accuracy: 0.9591 - val_loss: 0.2988 - val_accuracy: 0.9100\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1098 - accuracy: 0.9599 - val_loss: 0.3063 - val_accuracy: 0.9096\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1081 - accuracy: 0.9610 - val_loss: 0.3047 - val_accuracy: 0.9087\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1064 - accuracy: 0.9609 - val_loss: 0.3017 - val_accuracy: 0.9114\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1033 - accuracy: 0.9626 - val_loss: 0.3049 - val_accuracy: 0.9095\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1014 - accuracy: 0.9639 - val_loss: 0.3032 - val_accuracy: 0.9112\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0999 - accuracy: 0.9638 - val_loss: 0.3124 - val_accuracy: 0.9097\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0983 - accuracy: 0.9643 - val_loss: 0.3058 - val_accuracy: 0.9094\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0963 - accuracy: 0.9648 - val_loss: 0.3138 - val_accuracy: 0.9082\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0944 - accuracy: 0.9657 - val_loss: 0.3292 - val_accuracy: 0.9072\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0922 - accuracy: 0.9667 - val_loss: 0.3122 - val_accuracy: 0.9102\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0905 - accuracy: 0.9675 - val_loss: 0.3152 - val_accuracy: 0.9080\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0893 - accuracy: 0.9677 - val_loss: 0.3225 - val_accuracy: 0.9123\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0878 - accuracy: 0.9684 - val_loss: 0.3262 - val_accuracy: 0.9092\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0853 - accuracy: 0.9693 - val_loss: 0.3207 - val_accuracy: 0.9118\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0846 - accuracy: 0.9696 - val_loss: 0.3313 - val_accuracy: 0.9077\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0829 - accuracy: 0.9707 - val_loss: 0.3311 - val_accuracy: 0.9098\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0816 - accuracy: 0.9704 - val_loss: 0.3355 - val_accuracy: 0.9078\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0801 - accuracy: 0.9712 - val_loss: 0.3430 - val_accuracy: 0.9106\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0783 - accuracy: 0.9720 - val_loss: 0.3417 - val_accuracy: 0.9090\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0773 - accuracy: 0.9726 - val_loss: 0.3504 - val_accuracy: 0.9088\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0761 - accuracy: 0.9726 - val_loss: 0.3515 - val_accuracy: 0.9093\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0755 - accuracy: 0.9729 - val_loss: 0.3494 - val_accuracy: 0.9090\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0735 - accuracy: 0.9743 - val_loss: 0.3536 - val_accuracy: 0.9079\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0720 - accuracy: 0.9746 - val_loss: 0.3564 - val_accuracy: 0.9081\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0703 - accuracy: 0.9754 - val_loss: 0.3553 - val_accuracy: 0.9098\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0691 - accuracy: 0.9757 - val_loss: 0.3642 - val_accuracy: 0.9068\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0684 - accuracy: 0.9765 - val_loss: 0.3613 - val_accuracy: 0.9073\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0669 - accuracy: 0.9771 - val_loss: 0.3670 - val_accuracy: 0.9070\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0649 - accuracy: 0.9773 - val_loss: 0.3685 - val_accuracy: 0.9092\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0641 - accuracy: 0.9779 - val_loss: 0.3708 - val_accuracy: 0.9098\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0628 - accuracy: 0.9780 - val_loss: 0.3807 - val_accuracy: 0.9074\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0616 - accuracy: 0.9791 - val_loss: 0.3844 - val_accuracy: 0.9064\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0604 - accuracy: 0.9793 - val_loss: 0.3852 - val_accuracy: 0.9078\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0596 - accuracy: 0.9794 - val_loss: 0.3879 - val_accuracy: 0.9092\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0587 - accuracy: 0.9806 - val_loss: 0.3880 - val_accuracy: 0.9072\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0569 - accuracy: 0.9808 - val_loss: 0.4027 - val_accuracy: 0.9050\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0566 - accuracy: 0.9807 - val_loss: 0.4054 - val_accuracy: 0.9092\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0552 - accuracy: 0.9814 - val_loss: 0.4085 - val_accuracy: 0.9067\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0539 - accuracy: 0.9818 - val_loss: 0.4024 - val_accuracy: 0.9066\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0527 - accuracy: 0.9827 - val_loss: 0.4033 - val_accuracy: 0.9085\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0517 - accuracy: 0.9822 - val_loss: 0.4166 - val_accuracy: 0.9071\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0514 - accuracy: 0.9825 - val_loss: 0.4203 - val_accuracy: 0.9058\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0494 - accuracy: 0.9837 - val_loss: 0.4206 - val_accuracy: 0.9086\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0490 - accuracy: 0.9840 - val_loss: 0.4217 - val_accuracy: 0.9094\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0483 - accuracy: 0.9841 - val_loss: 0.4244 - val_accuracy: 0.9054\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0475 - accuracy: 0.9841 - val_loss: 0.4396 - val_accuracy: 0.9023\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0462 - accuracy: 0.9847 - val_loss: 0.4356 - val_accuracy: 0.9040\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0449 - accuracy: 0.9854 - val_loss: 0.4355 - val_accuracy: 0.9084\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0437 - accuracy: 0.9858 - val_loss: 0.4410 - val_accuracy: 0.9066\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0435 - accuracy: 0.9853 - val_loss: 0.4468 - val_accuracy: 0.9068\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0424 - accuracy: 0.9864 - val_loss: 0.4394 - val_accuracy: 0.9070\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0422 - accuracy: 0.9870 - val_loss: 0.4557 - val_accuracy: 0.9062\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0408 - accuracy: 0.9868 - val_loss: 0.4546 - val_accuracy: 0.9060\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0402 - accuracy: 0.9872 - val_loss: 0.4619 - val_accuracy: 0.9045\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0397 - accuracy: 0.9872 - val_loss: 0.4535 - val_accuracy: 0.9052\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0391 - accuracy: 0.9879 - val_loss: 0.4579 - val_accuracy: 0.9070\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0377 - accuracy: 0.9878 - val_loss: 0.4751 - val_accuracy: 0.9051\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0373 - accuracy: 0.9887 - val_loss: 0.4721 - val_accuracy: 0.9053\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0366 - accuracy: 0.9884 - val_loss: 0.4767 - val_accuracy: 0.9081\n",
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.5175 - accuracy: 0.8270 - val_loss: 0.4252 - val_accuracy: 0.8597\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.3376 - accuracy: 0.8816 - val_loss: 0.2687 - val_accuracy: 0.9057\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.2909 - accuracy: 0.8977 - val_loss: 0.3396 - val_accuracy: 0.8944\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.2617 - accuracy: 0.9069 - val_loss: 0.2270 - val_accuracy: 0.9161\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.2433 - accuracy: 0.9127 - val_loss: 0.2302 - val_accuracy: 0.9167\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.2282 - accuracy: 0.9176 - val_loss: 0.2290 - val_accuracy: 0.9150\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 225s 120ms/step - loss: 0.2204 - accuracy: 0.9195 - val_loss: 0.2238 - val_accuracy: 0.9177\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.2071 - accuracy: 0.9247 - val_loss: 0.2023 - val_accuracy: 0.9263\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.2004 - accuracy: 0.9271 - val_loss: 0.2001 - val_accuracy: 0.9276\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1924 - accuracy: 0.9298 - val_loss: 0.2009 - val_accuracy: 0.9302\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1839 - accuracy: 0.9328 - val_loss: 0.2008 - val_accuracy: 0.9298\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1802 - accuracy: 0.9350 - val_loss: 0.2004 - val_accuracy: 0.9278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1755 - accuracy: 0.9359 - val_loss: 0.1959 - val_accuracy: 0.9256\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1709 - accuracy: 0.9381 - val_loss: 0.1853 - val_accuracy: 0.9322\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1646 - accuracy: 0.9395 - val_loss: 0.1985 - val_accuracy: 0.9274\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1599 - accuracy: 0.9413 - val_loss: 0.1866 - val_accuracy: 0.9335\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1563 - accuracy: 0.9430 - val_loss: 0.1813 - val_accuracy: 0.9367\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1490 - accuracy: 0.9457 - val_loss: 0.1827 - val_accuracy: 0.9308\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.1474 - accuracy: 0.9461 - val_loss: 0.1825 - val_accuracy: 0.9349\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1432 - accuracy: 0.9473 - val_loss: 0.2251 - val_accuracy: 0.9300\n",
      "Epoch 21/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1401 - accuracy: 0.9490 - val_loss: 0.1790 - val_accuracy: 0.9353\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 225s 120ms/step - loss: 0.1379 - accuracy: 0.9490 - val_loss: 0.1741 - val_accuracy: 0.9374\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1362 - accuracy: 0.9488 - val_loss: 0.1778 - val_accuracy: 0.9368\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1341 - accuracy: 0.9504 - val_loss: 0.1778 - val_accuracy: 0.9371\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1302 - accuracy: 0.9517 - val_loss: 0.1733 - val_accuracy: 0.9380\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1279 - accuracy: 0.9526 - val_loss: 0.1787 - val_accuracy: 0.9367\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1251 - accuracy: 0.9538 - val_loss: 0.1880 - val_accuracy: 0.9362\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1240 - accuracy: 0.9541 - val_loss: 0.1787 - val_accuracy: 0.9390\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1218 - accuracy: 0.9551 - val_loss: 0.2485 - val_accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1169 - accuracy: 0.9566 - val_loss: 0.1879 - val_accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1163 - accuracy: 0.9569 - val_loss: 0.2703 - val_accuracy: 0.9280\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1140 - accuracy: 0.9571 - val_loss: 0.1852 - val_accuracy: 0.9401\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1109 - accuracy: 0.9586 - val_loss: 0.1825 - val_accuracy: 0.9391\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.1086 - accuracy: 0.9599 - val_loss: 0.1863 - val_accuracy: 0.9397\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1083 - accuracy: 0.9595 - val_loss: 0.1862 - val_accuracy: 0.9383\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1073 - accuracy: 0.9606 - val_loss: 0.1842 - val_accuracy: 0.9394\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1050 - accuracy: 0.9610 - val_loss: 0.1798 - val_accuracy: 0.9409\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.1047 - accuracy: 0.9606 - val_loss: 0.2741 - val_accuracy: 0.9287\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.1008 - accuracy: 0.9619 - val_loss: 0.1804 - val_accuracy: 0.9401\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.1020 - accuracy: 0.9620 - val_loss: 0.1846 - val_accuracy: 0.9383\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0999 - accuracy: 0.9637 - val_loss: 0.1764 - val_accuracy: 0.9424\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0980 - accuracy: 0.9640 - val_loss: 0.1787 - val_accuracy: 0.9402\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0977 - accuracy: 0.9639 - val_loss: 0.1820 - val_accuracy: 0.9399\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0961 - accuracy: 0.9646 - val_loss: 0.1816 - val_accuracy: 0.9419\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0931 - accuracy: 0.9654 - val_loss: 0.1835 - val_accuracy: 0.9401\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0890 - accuracy: 0.9656 - val_loss: 0.1821 - val_accuracy: 0.9414\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0894 - accuracy: 0.9664 - val_loss: 0.1824 - val_accuracy: 0.9407\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0899 - accuracy: 0.9672 - val_loss: 0.1838 - val_accuracy: 0.9422\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0905 - accuracy: 0.9664 - val_loss: 0.1835 - val_accuracy: 0.9403\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0848 - accuracy: 0.9683 - val_loss: 0.1851 - val_accuracy: 0.9415\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0867 - accuracy: 0.9675 - val_loss: 0.1817 - val_accuracy: 0.9411\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.0850 - accuracy: 0.9681 - val_loss: 0.1950 - val_accuracy: 0.9396\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0829 - accuracy: 0.9694 - val_loss: 0.1949 - val_accuracy: 0.9397\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 225s 120ms/step - loss: 0.0827 - accuracy: 0.9694 - val_loss: 0.1882 - val_accuracy: 0.9403\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0829 - accuracy: 0.9689 - val_loss: 0.2003 - val_accuracy: 0.9386\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0848 - accuracy: 0.9681 - val_loss: 0.1877 - val_accuracy: 0.9407\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0812 - accuracy: 0.9707 - val_loss: 0.1832 - val_accuracy: 0.9428\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.0790 - accuracy: 0.9707 - val_loss: 0.1892 - val_accuracy: 0.9408\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.0802 - accuracy: 0.9698 - val_loss: 0.1899 - val_accuracy: 0.9403\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0770 - accuracy: 0.9722 - val_loss: 0.2067 - val_accuracy: 0.9402\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0769 - accuracy: 0.9717 - val_loss: 0.1873 - val_accuracy: 0.9414\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0769 - accuracy: 0.9714 - val_loss: 0.1922 - val_accuracy: 0.9421\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0753 - accuracy: 0.9715 - val_loss: 0.1915 - val_accuracy: 0.9422\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0720 - accuracy: 0.9729 - val_loss: 0.2361 - val_accuracy: 0.9387\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0726 - accuracy: 0.9732 - val_loss: 0.1946 - val_accuracy: 0.9421\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.0728 - accuracy: 0.9729 - val_loss: 0.2183 - val_accuracy: 0.9401\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0720 - accuracy: 0.9729 - val_loss: 0.1870 - val_accuracy: 0.9440\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0719 - accuracy: 0.9735 - val_loss: 0.1888 - val_accuracy: 0.9431\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0695 - accuracy: 0.9743 - val_loss: 0.1954 - val_accuracy: 0.9418\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0693 - accuracy: 0.9740 - val_loss: 0.2015 - val_accuracy: 0.9393\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 227s 121ms/step - loss: 0.0706 - accuracy: 0.9737 - val_loss: 0.1938 - val_accuracy: 0.9426\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0670 - accuracy: 0.9756 - val_loss: 0.2000 - val_accuracy: 0.9408\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0685 - accuracy: 0.9740 - val_loss: 0.1931 - val_accuracy: 0.9448\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0688 - accuracy: 0.9744 - val_loss: 0.1921 - val_accuracy: 0.9434\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0662 - accuracy: 0.9754 - val_loss: 0.1944 - val_accuracy: 0.9427\n",
      "Epoch 76/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0677 - accuracy: 0.9749 - val_loss: 0.1947 - val_accuracy: 0.9424\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 223s 119ms/step - loss: 0.0659 - accuracy: 0.9763 - val_loss: 0.1946 - val_accuracy: 0.9423\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 224s 120ms/step - loss: 0.0643 - accuracy: 0.9759 - val_loss: 0.1975 - val_accuracy: 0.9423\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 224s 119ms/step - loss: 0.0640 - accuracy: 0.9766 - val_loss: 0.1961 - val_accuracy: 0.9436\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 225s 120ms/step - loss: 0.0633 - accuracy: 0.9765 - val_loss: 0.1998 - val_accuracy: 0.9426\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 225s 120ms/step - loss: 0.0643 - accuracy: 0.9755 - val_loss: 0.1992 - val_accuracy: 0.9423\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 225s 120ms/step - loss: 0.0634 - accuracy: 0.9764 - val_loss: 0.1986 - val_accuracy: 0.9426\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.1974 - val_accuracy: 0.9429\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 225s 120ms/step - loss: 0.0631 - accuracy: 0.9762 - val_loss: 0.2009 - val_accuracy: 0.9419\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0614 - accuracy: 0.9771 - val_loss: 0.1984 - val_accuracy: 0.9427\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0614 - accuracy: 0.9771 - val_loss: 0.1964 - val_accuracy: 0.9431\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 227s 121ms/step - loss: 0.0600 - accuracy: 0.9779 - val_loss: 0.1982 - val_accuracy: 0.9437\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0612 - accuracy: 0.9776 - val_loss: 0.1972 - val_accuracy: 0.9421\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 227s 121ms/step - loss: 0.0602 - accuracy: 0.9777 - val_loss: 0.2029 - val_accuracy: 0.9419\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 226s 120ms/step - loss: 0.0588 - accuracy: 0.9780 - val_loss: 0.2012 - val_accuracy: 0.9424\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0580 - accuracy: 0.9784 - val_loss: 0.2036 - val_accuracy: 0.9414\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0588 - accuracy: 0.9783 - val_loss: 0.2069 - val_accuracy: 0.9419\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 226s 120ms/step - loss: 0.0587 - accuracy: 0.9782 - val_loss: 0.2142 - val_accuracy: 0.9421\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0576 - accuracy: 0.9789 - val_loss: 0.2618 - val_accuracy: 0.9370\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 228s 121ms/step - loss: 0.0564 - accuracy: 0.9787 - val_loss: 0.2049 - val_accuracy: 0.9419\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 227s 121ms/step - loss: 0.0565 - accuracy: 0.9790 - val_loss: 0.2039 - val_accuracy: 0.9432\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0564 - accuracy: 0.9791 - val_loss: 0.2002 - val_accuracy: 0.9421\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0558 - accuracy: 0.9785 - val_loss: 0.2129 - val_accuracy: 0.9428\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 227s 121ms/step - loss: 0.0563 - accuracy: 0.9792 - val_loss: 0.2073 - val_accuracy: 0.9420\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 226s 121ms/step - loss: 0.0550 - accuracy: 0.9792 - val_loss: 0.2029 - val_accuracy: 0.9439\n",
      "Epoch 1/100\n",
      "1875/1875 [==============================] - 187s 100ms/step - loss: 3.0266 - accuracy: 0.0948 - val_loss: 13.6822 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1875/1875 [==============================] - 186s 99ms/step - loss: 2.8152 - accuracy: 0.0997 - val_loss: 2.9045 - val_accuracy: 0.1006\n",
      "Epoch 3/100\n",
      "1875/1875 [==============================] - 186s 99ms/step - loss: 2.4635 - accuracy: 0.1000 - val_loss: 2.2935 - val_accuracy: 0.0999\n",
      "Epoch 4/100\n",
      "1875/1875 [==============================] - 185s 99ms/step - loss: 2.3573 - accuracy: 0.1002 - val_loss: 2.9955 - val_accuracy: 0.0993\n",
      "Epoch 5/100\n",
      "1875/1875 [==============================] - 185s 98ms/step - loss: 2.5461 - accuracy: 0.0999 - val_loss: 2.2768 - val_accuracy: 0.1016\n",
      "Epoch 6/100\n",
      "1875/1875 [==============================] - 185s 99ms/step - loss: 2.6304 - accuracy: 0.1001 - val_loss: 3.7370 - val_accuracy: 0.0997\n",
      "Epoch 7/100\n",
      "1875/1875 [==============================] - 186s 99ms/step - loss: 2.7557 - accuracy: 0.0998 - val_loss: 2.2617 - val_accuracy: 0.1005\n",
      "Epoch 8/100\n",
      "1875/1875 [==============================] - 184s 98ms/step - loss: 2.5061 - accuracy: 0.1001 - val_loss: 2.3813 - val_accuracy: 0.1000\n",
      "Epoch 9/100\n",
      "1875/1875 [==============================] - 185s 99ms/step - loss: 2.6301 - accuracy: 0.1001 - val_loss: 3.8092 - val_accuracy: 0.1000\n",
      "Epoch 10/100\n",
      "1875/1875 [==============================] - 185s 98ms/step - loss: 2.6757 - accuracy: 0.0999 - val_loss: 2.3075 - val_accuracy: 0.1003\n",
      "Epoch 11/100\n",
      "1875/1875 [==============================] - 184s 98ms/step - loss: 2.5905 - accuracy: 0.1001 - val_loss: 2.3026 - val_accuracy: 0.1000\n",
      "Epoch 12/100\n",
      "1875/1875 [==============================] - 184s 98ms/step - loss: 2.5964 - accuracy: 0.1000 - val_loss: 2.3368 - val_accuracy: 0.1000\n",
      "Epoch 13/100\n",
      "1875/1875 [==============================] - 185s 99ms/step - loss: 2.6101 - accuracy: 0.1001 - val_loss: 2.4373 - val_accuracy: 0.1008\n",
      "Epoch 14/100\n",
      "1875/1875 [==============================] - 182s 97ms/step - loss: 2.7078 - accuracy: 0.1002 - val_loss: 7.1885 - val_accuracy: 0.1000\n",
      "Epoch 15/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.5268 - accuracy: 0.1000 - val_loss: 7.1531 - val_accuracy: 0.1000\n",
      "Epoch 16/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6292 - accuracy: 0.1000 - val_loss: 7.1620 - val_accuracy: 0.1000\n",
      "Epoch 17/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.7004 - accuracy: 0.1000 - val_loss: 8.8825 - val_accuracy: 0.1000\n",
      "Epoch 18/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7020 - accuracy: 0.1000 - val_loss: 7.1516 - val_accuracy: 0.1000\n",
      "Epoch 19/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6939 - accuracy: 0.1000 - val_loss: 8.9199 - val_accuracy: 0.1000\n",
      "Epoch 20/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.7031 - accuracy: 0.1000 - val_loss: 11.9861 - val_accuracy: 0.1000\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7035 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 22/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.7027 - accuracy: 0.1000 - val_loss: 10.3874 - val_accuracy: 0.1000\n",
      "Epoch 23/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7075 - accuracy: 0.1000 - val_loss: 7.2328 - val_accuracy: 0.1000\n",
      "Epoch 24/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7085 - accuracy: 0.1000 - val_loss: 10.5077 - val_accuracy: 0.1000\n",
      "Epoch 25/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6996 - accuracy: 0.1000 - val_loss: 7.1735 - val_accuracy: 0.0999\n",
      "Epoch 26/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.7009 - accuracy: 0.1000 - val_loss: 7.1470 - val_accuracy: 0.0999\n",
      "Epoch 27/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7049 - accuracy: 0.1000 - val_loss: 7.1752 - val_accuracy: 0.1000\n",
      "Epoch 28/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7018 - accuracy: 0.1000 - val_loss: 7.2095 - val_accuracy: 0.1000\n",
      "Epoch 29/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7099 - accuracy: 0.1000 - val_loss: 7.1531 - val_accuracy: 0.1000\n",
      "Epoch 30/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.7051 - accuracy: 0.1000 - val_loss: 7.3503 - val_accuracy: 0.1000\n",
      "Epoch 31/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.7044 - accuracy: 0.1000 - val_loss: 7.2742 - val_accuracy: 0.1000\n",
      "Epoch 32/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6996 - accuracy: 0.1000 - val_loss: 8.8449 - val_accuracy: 0.0999\n",
      "Epoch 33/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7025 - accuracy: 0.1000 - val_loss: 8.8890 - val_accuracy: 0.1000\n",
      "Epoch 34/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.7023 - accuracy: 0.1000 - val_loss: 10.3751 - val_accuracy: 0.1000\n",
      "Epoch 35/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7053 - accuracy: 0.1000 - val_loss: 11.9861 - val_accuracy: 0.1000\n",
      "Epoch 36/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7066 - accuracy: 0.1000 - val_loss: 7.2044 - val_accuracy: 0.1000\n",
      "Epoch 37/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.7062 - accuracy: 0.1000 - val_loss: 8.8678 - val_accuracy: 0.0999\n",
      "Epoch 38/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7021 - accuracy: 0.1000 - val_loss: 7.1712 - val_accuracy: 0.1000\n",
      "Epoch 39/100\n",
      "1875/1875 [==============================] - 182s 97ms/step - loss: 2.7044 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 40/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7153 - accuracy: 0.1000 - val_loss: 7.1555 - val_accuracy: 0.1000\n",
      "Epoch 41/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.7004 - accuracy: 0.1000 - val_loss: 7.1780 - val_accuracy: 0.1000\n",
      "Epoch 42/100\n",
      "1875/1875 [==============================] - 181s 97ms/step - loss: 2.7022 - accuracy: 0.1000 - val_loss: 8.8198 - val_accuracy: 0.1000\n",
      "Epoch 43/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6971 - accuracy: 0.1000 - val_loss: 7.1531 - val_accuracy: 0.1000\n",
      "Epoch 44/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.7023 - accuracy: 0.1000 - val_loss: 7.3310 - val_accuracy: 0.1000\n",
      "Epoch 45/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6967 - accuracy: 0.1000 - val_loss: 7.3149 - val_accuracy: 0.0999\n",
      "Epoch 46/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6987 - accuracy: 0.1000 - val_loss: 7.1469 - val_accuracy: 0.1000\n",
      "Epoch 47/100\n",
      "1875/1875 [==============================] - 181s 97ms/step - loss: 2.7004 - accuracy: 0.1000 - val_loss: 6.9282 - val_accuracy: 0.1000\n",
      "Epoch 48/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7022 - accuracy: 0.1000 - val_loss: 7.2495 - val_accuracy: 0.1000\n",
      "Epoch 49/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7013 - accuracy: 0.1000 - val_loss: 7.7275 - val_accuracy: 0.1000\n",
      "Epoch 50/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.6998 - accuracy: 0.1000 - val_loss: 12.0424 - val_accuracy: 0.1000\n",
      "Epoch 51/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.7039 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 52/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6996 - accuracy: 0.1000 - val_loss: 9.4231 - val_accuracy: 0.1000\n",
      "Epoch 53/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7076 - accuracy: 0.1000 - val_loss: 8.8105 - val_accuracy: 0.1000\n",
      "Epoch 54/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7028 - accuracy: 0.1000 - val_loss: 7.1814 - val_accuracy: 0.1000\n",
      "Epoch 55/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7025 - accuracy: 0.1000 - val_loss: 7.1531 - val_accuracy: 0.1000\n",
      "Epoch 56/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7074 - accuracy: 0.1000 - val_loss: 7.1478 - val_accuracy: 0.1000\n",
      "Epoch 57/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.7037 - accuracy: 0.1000 - val_loss: 7.1570 - val_accuracy: 0.1000\n",
      "Epoch 58/100\n",
      "1875/1875 [==============================] - 179s 95ms/step - loss: 2.7096 - accuracy: 0.1000 - val_loss: 11.9861 - val_accuracy: 0.1000\n",
      "Epoch 59/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6729 - accuracy: 0.1000 - val_loss: 7.2121 - val_accuracy: 0.1000\n",
      "Epoch 60/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.5495 - accuracy: 0.1000 - val_loss: 7.1523 - val_accuracy: 0.1000\n",
      "Epoch 61/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6036 - accuracy: 0.1000 - val_loss: 7.1523 - val_accuracy: 0.1000\n",
      "Epoch 62/100\n",
      "1875/1875 [==============================] - 181s 97ms/step - loss: 2.6041 - accuracy: 0.1000 - val_loss: 7.1523 - val_accuracy: 0.1000\n",
      "Epoch 63/100\n",
      "1875/1875 [==============================] - 182s 97ms/step - loss: 2.6032 - accuracy: 0.1000 - val_loss: 7.1648 - val_accuracy: 0.1000\n",
      "Epoch 64/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6039 - accuracy: 0.1000 - val_loss: 7.1567 - val_accuracy: 0.1000\n",
      "Epoch 65/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.6045 - accuracy: 0.1000 - val_loss: 7.4148 - val_accuracy: 0.1000\n",
      "Epoch 66/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6041 - accuracy: 0.1000 - val_loss: 7.1515 - val_accuracy: 0.1000\n",
      "Epoch 67/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.6038 - accuracy: 0.1000 - val_loss: 7.1531 - val_accuracy: 0.1000\n",
      "Epoch 68/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.6042 - accuracy: 0.1000 - val_loss: 7.1445 - val_accuracy: 0.1000\n",
      "Epoch 69/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6045 - accuracy: 0.1000 - val_loss: 7.1523 - val_accuracy: 0.0999\n",
      "Epoch 70/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6038 - accuracy: 0.1000 - val_loss: 7.3044 - val_accuracy: 0.1000\n",
      "Epoch 71/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6041 - accuracy: 0.1000 - val_loss: 8.9474 - val_accuracy: 0.1000\n",
      "Epoch 72/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6038 - accuracy: 0.1000 - val_loss: 7.1531 - val_accuracy: 0.1000\n",
      "Epoch 73/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6042 - accuracy: 0.1000 - val_loss: 7.1495 - val_accuracy: 0.1000\n",
      "Epoch 74/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6042 - accuracy: 0.1000 - val_loss: 7.1476 - val_accuracy: 0.1000\n",
      "Epoch 75/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6029 - accuracy: 0.1000 - val_loss: 10.3751 - val_accuracy: 0.1000\n",
      "Epoch 76/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.6033 - accuracy: 0.1000 - val_loss: 11.9861 - val_accuracy: 0.1000\n",
      "Epoch 77/100\n",
      "1875/1875 [==============================] - 179s 95ms/step - loss: 2.6034 - accuracy: 0.1000 - val_loss: 11.9861 - val_accuracy: 0.1000\n",
      "Epoch 78/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.6043 - accuracy: 0.1000 - val_loss: 10.3751 - val_accuracy: 0.1000\n",
      "Epoch 79/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.6037 - accuracy: 0.1000 - val_loss: 10.3751 - val_accuracy: 0.1000\n",
      "Epoch 80/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.6035 - accuracy: 0.1000 - val_loss: 11.9861 - val_accuracy: 0.1000\n",
      "Epoch 81/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6038 - accuracy: 0.1000 - val_loss: 8.9795 - val_accuracy: 0.1000\n",
      "Epoch 82/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6036 - accuracy: 0.1000 - val_loss: 11.9861 - val_accuracy: 0.1000\n",
      "Epoch 83/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6039 - accuracy: 0.1000 - val_loss: 7.4599 - val_accuracy: 0.1000\n",
      "Epoch 84/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6042 - accuracy: 0.1000 - val_loss: 7.1523 - val_accuracy: 0.1000\n",
      "Epoch 85/100\n",
      "1875/1875 [==============================] - 181s 96ms/step - loss: 2.6040 - accuracy: 0.1000 - val_loss: 7.1710 - val_accuracy: 0.1000\n",
      "Epoch 86/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.6037 - accuracy: 0.1000 - val_loss: 7.1634 - val_accuracy: 0.0999\n",
      "Epoch 87/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6043 - accuracy: 0.1000 - val_loss: 7.4201 - val_accuracy: 0.1000\n",
      "Epoch 88/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6044 - accuracy: 0.1000 - val_loss: 10.4899 - val_accuracy: 0.1000\n",
      "Epoch 89/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6042 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 90/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6032 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 91/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6037 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 92/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6041 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 93/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6035 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 94/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6038 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 95/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6037 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 96/100\n",
      "1875/1875 [==============================] - 179s 96ms/step - loss: 2.6028 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 97/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6039 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 98/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6040 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 99/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6035 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n",
      "Epoch 100/100\n",
      "1875/1875 [==============================] - 180s 96ms/step - loss: 2.6036 - accuracy: 0.1000 - val_loss: 13.5972 - val_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shapey</th>\n",
       "      <th>shapex</th>\n",
       "      <th>shapez</th>\n",
       "      <th>train size</th>\n",
       "      <th>test size</th>\n",
       "      <th>num epochs</th>\n",
       "      <th>lenet runtime</th>\n",
       "      <th>lenet test err</th>\n",
       "      <th>lenet history</th>\n",
       "      <th>vgg runtime</th>\n",
       "      <th>vgg test err</th>\n",
       "      <th>vgg history</th>\n",
       "      <th>mobilenet runtime</th>\n",
       "      <th>mobilenet test err</th>\n",
       "      <th>mobilenet history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fmnist</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>874.162244</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
       "      <td>22434.556872</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
       "      <td>18079.152862</td>\n",
       "      <td>0.10003</td>\n",
       "      <td>&lt;tensorflow.python.keras.callbacks.History obj...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  shapey  shapex  shapez  train size  test size  num epochs  \\\n",
       "0  fmnist      32      32       1       60000      10000         100   \n",
       "\n",
       "   lenet runtime  lenet test err  \\\n",
       "0     874.162244          0.9081   \n",
       "\n",
       "                                       lenet history   vgg runtime  \\\n",
       "0  <tensorflow.python.keras.callbacks.History obj...  22434.556872   \n",
       "\n",
       "   vgg test err                                        vgg history  \\\n",
       "0        0.9439  <tensorflow.python.keras.callbacks.History obj...   \n",
       "\n",
       "   mobilenet runtime  mobilenet test err  \\\n",
       "0       18079.152862             0.10003   \n",
       "\n",
       "                                   mobilenet history  \n",
       "0  <tensorflow.python.keras.callbacks.History obj...  "
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fmnist = evaluate_dataset('fmnist', num_epochs=100)\n",
    "df_fmnist.to_pickle('db_fmnist.pkl')\n",
    "df_fmnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shapey</th>\n",
       "      <th>shapex</th>\n",
       "      <th>shapez</th>\n",
       "      <th>train size</th>\n",
       "      <th>test size</th>\n",
       "      <th>num epochs</th>\n",
       "      <th>lenet runtime</th>\n",
       "      <th>lenet test err</th>\n",
       "      <th>lenet history</th>\n",
       "      <th>vgg runtime</th>\n",
       "      <th>vgg test err</th>\n",
       "      <th>vgg history</th>\n",
       "      <th>mobilenet runtime</th>\n",
       "      <th>mobilenet test err</th>\n",
       "      <th>mobilenet history</th>\n",
       "      <th>convsvm runtime</th>\n",
       "      <th>convsvm test err</th>\n",
       "      <th>convsvm history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fmnist</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>874.162244</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>{'loss': [0.6234489679336548, 0.38793143630027...</td>\n",
       "      <td>22434.556872</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>{'loss': [0.5175429582595825, 0.33762103319168...</td>\n",
       "      <td>18973.48017</td>\n",
       "      <td>0.9074</td>\n",
       "      <td>{'loss': [0.6217073202133179, 0.38363438844680...</td>\n",
       "      <td>361.976835</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>{'accuracy': [0.8441833333333333], 'val_accura...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     name  shapey  shapex  shapez  train size  test size  num epochs  \\\n",
       "0  fmnist      32      32       1       60000      10000         100   \n",
       "\n",
       "   lenet runtime  lenet test err  \\\n",
       "0     874.162244          0.9081   \n",
       "\n",
       "                                       lenet history   vgg runtime  \\\n",
       "0  {'loss': [0.6234489679336548, 0.38793143630027...  22434.556872   \n",
       "\n",
       "   vgg test err                                        vgg history  \\\n",
       "0        0.9439  {'loss': [0.5175429582595825, 0.33762103319168...   \n",
       "\n",
       "   mobilenet runtime  mobilenet test err  \\\n",
       "0        18973.48017              0.9074   \n",
       "\n",
       "                                   mobilenet history  convsvm runtime  \\\n",
       "0  {'loss': [0.6217073202133179, 0.38363438844680...       361.976835   \n",
       "\n",
       "   convsvm test err                                    convsvm history  \n",
       "0            0.8277  {'accuracy': [0.8441833333333333], 'val_accura...  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fmnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 1.7826 - accuracy: 0.3506 - val_loss: 1.6145 - val_accuracy: 0.4213\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.4577 - accuracy: 0.4724 - val_loss: 1.3607 - val_accuracy: 0.5125\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3302 - accuracy: 0.5214 - val_loss: 1.3110 - val_accuracy: 0.5333\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.2395 - accuracy: 0.5555 - val_loss: 1.2705 - val_accuracy: 0.5483\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.1612 - accuracy: 0.5878 - val_loss: 1.2112 - val_accuracy: 0.5748\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0941 - accuracy: 0.6116 - val_loss: 1.1771 - val_accuracy: 0.5871\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 1.0340 - accuracy: 0.6341 - val_loss: 1.1677 - val_accuracy: 0.5957\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9757 - accuracy: 0.6537 - val_loss: 1.1523 - val_accuracy: 0.6047\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.9266 - accuracy: 0.6722 - val_loss: 1.1599 - val_accuracy: 0.6035\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8804 - accuracy: 0.6876 - val_loss: 1.1798 - val_accuracy: 0.6035\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.8382 - accuracy: 0.7028 - val_loss: 1.1557 - val_accuracy: 0.6045\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7982 - accuracy: 0.7183 - val_loss: 1.1397 - val_accuracy: 0.6099\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7669 - accuracy: 0.7279 - val_loss: 1.1796 - val_accuracy: 0.6119\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7293 - accuracy: 0.7408 - val_loss: 1.1850 - val_accuracy: 0.6158\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6982 - accuracy: 0.7507 - val_loss: 1.2374 - val_accuracy: 0.6138\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6634 - accuracy: 0.7644 - val_loss: 1.2386 - val_accuracy: 0.6166\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6307 - accuracy: 0.7766 - val_loss: 1.2677 - val_accuracy: 0.6134\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6028 - accuracy: 0.7854 - val_loss: 1.2950 - val_accuracy: 0.6037\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5798 - accuracy: 0.7942 - val_loss: 1.3297 - val_accuracy: 0.6110\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5489 - accuracy: 0.8052 - val_loss: 1.3785 - val_accuracy: 0.6096\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5239 - accuracy: 0.8147 - val_loss: 1.4126 - val_accuracy: 0.6088\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.5018 - accuracy: 0.8208 - val_loss: 1.4622 - val_accuracy: 0.5990\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4753 - accuracy: 0.8324 - val_loss: 1.4919 - val_accuracy: 0.5991\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4523 - accuracy: 0.8399 - val_loss: 1.5537 - val_accuracy: 0.6014\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4325 - accuracy: 0.8474 - val_loss: 1.5962 - val_accuracy: 0.6032\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4104 - accuracy: 0.8556 - val_loss: 1.6316 - val_accuracy: 0.6005\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3886 - accuracy: 0.8622 - val_loss: 1.6994 - val_accuracy: 0.5997\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3708 - accuracy: 0.8698 - val_loss: 1.7614 - val_accuracy: 0.5971\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3517 - accuracy: 0.8760 - val_loss: 1.8108 - val_accuracy: 0.6039\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3365 - accuracy: 0.8816 - val_loss: 1.8851 - val_accuracy: 0.5994\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3167 - accuracy: 0.8893 - val_loss: 1.9344 - val_accuracy: 0.5986\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.3001 - accuracy: 0.8962 - val_loss: 1.9552 - val_accuracy: 0.5980\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2825 - accuracy: 0.9023 - val_loss: 2.0661 - val_accuracy: 0.5945\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2656 - accuracy: 0.9076 - val_loss: 2.1175 - val_accuracy: 0.5985\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2516 - accuracy: 0.9147 - val_loss: 2.1876 - val_accuracy: 0.5939\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.2347 - accuracy: 0.9207 - val_loss: 2.3383 - val_accuracy: 0.5908\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2239 - accuracy: 0.9252 - val_loss: 2.3277 - val_accuracy: 0.5951\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.2136 - accuracy: 0.9285 - val_loss: 2.4531 - val_accuracy: 0.5926\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1982 - accuracy: 0.9328 - val_loss: 2.5088 - val_accuracy: 0.5942\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1835 - accuracy: 0.9391 - val_loss: 2.5882 - val_accuracy: 0.5922\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1698 - accuracy: 0.9452 - val_loss: 2.6712 - val_accuracy: 0.5908\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1592 - accuracy: 0.9482 - val_loss: 2.7761 - val_accuracy: 0.5897\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1501 - accuracy: 0.9521 - val_loss: 2.8544 - val_accuracy: 0.5872\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1374 - accuracy: 0.9568 - val_loss: 2.9143 - val_accuracy: 0.5937\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1306 - accuracy: 0.9600 - val_loss: 3.0921 - val_accuracy: 0.5888\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1186 - accuracy: 0.9631 - val_loss: 3.0811 - val_accuracy: 0.5886\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.1119 - accuracy: 0.9663 - val_loss: 3.2069 - val_accuracy: 0.5882\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0988 - accuracy: 0.9717 - val_loss: 3.2948 - val_accuracy: 0.5911\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0901 - accuracy: 0.9744 - val_loss: 3.3371 - val_accuracy: 0.5878\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0769 - accuracy: 0.9807 - val_loss: 3.4762 - val_accuracy: 0.5896\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0690 - accuracy: 0.9829 - val_loss: 3.5447 - val_accuracy: 0.5840\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0632 - accuracy: 0.9854 - val_loss: 3.6075 - val_accuracy: 0.5857\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0529 - accuracy: 0.9898 - val_loss: 3.7318 - val_accuracy: 0.5874\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0446 - accuracy: 0.9924 - val_loss: 3.8301 - val_accuracy: 0.5860\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0412 - accuracy: 0.9934 - val_loss: 3.9342 - val_accuracy: 0.5871\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0329 - accuracy: 0.9956 - val_loss: 4.0077 - val_accuracy: 0.5893\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0276 - accuracy: 0.9973 - val_loss: 4.1415 - val_accuracy: 0.5871\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0234 - accuracy: 0.9981 - val_loss: 4.2010 - val_accuracy: 0.5875\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0208 - accuracy: 0.9986 - val_loss: 4.2866 - val_accuracy: 0.5874\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0181 - accuracy: 0.9988 - val_loss: 4.3554 - val_accuracy: 0.5847\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0161 - accuracy: 0.9991 - val_loss: 4.4339 - val_accuracy: 0.5879\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0143 - accuracy: 0.9993 - val_loss: 4.4884 - val_accuracy: 0.5869\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0130 - accuracy: 0.9995 - val_loss: 4.5785 - val_accuracy: 0.5858\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0117 - accuracy: 0.9996 - val_loss: 4.6271 - val_accuracy: 0.5888\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0107 - accuracy: 0.9997 - val_loss: 4.6698 - val_accuracy: 0.5862\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0101 - accuracy: 0.9997 - val_loss: 4.7248 - val_accuracy: 0.5865\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0092 - accuracy: 0.9998 - val_loss: 4.7852 - val_accuracy: 0.5874\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0087 - accuracy: 0.9999 - val_loss: 4.8343 - val_accuracy: 0.5874\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0080 - accuracy: 0.9999 - val_loss: 4.8797 - val_accuracy: 0.5853\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0076 - accuracy: 0.9999 - val_loss: 4.9200 - val_accuracy: 0.5862\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0072 - accuracy: 0.9999 - val_loss: 4.9545 - val_accuracy: 0.5870\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0068 - accuracy: 0.9999 - val_loss: 4.9956 - val_accuracy: 0.5871\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0065 - accuracy: 0.9999 - val_loss: 5.0427 - val_accuracy: 0.5874\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 5.0786 - val_accuracy: 0.5871\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 5.1126 - val_accuracy: 0.5875\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 5.1333 - val_accuracy: 0.5869\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 5.1864 - val_accuracy: 0.5872\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 5.2058 - val_accuracy: 0.5868\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 5.2371 - val_accuracy: 0.5861\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 5.2588 - val_accuracy: 0.5861\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 5.2929 - val_accuracy: 0.5860\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 5.3161 - val_accuracy: 0.5847\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 5.3444 - val_accuracy: 0.5858\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 10s 6ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 5.3616 - val_accuracy: 0.5855\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 5.3939 - val_accuracy: 0.5862\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 5.4177 - val_accuracy: 0.5860\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 5.4395 - val_accuracy: 0.5857\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 5.4581 - val_accuracy: 0.5850\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 5.4794 - val_accuracy: 0.5848\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.5039 - val_accuracy: 0.5871\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 5.5154 - val_accuracy: 0.5854\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.5438 - val_accuracy: 0.5857\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 5.5641 - val_accuracy: 0.5860\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 5.5814 - val_accuracy: 0.5855\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 5.6004 - val_accuracy: 0.5863\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 5.6134 - val_accuracy: 0.5855\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 5.6323 - val_accuracy: 0.5864\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.6492 - val_accuracy: 0.5860\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 5.6668 - val_accuracy: 0.5867\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 9s 6ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 5.6797 - val_accuracy: 0.5862\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 185s 119ms/step - loss: 1.8758 - accuracy: 0.4177 - val_loss: 1.4988 - val_accuracy: 0.4932\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 1.2130 - accuracy: 0.5802 - val_loss: 1.0228 - val_accuracy: 0.6337\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.9922 - accuracy: 0.6533 - val_loss: 0.8619 - val_accuracy: 0.6976\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.8682 - accuracy: 0.6963 - val_loss: 0.7752 - val_accuracy: 0.7240\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.7952 - accuracy: 0.7231 - val_loss: 0.7360 - val_accuracy: 0.7446\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 193s 124ms/step - loss: 0.7426 - accuracy: 0.7389 - val_loss: 0.6883 - val_accuracy: 0.7632\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.6948 - accuracy: 0.7553 - val_loss: 0.6850 - val_accuracy: 0.7666\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.6556 - accuracy: 0.7702 - val_loss: 0.6370 - val_accuracy: 0.7750\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.6258 - accuracy: 0.7801 - val_loss: 0.6010 - val_accuracy: 0.7891\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.5934 - accuracy: 0.7910 - val_loss: 0.6004 - val_accuracy: 0.7924\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.5686 - accuracy: 0.7987 - val_loss: 0.5864 - val_accuracy: 0.7968\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.5472 - accuracy: 0.8080 - val_loss: 0.5851 - val_accuracy: 0.7983\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.5253 - accuracy: 0.8157 - val_loss: 0.6075 - val_accuracy: 0.7911\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.5025 - accuracy: 0.8239 - val_loss: 0.5680 - val_accuracy: 0.8053\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.4846 - accuracy: 0.8308 - val_loss: 0.5618 - val_accuracy: 0.8067\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.4675 - accuracy: 0.8377 - val_loss: 0.5615 - val_accuracy: 0.8123\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.4556 - accuracy: 0.8390 - val_loss: 0.5749 - val_accuracy: 0.8039\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.4365 - accuracy: 0.8462 - val_loss: 0.5493 - val_accuracy: 0.8127\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.4232 - accuracy: 0.8499 - val_loss: 0.5453 - val_accuracy: 0.8116\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 193s 123ms/step - loss: 0.4123 - accuracy: 0.8564 - val_loss: 0.5375 - val_accuracy: 0.8187\n",
      "Epoch 21/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3964 - accuracy: 0.8582 - val_loss: 0.5551 - val_accuracy: 0.8115\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3904 - accuracy: 0.8626 - val_loss: 0.5519 - val_accuracy: 0.8157\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3754 - accuracy: 0.8672 - val_loss: 0.5595 - val_accuracy: 0.8126\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.3700 - accuracy: 0.8692 - val_loss: 0.5529 - val_accuracy: 0.8138\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3559 - accuracy: 0.8736 - val_loss: 0.5498 - val_accuracy: 0.8171\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3451 - accuracy: 0.8763 - val_loss: 0.5423 - val_accuracy: 0.8199\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3395 - accuracy: 0.8797 - val_loss: 0.5463 - val_accuracy: 0.8218\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3382 - accuracy: 0.8798 - val_loss: 0.5369 - val_accuracy: 0.8221\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.3188 - accuracy: 0.8863 - val_loss: 0.5315 - val_accuracy: 0.8254\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.3095 - accuracy: 0.8890 - val_loss: 0.5379 - val_accuracy: 0.8227\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.3058 - accuracy: 0.8908 - val_loss: 0.5492 - val_accuracy: 0.8211\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2983 - accuracy: 0.8928 - val_loss: 0.5461 - val_accuracy: 0.8234\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2950 - accuracy: 0.8959 - val_loss: 0.5589 - val_accuracy: 0.8209\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2904 - accuracy: 0.8964 - val_loss: 0.5466 - val_accuracy: 0.8266\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2824 - accuracy: 0.8997 - val_loss: 0.5320 - val_accuracy: 0.8284\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2773 - accuracy: 0.8997 - val_loss: 0.5508 - val_accuracy: 0.8256\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2740 - accuracy: 0.9019 - val_loss: 0.5547 - val_accuracy: 0.8245\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2705 - accuracy: 0.9038 - val_loss: 0.5425 - val_accuracy: 0.8248\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2599 - accuracy: 0.9081 - val_loss: 0.5387 - val_accuracy: 0.8296\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2608 - accuracy: 0.9070 - val_loss: 0.5397 - val_accuracy: 0.8269\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2549 - accuracy: 0.9088 - val_loss: 0.5660 - val_accuracy: 0.8260\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 191s 123ms/step - loss: 0.2514 - accuracy: 0.9101 - val_loss: 0.5531 - val_accuracy: 0.8259\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2444 - accuracy: 0.9139 - val_loss: 0.5638 - val_accuracy: 0.8273\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2422 - accuracy: 0.9137 - val_loss: 0.5426 - val_accuracy: 0.8305\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2363 - accuracy: 0.9160 - val_loss: 0.5711 - val_accuracy: 0.8249\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2321 - accuracy: 0.9168 - val_loss: 0.5354 - val_accuracy: 0.8303\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2284 - accuracy: 0.9188 - val_loss: 0.5458 - val_accuracy: 0.8309\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2286 - accuracy: 0.9183 - val_loss: 0.5490 - val_accuracy: 0.8288\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2185 - accuracy: 0.9225 - val_loss: 0.5589 - val_accuracy: 0.8313\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2202 - accuracy: 0.9211 - val_loss: 0.5498 - val_accuracy: 0.8282\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2143 - accuracy: 0.9239 - val_loss: 0.5489 - val_accuracy: 0.8303\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2147 - accuracy: 0.9239 - val_loss: 0.5505 - val_accuracy: 0.8310\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2080 - accuracy: 0.9259 - val_loss: 0.5589 - val_accuracy: 0.8306\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2073 - accuracy: 0.9250 - val_loss: 0.5638 - val_accuracy: 0.8304\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2090 - accuracy: 0.9264 - val_loss: 0.5592 - val_accuracy: 0.8288\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.2025 - accuracy: 0.9277 - val_loss: 0.5546 - val_accuracy: 0.8287\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2029 - accuracy: 0.9267 - val_loss: 0.5542 - val_accuracy: 0.8286\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.2036 - accuracy: 0.9280 - val_loss: 0.5664 - val_accuracy: 0.8284\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1951 - accuracy: 0.9309 - val_loss: 0.5633 - val_accuracy: 0.8302\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.1940 - accuracy: 0.9308 - val_loss: 0.5639 - val_accuracy: 0.8312\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 193s 123ms/step - loss: 0.1923 - accuracy: 0.9312 - val_loss: 0.5712 - val_accuracy: 0.8300\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1895 - accuracy: 0.9341 - val_loss: 0.5642 - val_accuracy: 0.8315\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 191s 123ms/step - loss: 0.1887 - accuracy: 0.9312 - val_loss: 0.5615 - val_accuracy: 0.8338\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1883 - accuracy: 0.9338 - val_loss: 0.5583 - val_accuracy: 0.8316\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1837 - accuracy: 0.9354 - val_loss: 0.5605 - val_accuracy: 0.8312\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.1770 - accuracy: 0.9377 - val_loss: 0.5675 - val_accuracy: 0.8331\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1792 - accuracy: 0.9361 - val_loss: 0.5680 - val_accuracy: 0.8345\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1786 - accuracy: 0.9366 - val_loss: 0.5650 - val_accuracy: 0.8322\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1751 - accuracy: 0.9382 - val_loss: 0.5697 - val_accuracy: 0.8314\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1700 - accuracy: 0.9402 - val_loss: 0.5647 - val_accuracy: 0.8312\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1731 - accuracy: 0.9386 - val_loss: 0.5711 - val_accuracy: 0.8316\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1687 - accuracy: 0.9413 - val_loss: 0.5703 - val_accuracy: 0.8320\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1658 - accuracy: 0.9414 - val_loss: 0.5730 - val_accuracy: 0.8307\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1683 - accuracy: 0.9406 - val_loss: 0.5744 - val_accuracy: 0.8312\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1709 - accuracy: 0.9390 - val_loss: 0.5651 - val_accuracy: 0.8325\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1641 - accuracy: 0.9412 - val_loss: 0.5825 - val_accuracy: 0.8320\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1668 - accuracy: 0.9407 - val_loss: 0.5749 - val_accuracy: 0.8330\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.1603 - accuracy: 0.9442 - val_loss: 0.5687 - val_accuracy: 0.8322\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1608 - accuracy: 0.9431 - val_loss: 0.5715 - val_accuracy: 0.8350\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1597 - accuracy: 0.9433 - val_loss: 0.5742 - val_accuracy: 0.8334\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.1607 - accuracy: 0.9437 - val_loss: 0.5772 - val_accuracy: 0.8338\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1554 - accuracy: 0.9448 - val_loss: 0.5795 - val_accuracy: 0.8339\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1553 - accuracy: 0.9447 - val_loss: 0.5807 - val_accuracy: 0.8341\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1520 - accuracy: 0.9463 - val_loss: 0.5802 - val_accuracy: 0.8324\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.1564 - accuracy: 0.9459 - val_loss: 0.5812 - val_accuracy: 0.8329\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.1541 - accuracy: 0.9448 - val_loss: 0.5822 - val_accuracy: 0.8335\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1559 - accuracy: 0.9446 - val_loss: 0.5796 - val_accuracy: 0.8328\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1524 - accuracy: 0.9468 - val_loss: 0.5829 - val_accuracy: 0.8340\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1470 - accuracy: 0.9474 - val_loss: 0.5784 - val_accuracy: 0.8345\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1496 - accuracy: 0.9467 - val_loss: 0.5781 - val_accuracy: 0.8321\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1481 - accuracy: 0.9476 - val_loss: 0.5842 - val_accuracy: 0.8327\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1440 - accuracy: 0.9490 - val_loss: 0.5810 - val_accuracy: 0.8321\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1493 - accuracy: 0.9462 - val_loss: 0.5897 - val_accuracy: 0.8321\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 0.1442 - accuracy: 0.9490 - val_loss: 0.5782 - val_accuracy: 0.8342\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1464 - accuracy: 0.9482 - val_loss: 0.5843 - val_accuracy: 0.8345\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1419 - accuracy: 0.9502 - val_loss: 0.5838 - val_accuracy: 0.8337\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1481 - accuracy: 0.9473 - val_loss: 0.5853 - val_accuracy: 0.8334\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 193s 123ms/step - loss: 0.1409 - accuracy: 0.9499 - val_loss: 0.5892 - val_accuracy: 0.8348\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1398 - accuracy: 0.9504 - val_loss: 0.5853 - val_accuracy: 0.8349\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.1393 - accuracy: 0.9513 - val_loss: 0.5892 - val_accuracy: 0.8348\n",
      "Epoch 1/100\n",
      "1563/1563 [==============================] - 159s 102ms/step - loss: 2.3538 - accuracy: 0.2195 - val_loss: 2.3296 - val_accuracy: 0.1000\n",
      "Epoch 2/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 1.8165 - accuracy: 0.3295 - val_loss: 2.3067 - val_accuracy: 0.1230\n",
      "Epoch 3/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 1.6286 - accuracy: 0.4020 - val_loss: 2.0098 - val_accuracy: 0.2644\n",
      "Epoch 4/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 1.5028 - accuracy: 0.4510 - val_loss: 1.5904 - val_accuracy: 0.4268\n",
      "Epoch 5/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 1.4197 - accuracy: 0.4826 - val_loss: 1.5828 - val_accuracy: 0.4103\n",
      "Epoch 6/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 1.3784 - accuracy: 0.4977 - val_loss: 1.4971 - val_accuracy: 0.4594\n",
      "Epoch 7/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 1.3327 - accuracy: 0.5175 - val_loss: 1.3660 - val_accuracy: 0.4998\n",
      "Epoch 8/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 1.2616 - accuracy: 0.5462 - val_loss: 1.3170 - val_accuracy: 0.5185\n",
      "Epoch 9/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 1.2202 - accuracy: 0.5610 - val_loss: 1.2986 - val_accuracy: 0.5291\n",
      "Epoch 10/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 1.1590 - accuracy: 0.5817 - val_loss: 1.2333 - val_accuracy: 0.5597\n",
      "Epoch 11/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 1.1158 - accuracy: 0.5986 - val_loss: 1.2262 - val_accuracy: 0.5561\n",
      "Epoch 12/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 1.0765 - accuracy: 0.6161 - val_loss: 1.1606 - val_accuracy: 0.5886\n",
      "Epoch 13/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 1.0349 - accuracy: 0.6268 - val_loss: 1.1411 - val_accuracy: 0.5934\n",
      "Epoch 14/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.9935 - accuracy: 0.6429 - val_loss: 1.1803 - val_accuracy: 0.5758\n",
      "Epoch 15/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.9876 - accuracy: 0.6449 - val_loss: 1.2588 - val_accuracy: 0.5656\n",
      "Epoch 16/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.9927 - accuracy: 0.6453 - val_loss: 1.1827 - val_accuracy: 0.5781\n",
      "Epoch 17/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.9526 - accuracy: 0.6592 - val_loss: 1.2133 - val_accuracy: 0.5713\n",
      "Epoch 18/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.9718 - accuracy: 0.6528 - val_loss: 1.3644 - val_accuracy: 0.5236\n",
      "Epoch 19/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.9548 - accuracy: 0.6595 - val_loss: 1.2142 - val_accuracy: 0.5723\n",
      "Epoch 20/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.9729 - accuracy: 0.6542 - val_loss: 1.4061 - val_accuracy: 0.4958\n",
      "Epoch 21/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.9360 - accuracy: 0.6665 - val_loss: 1.1483 - val_accuracy: 0.5895\n",
      "Epoch 22/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.9268 - accuracy: 0.6716 - val_loss: 1.2183 - val_accuracy: 0.5699\n",
      "Epoch 23/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.8985 - accuracy: 0.6806 - val_loss: 1.2263 - val_accuracy: 0.5654\n",
      "Epoch 24/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.8522 - accuracy: 0.6952 - val_loss: 1.0877 - val_accuracy: 0.6147\n",
      "Epoch 25/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.8982 - accuracy: 0.6784 - val_loss: 1.3152 - val_accuracy: 0.5516\n",
      "Epoch 26/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.8705 - accuracy: 0.6873 - val_loss: 1.0746 - val_accuracy: 0.6217\n",
      "Epoch 27/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.8617 - accuracy: 0.6951 - val_loss: 1.1834 - val_accuracy: 0.5980\n",
      "Epoch 28/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.8130 - accuracy: 0.7100 - val_loss: 1.1432 - val_accuracy: 0.6106\n",
      "Epoch 29/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.7424 - accuracy: 0.7372 - val_loss: 1.0926 - val_accuracy: 0.6207\n",
      "Epoch 30/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.7642 - accuracy: 0.7279 - val_loss: 1.1356 - val_accuracy: 0.6068\n",
      "Epoch 31/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.7339 - accuracy: 0.7411 - val_loss: 1.0771 - val_accuracy: 0.6367\n",
      "Epoch 32/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.7016 - accuracy: 0.7511 - val_loss: 1.1193 - val_accuracy: 0.6216\n",
      "Epoch 33/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.7505 - accuracy: 0.7337 - val_loss: 1.3113 - val_accuracy: 0.5538\n",
      "Epoch 34/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.7159 - accuracy: 0.7433 - val_loss: 1.0922 - val_accuracy: 0.6309\n",
      "Epoch 35/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.6528 - accuracy: 0.7653 - val_loss: 1.0711 - val_accuracy: 0.6492\n",
      "Epoch 36/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.6537 - accuracy: 0.7699 - val_loss: 1.1836 - val_accuracy: 0.6172\n",
      "Epoch 37/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.6321 - accuracy: 0.7754 - val_loss: 1.1129 - val_accuracy: 0.6470\n",
      "Epoch 38/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.5896 - accuracy: 0.7908 - val_loss: 1.0982 - val_accuracy: 0.6456\n",
      "Epoch 39/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.6024 - accuracy: 0.7865 - val_loss: 1.1029 - val_accuracy: 0.6464\n",
      "Epoch 40/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.6055 - accuracy: 0.7852 - val_loss: 1.1116 - val_accuracy: 0.6384\n",
      "Epoch 41/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.5289 - accuracy: 0.8138 - val_loss: 1.1823 - val_accuracy: 0.6276\n",
      "Epoch 42/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.5274 - accuracy: 0.8125 - val_loss: 1.2480 - val_accuracy: 0.6258\n",
      "Epoch 43/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.5131 - accuracy: 0.8185 - val_loss: 1.1502 - val_accuracy: 0.6519\n",
      "Epoch 44/100\n",
      "1563/1563 [==============================] - 159s 101ms/step - loss: 0.4847 - accuracy: 0.8289 - val_loss: 1.1480 - val_accuracy: 0.6478\n",
      "Epoch 45/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.4715 - accuracy: 0.8356 - val_loss: 1.1792 - val_accuracy: 0.6480\n",
      "Epoch 46/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.4306 - accuracy: 0.8483 - val_loss: 1.2289 - val_accuracy: 0.6510\n",
      "Epoch 47/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.4133 - accuracy: 0.8537 - val_loss: 1.2468 - val_accuracy: 0.6440\n",
      "Epoch 48/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.3811 - accuracy: 0.8668 - val_loss: 1.3015 - val_accuracy: 0.6415\n",
      "Epoch 49/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.3830 - accuracy: 0.8650 - val_loss: 1.2907 - val_accuracy: 0.6424\n",
      "Epoch 50/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.3566 - accuracy: 0.8741 - val_loss: 1.2926 - val_accuracy: 0.6464\n",
      "Epoch 51/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.3411 - accuracy: 0.8802 - val_loss: 1.3389 - val_accuracy: 0.6458\n",
      "Epoch 52/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.3164 - accuracy: 0.8895 - val_loss: 1.3272 - val_accuracy: 0.6483\n",
      "Epoch 53/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.3170 - accuracy: 0.8889 - val_loss: 1.3929 - val_accuracy: 0.6449\n",
      "Epoch 54/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.3124 - accuracy: 0.8901 - val_loss: 1.3914 - val_accuracy: 0.6490\n",
      "Epoch 55/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2976 - accuracy: 0.8959 - val_loss: 1.4336 - val_accuracy: 0.6413\n",
      "Epoch 56/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.2793 - accuracy: 0.9018 - val_loss: 1.4300 - val_accuracy: 0.6475\n",
      "Epoch 57/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2669 - accuracy: 0.9074 - val_loss: 1.4643 - val_accuracy: 0.6454\n",
      "Epoch 58/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2690 - accuracy: 0.9052 - val_loss: 1.4539 - val_accuracy: 0.6441\n",
      "Epoch 59/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2543 - accuracy: 0.9115 - val_loss: 1.4826 - val_accuracy: 0.6477\n",
      "Epoch 60/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2401 - accuracy: 0.9165 - val_loss: 1.5144 - val_accuracy: 0.6495\n",
      "Epoch 61/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.2371 - accuracy: 0.9177 - val_loss: 1.5271 - val_accuracy: 0.6407\n",
      "Epoch 62/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.2226 - accuracy: 0.9229 - val_loss: 1.5603 - val_accuracy: 0.6416\n",
      "Epoch 63/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2360 - accuracy: 0.9197 - val_loss: 1.5548 - val_accuracy: 0.6466\n",
      "Epoch 64/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2214 - accuracy: 0.9228 - val_loss: 1.5765 - val_accuracy: 0.6434\n",
      "Epoch 65/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2111 - accuracy: 0.9269 - val_loss: 1.5720 - val_accuracy: 0.6484\n",
      "Epoch 66/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1923 - accuracy: 0.9333 - val_loss: 1.6154 - val_accuracy: 0.6487\n",
      "Epoch 67/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1878 - accuracy: 0.9354 - val_loss: 1.6827 - val_accuracy: 0.6413\n",
      "Epoch 68/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.2478 - accuracy: 0.9157 - val_loss: 1.5587 - val_accuracy: 0.6510\n",
      "Epoch 69/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1984 - accuracy: 0.9317 - val_loss: 1.6370 - val_accuracy: 0.6424\n",
      "Epoch 70/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1934 - accuracy: 0.9331 - val_loss: 1.6343 - val_accuracy: 0.6486\n",
      "Epoch 71/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1822 - accuracy: 0.9362 - val_loss: 1.6547 - val_accuracy: 0.6452\n",
      "Epoch 72/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1581 - accuracy: 0.9459 - val_loss: 1.6882 - val_accuracy: 0.6507\n",
      "Epoch 73/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1683 - accuracy: 0.9417 - val_loss: 1.6635 - val_accuracy: 0.6484\n",
      "Epoch 74/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1566 - accuracy: 0.9452 - val_loss: 1.7348 - val_accuracy: 0.6465\n",
      "Epoch 75/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1641 - accuracy: 0.9431 - val_loss: 1.7666 - val_accuracy: 0.6271\n",
      "Epoch 76/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1620 - accuracy: 0.9438 - val_loss: 1.7104 - val_accuracy: 0.6461\n",
      "Epoch 77/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1431 - accuracy: 0.9506 - val_loss: 1.7446 - val_accuracy: 0.6524\n",
      "Epoch 78/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1487 - accuracy: 0.9480 - val_loss: 1.7516 - val_accuracy: 0.6462\n",
      "Epoch 79/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1391 - accuracy: 0.9515 - val_loss: 1.7475 - val_accuracy: 0.6551\n",
      "Epoch 80/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1249 - accuracy: 0.9568 - val_loss: 1.7844 - val_accuracy: 0.6405\n",
      "Epoch 81/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.1176 - accuracy: 0.9588 - val_loss: 1.8183 - val_accuracy: 0.6438\n",
      "Epoch 82/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1155 - accuracy: 0.9591 - val_loss: 1.8336 - val_accuracy: 0.6475\n",
      "Epoch 83/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1112 - accuracy: 0.9607 - val_loss: 1.8526 - val_accuracy: 0.6486\n",
      "Epoch 84/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1215 - accuracy: 0.9577 - val_loss: 1.8313 - val_accuracy: 0.6520\n",
      "Epoch 85/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.1145 - accuracy: 0.9604 - val_loss: 1.8480 - val_accuracy: 0.6481\n",
      "Epoch 86/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1294 - accuracy: 0.9558 - val_loss: 1.8156 - val_accuracy: 0.6448\n",
      "Epoch 87/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1259 - accuracy: 0.9565 - val_loss: 1.7913 - val_accuracy: 0.6525\n",
      "Epoch 88/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1232 - accuracy: 0.9588 - val_loss: 1.7964 - val_accuracy: 0.6465\n",
      "Epoch 89/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.1242 - accuracy: 0.9567 - val_loss: 1.8134 - val_accuracy: 0.6468\n",
      "Epoch 90/100\n",
      "1563/1563 [==============================] - 157s 100ms/step - loss: 0.1051 - accuracy: 0.9638 - val_loss: 1.8709 - val_accuracy: 0.6454\n",
      "Epoch 91/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.1110 - accuracy: 0.9610 - val_loss: 1.8880 - val_accuracy: 0.6491\n",
      "Epoch 92/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.0965 - accuracy: 0.9667 - val_loss: 1.8732 - val_accuracy: 0.6540\n",
      "Epoch 93/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.0943 - accuracy: 0.9674 - val_loss: 1.9222 - val_accuracy: 0.6503\n",
      "Epoch 94/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.0908 - accuracy: 0.9688 - val_loss: 1.9438 - val_accuracy: 0.6494\n",
      "Epoch 95/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.0862 - accuracy: 0.9699 - val_loss: 1.9076 - val_accuracy: 0.6506\n",
      "Epoch 96/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.0826 - accuracy: 0.9714 - val_loss: 1.9537 - val_accuracy: 0.6480\n",
      "Epoch 97/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.0850 - accuracy: 0.9702 - val_loss: 1.9573 - val_accuracy: 0.6528\n",
      "Epoch 98/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.0784 - accuracy: 0.9734 - val_loss: 1.9901 - val_accuracy: 0.6565\n",
      "Epoch 99/100\n",
      "1563/1563 [==============================] - 157s 101ms/step - loss: 0.0801 - accuracy: 0.9722 - val_loss: 1.9900 - val_accuracy: 0.6557\n",
      "Epoch 100/100\n",
      "1563/1563 [==============================] - 158s 101ms/step - loss: 0.0759 - accuracy: 0.9739 - val_loss: 1.9706 - val_accuracy: 0.6534\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shapey</th>\n",
       "      <th>shapex</th>\n",
       "      <th>shapez</th>\n",
       "      <th>train size</th>\n",
       "      <th>test size</th>\n",
       "      <th>num epochs</th>\n",
       "      <th>lenet runtime</th>\n",
       "      <th>lenet test err</th>\n",
       "      <th>lenet history</th>\n",
       "      <th>vgg runtime</th>\n",
       "      <th>vgg test err</th>\n",
       "      <th>vgg history</th>\n",
       "      <th>mobilenet runtime</th>\n",
       "      <th>mobilenet test err</th>\n",
       "      <th>mobilenet history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>905.454609</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>{'loss': [1.7826309204101562, 1.45772171020507...</td>\n",
       "      <td>19137.917245</td>\n",
       "      <td>0.8348</td>\n",
       "      <td>{'loss': [1.8757611513137817, 1.21302139759063...</td>\n",
       "      <td>15757.714642</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>{'loss': [2.3537964820861816, 1.81646561622619...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  shapey  shapex  shapez  train size  test size  num epochs  \\\n",
       "0  cifar10      32      32       3       50000      10000         100   \n",
       "\n",
       "   lenet runtime  lenet test err  \\\n",
       "0     905.454609          0.5862   \n",
       "\n",
       "                                       lenet history   vgg runtime  \\\n",
       "0  {'loss': [1.7826309204101562, 1.45772171020507...  19137.917245   \n",
       "\n",
       "   vgg test err                                        vgg history  \\\n",
       "0        0.8348  {'loss': [1.8757611513137817, 1.21302139759063...   \n",
       "\n",
       "   mobilenet runtime  mobilenet test err  \\\n",
       "0       15757.714642              0.6534   \n",
       "\n",
       "                                   mobilenet history  \n",
       "0  {'loss': [2.3537964820861816, 1.81646561622619...  "
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cifar = evaluate_dataset('cifar10', num_epochs=100)\n",
    "df_cifar.to_pickle('df_cifar.pkl')\n",
    "df_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shapey</th>\n",
       "      <th>shapex</th>\n",
       "      <th>shapez</th>\n",
       "      <th>train size</th>\n",
       "      <th>test size</th>\n",
       "      <th>num epochs</th>\n",
       "      <th>lenet runtime</th>\n",
       "      <th>lenet test err</th>\n",
       "      <th>lenet history</th>\n",
       "      <th>vgg runtime</th>\n",
       "      <th>vgg test err</th>\n",
       "      <th>vgg history</th>\n",
       "      <th>mobilenet runtime</th>\n",
       "      <th>mobilenet test err</th>\n",
       "      <th>mobilenet history</th>\n",
       "      <th>convsvm runtime</th>\n",
       "      <th>convsvm test err</th>\n",
       "      <th>convsvm history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>905.454609</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>{'loss': [1.7826309204101562, 1.45772171020507...</td>\n",
       "      <td>19137.917245</td>\n",
       "      <td>0.8348</td>\n",
       "      <td>{'loss': [1.8757611513137817, 1.21302139759063...</td>\n",
       "      <td>15757.714642</td>\n",
       "      <td>0.6534</td>\n",
       "      <td>{'loss': [2.3537964820861816, 1.81646561622619...</td>\n",
       "      <td>842.1628</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>{'accuracy': [0.44272], 'val_accuracy': [0.3582]}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name  shapey  shapex  shapez  train size  test size  num epochs  \\\n",
       "0  cifar10      32      32       3       50000      10000         100   \n",
       "\n",
       "   lenet runtime  lenet test err  \\\n",
       "0     905.454609          0.5862   \n",
       "\n",
       "                                       lenet history   vgg runtime  \\\n",
       "0  {'loss': [1.7826309204101562, 1.45772171020507...  19137.917245   \n",
       "\n",
       "   vgg test err                                        vgg history  \\\n",
       "0        0.8348  {'loss': [1.8757611513137817, 1.21302139759063...   \n",
       "\n",
       "   mobilenet runtime  mobilenet test err  \\\n",
       "0       15757.714642              0.6534   \n",
       "\n",
       "                                   mobilenet history  convsvm runtime  \\\n",
       "0  {'loss': [2.3537964820861816, 1.81646561622619...         842.1628   \n",
       "\n",
       "   convsvm test err                                    convsvm history  \n",
       "0            0.3582  {'accuracy': [0.44272], 'val_accuracy': [0.3582]}  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cifar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breast Cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc = pd.read_pickle('df_bcancer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc['convsvm runtime'] = df_bc_csvm['convsvm runtime']\n",
    "df_bc['convsvm test err'] = df_bc_csvm['convsvm test err']\n",
    "df_bc['convsvm history'] = df_bc_csvm['convsvm history']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_train_y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39652, 50, 50, 3), (39652,))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc_train_x.shape, bc_train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Layer weight shape (1936, 120) not compatible with provided weight shape (576, 120)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-0932be315f83>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbc_train_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbc_train_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbc_test_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbc_test_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf_bc_csvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mdf_bc_csvm\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-276e346ea110>\u001b[0m in \u001b[0;36mevaluate_dataset\u001b[1;34m(db_name, num_epochs)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m     \u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'convsvm runtime'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'convsvm'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtestx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtesty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'convsvm test err'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_accuracy'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'convsvm history'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-82190025da37>\u001b[0m in \u001b[0;36mevaluate_model\u001b[1;34m(model_name, trainx, trainy, testx, testy, num_epochs)\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_mobilenmetv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'convsvm'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_convsvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-27136d912557>\u001b[0m in \u001b[0;36mcreate_convsvm\u001b[1;34m(input_shape)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcreate_convsvm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mConv_SVM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-b5d399a681b7>\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_shape, location)\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_load_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-b5d399a681b7>\u001b[0m in \u001b[0;36m_load_model\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlenet_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_layer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnew_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[1;34m(self, weights)\u001b[0m\n\u001b[0;32m   1822\u001b[0m         \u001b[0mref_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1823\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mref_shape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1824\u001b[1;33m           raise ValueError(\n\u001b[0m\u001b[0;32m   1825\u001b[0m               \u001b[1;34m'Layer weight shape %s not compatible with provided weight '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1826\u001b[0m               'shape %s' % (ref_shape, weight.shape))\n",
      "\u001b[1;31mValueError\u001b[0m: Layer weight shape (1936, 120) not compatible with provided weight shape (576, 120)"
     ]
    }
   ],
   "source": [
    "data = (bc_train_x,bc_train_y,bc_test_x,bc_test_y)\n",
    "df_bc_csvm = evaluate_dataset(data, num_epochs=100)\n",
    "df_bc_csvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.4967 - accuracy: 0.7750 - val_loss: 0.4111 - val_accuracy: 0.8220\n",
      "Epoch 2/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.4188 - accuracy: 0.8212 - val_loss: 0.4925 - val_accuracy: 0.7920\n",
      "Epoch 3/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.4071 - accuracy: 0.8244 - val_loss: 0.3912 - val_accuracy: 0.8287\n",
      "Epoch 4/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.3944 - accuracy: 0.8299 - val_loss: 0.4040 - val_accuracy: 0.8223\n",
      "Epoch 5/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.3890 - accuracy: 0.8336 - val_loss: 0.3970 - val_accuracy: 0.8272\n",
      "Epoch 6/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.3783 - accuracy: 0.8382 - val_loss: 0.3813 - val_accuracy: 0.8344\n",
      "Epoch 7/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.3716 - accuracy: 0.8437 - val_loss: 0.3757 - val_accuracy: 0.8387\n",
      "Epoch 8/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.3650 - accuracy: 0.8449 - val_loss: 0.3753 - val_accuracy: 0.8399\n",
      "Epoch 9/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.3576 - accuracy: 0.8485 - val_loss: 0.3749 - val_accuracy: 0.8439\n",
      "Epoch 10/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.3513 - accuracy: 0.8518 - val_loss: 0.3993 - val_accuracy: 0.8251\n",
      "Epoch 11/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.3445 - accuracy: 0.8558 - val_loss: 0.3630 - val_accuracy: 0.8417\n",
      "Epoch 12/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.3364 - accuracy: 0.8596 - val_loss: 0.3676 - val_accuracy: 0.8388\n",
      "Epoch 13/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.3287 - accuracy: 0.8631 - val_loss: 0.3695 - val_accuracy: 0.8399\n",
      "Epoch 14/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.3195 - accuracy: 0.8689 - val_loss: 0.3848 - val_accuracy: 0.8371\n",
      "Epoch 15/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.3075 - accuracy: 0.8758 - val_loss: 0.3760 - val_accuracy: 0.8416\n",
      "Epoch 16/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.2934 - accuracy: 0.8814 - val_loss: 0.3774 - val_accuracy: 0.8407\n",
      "Epoch 17/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.2802 - accuracy: 0.8881 - val_loss: 0.4159 - val_accuracy: 0.8283\n",
      "Epoch 18/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.2648 - accuracy: 0.8952 - val_loss: 0.3944 - val_accuracy: 0.8368\n",
      "Epoch 19/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.2469 - accuracy: 0.9033 - val_loss: 0.4353 - val_accuracy: 0.8208\n",
      "Epoch 20/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.2272 - accuracy: 0.9129 - val_loss: 0.4440 - val_accuracy: 0.8323\n",
      "Epoch 21/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.2088 - accuracy: 0.9216 - val_loss: 0.4716 - val_accuracy: 0.8291\n",
      "Epoch 22/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.1896 - accuracy: 0.9299 - val_loss: 0.5198 - val_accuracy: 0.8265\n",
      "Epoch 23/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.1742 - accuracy: 0.9367 - val_loss: 0.5377 - val_accuracy: 0.8203\n",
      "Epoch 24/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.1542 - accuracy: 0.9434 - val_loss: 0.5842 - val_accuracy: 0.8148\n",
      "Epoch 25/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.1367 - accuracy: 0.9514 - val_loss: 0.6033 - val_accuracy: 0.8154\n",
      "Epoch 26/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.1260 - accuracy: 0.9545 - val_loss: 0.6788 - val_accuracy: 0.8116\n",
      "Epoch 27/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.1142 - accuracy: 0.9589 - val_loss: 0.7046 - val_accuracy: 0.8194\n",
      "Epoch 28/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0963 - accuracy: 0.9653 - val_loss: 0.7799 - val_accuracy: 0.8171\n",
      "Epoch 29/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0865 - accuracy: 0.9696 - val_loss: 0.8861 - val_accuracy: 0.8099\n",
      "Epoch 30/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0739 - accuracy: 0.9742 - val_loss: 0.8541 - val_accuracy: 0.8193\n",
      "Epoch 31/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0638 - accuracy: 0.9780 - val_loss: 0.9334 - val_accuracy: 0.8135\n",
      "Epoch 32/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0608 - accuracy: 0.9786 - val_loss: 1.0246 - val_accuracy: 0.8088\n",
      "Epoch 33/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0488 - accuracy: 0.9837 - val_loss: 1.0365 - val_accuracy: 0.8197\n",
      "Epoch 34/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0435 - accuracy: 0.9851 - val_loss: 1.1093 - val_accuracy: 0.8139\n",
      "Epoch 35/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0342 - accuracy: 0.9893 - val_loss: 1.1176 - val_accuracy: 0.8107\n",
      "Epoch 36/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0310 - accuracy: 0.9899 - val_loss: 1.1719 - val_accuracy: 0.8150\n",
      "Epoch 37/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0251 - accuracy: 0.9921 - val_loss: 1.2539 - val_accuracy: 0.8159\n",
      "Epoch 38/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0186 - accuracy: 0.9947 - val_loss: 1.3459 - val_accuracy: 0.8144\n",
      "Epoch 39/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0169 - accuracy: 0.9946 - val_loss: 1.3502 - val_accuracy: 0.8158\n",
      "Epoch 40/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0131 - accuracy: 0.9962 - val_loss: 1.4201 - val_accuracy: 0.8166\n",
      "Epoch 41/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0109 - accuracy: 0.9968 - val_loss: 1.4279 - val_accuracy: 0.8162\n",
      "Epoch 42/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0096 - accuracy: 0.9974 - val_loss: 1.5268 - val_accuracy: 0.8207\n",
      "Epoch 43/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 1.6065 - val_accuracy: 0.8202\n",
      "Epoch 44/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 1.5961 - val_accuracy: 0.8210\n",
      "Epoch 45/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0069 - accuracy: 0.9979 - val_loss: 1.6091 - val_accuracy: 0.8185\n",
      "Epoch 46/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0061 - accuracy: 0.9980 - val_loss: 1.6855 - val_accuracy: 0.8180\n",
      "Epoch 47/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0056 - accuracy: 0.9984 - val_loss: 1.6510 - val_accuracy: 0.8163\n",
      "Epoch 48/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0051 - accuracy: 0.9983 - val_loss: 1.7135 - val_accuracy: 0.8181\n",
      "Epoch 49/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0045 - accuracy: 0.9986 - val_loss: 1.7537 - val_accuracy: 0.8186\n",
      "Epoch 50/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0039 - accuracy: 0.9989 - val_loss: 1.7761 - val_accuracy: 0.8177\n",
      "Epoch 51/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0037 - accuracy: 0.9989 - val_loss: 1.8214 - val_accuracy: 0.8207\n",
      "Epoch 52/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 1.8428 - val_accuracy: 0.8153\n",
      "Epoch 53/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0032 - accuracy: 0.9991 - val_loss: 1.8621 - val_accuracy: 0.8170\n",
      "Epoch 54/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 1.8871 - val_accuracy: 0.8197\n",
      "Epoch 55/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0028 - accuracy: 0.9993 - val_loss: 1.9041 - val_accuracy: 0.8171\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0025 - accuracy: 0.9994 - val_loss: 1.9035 - val_accuracy: 0.8168\n",
      "Epoch 57/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0024 - accuracy: 0.9994 - val_loss: 1.9412 - val_accuracy: 0.8181\n",
      "Epoch 58/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.9717 - val_accuracy: 0.8180\n",
      "Epoch 59/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0020 - accuracy: 0.9995 - val_loss: 1.9725 - val_accuracy: 0.8174\n",
      "Epoch 60/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0019 - accuracy: 0.9996 - val_loss: 2.0011 - val_accuracy: 0.8168\n",
      "Epoch 61/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0017 - accuracy: 0.9995 - val_loss: 2.0162 - val_accuracy: 0.8168\n",
      "Epoch 62/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0017 - accuracy: 0.9996 - val_loss: 2.0406 - val_accuracy: 0.8162\n",
      "Epoch 63/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 2.0453 - val_accuracy: 0.8161\n",
      "Epoch 64/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0015 - accuracy: 0.9997 - val_loss: 2.0539 - val_accuracy: 0.8184\n",
      "Epoch 65/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0014 - accuracy: 0.9996 - val_loss: 2.0841 - val_accuracy: 0.8169\n",
      "Epoch 66/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 0.0015 - accuracy: 0.9996 - val_loss: 2.0953 - val_accuracy: 0.8174\n",
      "Epoch 67/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 2.1023 - val_accuracy: 0.8169\n",
      "Epoch 68/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0013 - accuracy: 0.9997 - val_loss: 2.1041 - val_accuracy: 0.8188\n",
      "Epoch 69/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0012 - accuracy: 0.9998 - val_loss: 2.1143 - val_accuracy: 0.8176\n",
      "Epoch 70/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.1409 - val_accuracy: 0.8149\n",
      "Epoch 71/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 2.1394 - val_accuracy: 0.8188\n",
      "Epoch 72/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 2.1431 - val_accuracy: 0.8182\n",
      "Epoch 73/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 9.9264e-04 - accuracy: 0.9998 - val_loss: 2.1604 - val_accuracy: 0.8168\n",
      "Epoch 74/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 9.3686e-04 - accuracy: 0.9998 - val_loss: 2.1791 - val_accuracy: 0.8189\n",
      "Epoch 75/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 0.0011 - accuracy: 0.9997 - val_loss: 2.1875 - val_accuracy: 0.8177\n",
      "Epoch 76/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 9.6367e-04 - accuracy: 0.9997 - val_loss: 2.1786 - val_accuracy: 0.8175\n",
      "Epoch 77/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 8.6487e-04 - accuracy: 0.9998 - val_loss: 2.1960 - val_accuracy: 0.8169\n",
      "Epoch 78/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 8.6997e-04 - accuracy: 0.9998 - val_loss: 2.2115 - val_accuracy: 0.8183\n",
      "Epoch 79/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 7.6868e-04 - accuracy: 0.9999 - val_loss: 2.2097 - val_accuracy: 0.8174\n",
      "Epoch 80/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 8.5607e-04 - accuracy: 0.9998 - val_loss: 2.2173 - val_accuracy: 0.8165\n",
      "Epoch 81/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 7.5724e-04 - accuracy: 0.9999 - val_loss: 2.2433 - val_accuracy: 0.8154\n",
      "Epoch 82/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 7.6672e-04 - accuracy: 0.9999 - val_loss: 2.2343 - val_accuracy: 0.8168\n",
      "Epoch 83/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 7.4049e-04 - accuracy: 0.9998 - val_loss: 2.2538 - val_accuracy: 0.8164\n",
      "Epoch 84/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 7.3247e-04 - accuracy: 0.9998 - val_loss: 2.2593 - val_accuracy: 0.8173\n",
      "Epoch 85/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 7.0748e-04 - accuracy: 0.9998 - val_loss: 2.2569 - val_accuracy: 0.8169\n",
      "Epoch 86/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 7.0355e-04 - accuracy: 0.9998 - val_loss: 2.2608 - val_accuracy: 0.8163\n",
      "Epoch 87/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 6.6504e-04 - accuracy: 0.9998 - val_loss: 2.2687 - val_accuracy: 0.8173\n",
      "Epoch 88/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 6.9907e-04 - accuracy: 0.9998 - val_loss: 2.2776 - val_accuracy: 0.8173\n",
      "Epoch 89/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 6.4344e-04 - accuracy: 0.9999 - val_loss: 2.2800 - val_accuracy: 0.8169\n",
      "Epoch 90/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 5.7368e-04 - accuracy: 0.9999 - val_loss: 2.2894 - val_accuracy: 0.8173\n",
      "Epoch 91/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 6.5120e-04 - accuracy: 0.9999 - val_loss: 2.2944 - val_accuracy: 0.8172\n",
      "Epoch 92/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 6.2854e-04 - accuracy: 0.9998 - val_loss: 2.2963 - val_accuracy: 0.8168\n",
      "Epoch 93/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 5.7197e-04 - accuracy: 0.9999 - val_loss: 2.3109 - val_accuracy: 0.8170\n",
      "Epoch 94/100\n",
      "1240/1240 [==============================] - 15s 12ms/step - loss: 5.7208e-04 - accuracy: 0.9999 - val_loss: 2.3016 - val_accuracy: 0.8172\n",
      "Epoch 95/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 5.7006e-04 - accuracy: 0.9999 - val_loss: 2.3061 - val_accuracy: 0.8166\n",
      "Epoch 96/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 5.5210e-04 - accuracy: 0.9999 - val_loss: 2.3126 - val_accuracy: 0.8171\n",
      "Epoch 97/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 5.7162e-04 - accuracy: 0.9999 - val_loss: 2.3244 - val_accuracy: 0.8169\n",
      "Epoch 98/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 5.2700e-04 - accuracy: 0.9999 - val_loss: 2.3307 - val_accuracy: 0.8171\n",
      "Epoch 99/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 5.3366e-04 - accuracy: 0.9999 - val_loss: 2.3333 - val_accuracy: 0.8171\n",
      "Epoch 100/100\n",
      "1240/1240 [==============================] - 16s 13ms/step - loss: 4.7625e-04 - accuracy: 0.9999 - val_loss: 2.3298 - val_accuracy: 0.8159\n",
      "Epoch 1/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.7389 - accuracy: 0.7866 - val_loss: 1.3079 - val_accuracy: 0.7945\n",
      "Epoch 2/100\n",
      "1240/1240 [==============================] - 322s 259ms/step - loss: 0.4794 - accuracy: 0.8124 - val_loss: 2.5814 - val_accuracy: 0.7355\n",
      "Epoch 3/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.4036 - accuracy: 0.8307 - val_loss: 0.5525 - val_accuracy: 0.7388\n",
      "Epoch 4/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3802 - accuracy: 0.8403 - val_loss: 0.3516 - val_accuracy: 0.8474\n",
      "Epoch 5/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3658 - accuracy: 0.8464 - val_loss: 0.3650 - val_accuracy: 0.8544\n",
      "Epoch 6/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3536 - accuracy: 0.8508 - val_loss: 0.5603 - val_accuracy: 0.8160\n",
      "Epoch 7/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.3489 - accuracy: 0.8553 - val_loss: 0.3415 - val_accuracy: 0.8544\n",
      "Epoch 8/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.3390 - accuracy: 0.8573 - val_loss: 1.0685 - val_accuracy: 0.7589\n",
      "Epoch 9/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.3413 - accuracy: 0.8575 - val_loss: 0.3725 - val_accuracy: 0.8587\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3358 - accuracy: 0.8582 - val_loss: 0.5449 - val_accuracy: 0.8123\n",
      "Epoch 11/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.3295 - accuracy: 0.8604 - val_loss: 1.1781 - val_accuracy: 0.7807\n",
      "Epoch 12/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3256 - accuracy: 0.8633 - val_loss: 0.3690 - val_accuracy: 0.8505\n",
      "Epoch 13/100\n",
      "1240/1240 [==============================] - 325s 262ms/step - loss: 0.3189 - accuracy: 0.8649 - val_loss: 0.3324 - val_accuracy: 0.8577\n",
      "Epoch 14/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3219 - accuracy: 0.8629 - val_loss: 0.3246 - val_accuracy: 0.8652\n",
      "Epoch 15/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3165 - accuracy: 0.8661 - val_loss: 0.3586 - val_accuracy: 0.8612\n",
      "Epoch 16/100\n",
      "1240/1240 [==============================] - 324s 261ms/step - loss: 0.3126 - accuracy: 0.8676 - val_loss: 0.3192 - val_accuracy: 0.8713\n",
      "Epoch 17/100\n",
      "1240/1240 [==============================] - 322s 259ms/step - loss: 0.3107 - accuracy: 0.8685 - val_loss: 0.3171 - val_accuracy: 0.8680\n",
      "Epoch 18/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.3090 - accuracy: 0.8702 - val_loss: 0.3618 - val_accuracy: 0.8515\n",
      "Epoch 19/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.3076 - accuracy: 0.8712 - val_loss: 0.3269 - val_accuracy: 0.8692\n",
      "Epoch 20/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.3036 - accuracy: 0.8720 - val_loss: 0.3620 - val_accuracy: 0.8537\n",
      "Epoch 21/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.3039 - accuracy: 0.8709 - val_loss: 0.3175 - val_accuracy: 0.8695\n",
      "Epoch 22/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2992 - accuracy: 0.8730 - val_loss: 0.3112 - val_accuracy: 0.8709\n",
      "Epoch 23/100\n",
      "1240/1240 [==============================] - 319s 258ms/step - loss: 0.2974 - accuracy: 0.8749 - val_loss: 0.3380 - val_accuracy: 0.8645\n",
      "Epoch 24/100\n",
      "1240/1240 [==============================] - 325s 262ms/step - loss: 0.2950 - accuracy: 0.8767 - val_loss: 0.3267 - val_accuracy: 0.8600\n",
      "Epoch 25/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2908 - accuracy: 0.8772 - val_loss: 0.3095 - val_accuracy: 0.8694\n",
      "Epoch 26/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2904 - accuracy: 0.8762 - val_loss: 0.3055 - val_accuracy: 0.8732\n",
      "Epoch 27/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2888 - accuracy: 0.8786 - val_loss: 0.3492 - val_accuracy: 0.8679\n",
      "Epoch 28/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.2934 - accuracy: 0.8771 - val_loss: 0.3299 - val_accuracy: 0.8616\n",
      "Epoch 29/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2877 - accuracy: 0.8794 - val_loss: 0.3220 - val_accuracy: 0.8709\n",
      "Epoch 30/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2853 - accuracy: 0.8800 - val_loss: 0.3411 - val_accuracy: 0.8593\n",
      "Epoch 31/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2843 - accuracy: 0.8806 - val_loss: 0.8162 - val_accuracy: 0.8284\n",
      "Epoch 32/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2894 - accuracy: 0.8802 - val_loss: 0.3015 - val_accuracy: 0.8721\n",
      "Epoch 33/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2831 - accuracy: 0.8815 - val_loss: 0.3135 - val_accuracy: 0.8665\n",
      "Epoch 34/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2814 - accuracy: 0.8823 - val_loss: 0.3385 - val_accuracy: 0.8685\n",
      "Epoch 35/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2804 - accuracy: 0.8822 - val_loss: 0.3004 - val_accuracy: 0.8734\n",
      "Epoch 36/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2779 - accuracy: 0.8828 - val_loss: 0.3451 - val_accuracy: 0.8677\n",
      "Epoch 37/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2769 - accuracy: 0.8851 - val_loss: 0.3147 - val_accuracy: 0.8705\n",
      "Epoch 38/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2709 - accuracy: 0.8877 - val_loss: 0.3263 - val_accuracy: 0.8671\n",
      "Epoch 39/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2723 - accuracy: 0.8857 - val_loss: 0.3165 - val_accuracy: 0.8708\n",
      "Epoch 40/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2698 - accuracy: 0.8871 - val_loss: 0.3539 - val_accuracy: 0.8627\n",
      "Epoch 41/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2670 - accuracy: 0.8882 - val_loss: 0.3253 - val_accuracy: 0.8706\n",
      "Epoch 42/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2647 - accuracy: 0.8883 - val_loss: 0.3319 - val_accuracy: 0.8697\n",
      "Epoch 43/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2663 - accuracy: 0.8881 - val_loss: 0.3152 - val_accuracy: 0.8713\n",
      "Epoch 44/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.2626 - accuracy: 0.8910 - val_loss: 0.3161 - val_accuracy: 0.8724\n",
      "Epoch 45/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2619 - accuracy: 0.8895 - val_loss: 0.3032 - val_accuracy: 0.8738\n",
      "Epoch 46/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.2611 - accuracy: 0.8917 - val_loss: 0.3755 - val_accuracy: 0.8637\n",
      "Epoch 47/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2591 - accuracy: 0.8921 - val_loss: 0.3239 - val_accuracy: 0.8632\n",
      "Epoch 48/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2551 - accuracy: 0.8936 - val_loss: 0.3442 - val_accuracy: 0.8645\n",
      "Epoch 49/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2536 - accuracy: 0.8941 - val_loss: 0.3375 - val_accuracy: 0.8557\n",
      "Epoch 50/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.2518 - accuracy: 0.8951 - val_loss: 0.3408 - val_accuracy: 0.8615\n",
      "Epoch 51/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2499 - accuracy: 0.8968 - val_loss: 0.3325 - val_accuracy: 0.8656\n",
      "Epoch 52/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2481 - accuracy: 0.8975 - val_loss: 0.3062 - val_accuracy: 0.8710\n",
      "Epoch 53/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2445 - accuracy: 0.8968 - val_loss: 0.3193 - val_accuracy: 0.8746\n",
      "Epoch 54/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2441 - accuracy: 0.8989 - val_loss: 0.3145 - val_accuracy: 0.8728\n",
      "Epoch 55/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2431 - accuracy: 0.8993 - val_loss: 0.4072 - val_accuracy: 0.8187\n",
      "Epoch 56/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2442 - accuracy: 0.8987 - val_loss: 0.3339 - val_accuracy: 0.8711\n",
      "Epoch 57/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2389 - accuracy: 0.9000 - val_loss: 0.3356 - val_accuracy: 0.8716\n",
      "Epoch 58/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.2397 - accuracy: 0.9011 - val_loss: 0.3185 - val_accuracy: 0.8627\n",
      "Epoch 59/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2388 - accuracy: 0.9003 - val_loss: 0.3352 - val_accuracy: 0.8692\n",
      "Epoch 60/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2395 - accuracy: 0.9009 - val_loss: 0.3243 - val_accuracy: 0.8737\n",
      "Epoch 61/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.2370 - accuracy: 0.9021 - val_loss: 0.3335 - val_accuracy: 0.8583\n",
      "Epoch 62/100\n",
      "1240/1240 [==============================] - 322s 259ms/step - loss: 0.2305 - accuracy: 0.9044 - val_loss: 0.3204 - val_accuracy: 0.8725\n",
      "Epoch 63/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2293 - accuracy: 0.9036 - val_loss: 0.3260 - val_accuracy: 0.8713\n",
      "Epoch 64/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2304 - accuracy: 0.9049 - val_loss: 0.3330 - val_accuracy: 0.8701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/100\n",
      "1240/1240 [==============================] - 319s 258ms/step - loss: 0.2263 - accuracy: 0.9055 - val_loss: 0.3258 - val_accuracy: 0.8672\n",
      "Epoch 66/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2245 - accuracy: 0.9079 - val_loss: 0.3601 - val_accuracy: 0.8514\n",
      "Epoch 67/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2221 - accuracy: 0.9062 - val_loss: 0.3637 - val_accuracy: 0.8588\n",
      "Epoch 68/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2224 - accuracy: 0.9084 - val_loss: 0.3780 - val_accuracy: 0.8446\n",
      "Epoch 69/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2156 - accuracy: 0.9077 - val_loss: 0.3507 - val_accuracy: 0.8684\n",
      "Epoch 70/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2171 - accuracy: 0.9101 - val_loss: 0.3189 - val_accuracy: 0.8702\n",
      "Epoch 71/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2144 - accuracy: 0.9121 - val_loss: 0.3492 - val_accuracy: 0.8709\n",
      "Epoch 72/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2132 - accuracy: 0.9111 - val_loss: 0.3318 - val_accuracy: 0.8645\n",
      "Epoch 73/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2116 - accuracy: 0.9122 - val_loss: 0.3283 - val_accuracy: 0.8752\n",
      "Epoch 74/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2090 - accuracy: 0.9125 - val_loss: 0.3504 - val_accuracy: 0.8597\n",
      "Epoch 75/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2122 - accuracy: 0.9121 - val_loss: 0.3332 - val_accuracy: 0.8667\n",
      "Epoch 76/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2074 - accuracy: 0.9139 - val_loss: 0.3609 - val_accuracy: 0.8656\n",
      "Epoch 77/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2034 - accuracy: 0.9157 - val_loss: 0.3306 - val_accuracy: 0.8708\n",
      "Epoch 78/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.2001 - accuracy: 0.9169 - val_loss: 0.3687 - val_accuracy: 0.8712\n",
      "Epoch 79/100\n",
      "1240/1240 [==============================] - 319s 258ms/step - loss: 0.1986 - accuracy: 0.9186 - val_loss: 0.3530 - val_accuracy: 0.8683\n",
      "Epoch 80/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.2009 - accuracy: 0.9174 - val_loss: 0.3662 - val_accuracy: 0.8611\n",
      "Epoch 81/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.1961 - accuracy: 0.9194 - val_loss: 0.3629 - val_accuracy: 0.8676\n",
      "Epoch 82/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1947 - accuracy: 0.9191 - val_loss: 0.3853 - val_accuracy: 0.8580\n",
      "Epoch 83/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1938 - accuracy: 0.9200 - val_loss: 0.3763 - val_accuracy: 0.8612\n",
      "Epoch 84/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.1915 - accuracy: 0.9221 - val_loss: 0.4012 - val_accuracy: 0.8486\n",
      "Epoch 85/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.1933 - accuracy: 0.9188 - val_loss: 0.3731 - val_accuracy: 0.8698\n",
      "Epoch 86/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1910 - accuracy: 0.9220 - val_loss: 0.3477 - val_accuracy: 0.8662\n",
      "Epoch 87/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1913 - accuracy: 0.9221 - val_loss: 0.3529 - val_accuracy: 0.8708\n",
      "Epoch 88/100\n",
      "1240/1240 [==============================] - 319s 258ms/step - loss: 0.1897 - accuracy: 0.9212 - val_loss: 0.3879 - val_accuracy: 0.8616\n",
      "Epoch 89/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1841 - accuracy: 0.9240 - val_loss: 0.3489 - val_accuracy: 0.8698\n",
      "Epoch 90/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1813 - accuracy: 0.9257 - val_loss: 0.3845 - val_accuracy: 0.8721\n",
      "Epoch 91/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1845 - accuracy: 0.9240 - val_loss: 0.3709 - val_accuracy: 0.8519\n",
      "Epoch 92/100\n",
      "1240/1240 [==============================] - 321s 258ms/step - loss: 0.1806 - accuracy: 0.9264 - val_loss: 0.3406 - val_accuracy: 0.8657\n",
      "Epoch 93/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.1766 - accuracy: 0.9275 - val_loss: 0.4238 - val_accuracy: 0.8663\n",
      "Epoch 94/100\n",
      "1240/1240 [==============================] - 321s 259ms/step - loss: 0.1792 - accuracy: 0.9271 - val_loss: 0.3746 - val_accuracy: 0.8689\n",
      "Epoch 95/100\n",
      "1240/1240 [==============================] - 322s 260ms/step - loss: 0.1744 - accuracy: 0.9277 - val_loss: 0.3565 - val_accuracy: 0.8711\n",
      "Epoch 96/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1722 - accuracy: 0.9301 - val_loss: 0.3777 - val_accuracy: 0.8727\n",
      "Epoch 97/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1724 - accuracy: 0.9307 - val_loss: 0.3594 - val_accuracy: 0.8667\n",
      "Epoch 98/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1681 - accuracy: 0.9306 - val_loss: 0.3813 - val_accuracy: 0.8603\n",
      "Epoch 99/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1697 - accuracy: 0.9304 - val_loss: 0.3507 - val_accuracy: 0.8685\n",
      "Epoch 100/100\n",
      "1240/1240 [==============================] - 320s 258ms/step - loss: 0.1665 - accuracy: 0.9332 - val_loss: 0.3808 - val_accuracy: 0.8746\n",
      "Epoch 1/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.4184 - accuracy: 0.8249 - val_loss: 0.6186 - val_accuracy: 0.7152\n",
      "Epoch 2/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.3698 - accuracy: 0.8421 - val_loss: 0.6125 - val_accuracy: 0.7152\n",
      "Epoch 3/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.3509 - accuracy: 0.8493 - val_loss: 0.6131 - val_accuracy: 0.7152\n",
      "Epoch 4/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.3412 - accuracy: 0.8550 - val_loss: 0.5925 - val_accuracy: 0.7152\n",
      "Epoch 5/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.3273 - accuracy: 0.8584 - val_loss: 0.4093 - val_accuracy: 0.8001\n",
      "Epoch 6/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.3181 - accuracy: 0.8650 - val_loss: 0.3769 - val_accuracy: 0.8413\n",
      "Epoch 7/100\n",
      "1240/1240 [==============================] - 285s 230ms/step - loss: 0.3070 - accuracy: 0.8684 - val_loss: 0.5086 - val_accuracy: 0.7904\n",
      "Epoch 8/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.3028 - accuracy: 0.8705 - val_loss: 0.4409 - val_accuracy: 0.7931\n",
      "Epoch 9/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.2952 - accuracy: 0.8737 - val_loss: 0.9252 - val_accuracy: 0.7592\n",
      "Epoch 10/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.2823 - accuracy: 0.8799 - val_loss: 0.9001 - val_accuracy: 0.7913\n",
      "Epoch 11/100\n",
      "1240/1240 [==============================] - 283s 229ms/step - loss: 0.2762 - accuracy: 0.8829 - val_loss: 0.9094 - val_accuracy: 0.7899\n",
      "Epoch 12/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.2674 - accuracy: 0.8859 - val_loss: 0.4641 - val_accuracy: 0.8441\n",
      "Epoch 13/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.2560 - accuracy: 0.8905 - val_loss: 0.3933 - val_accuracy: 0.8414\n",
      "Epoch 14/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.2495 - accuracy: 0.8962 - val_loss: 0.4164 - val_accuracy: 0.8168\n",
      "Epoch 15/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.2333 - accuracy: 0.9037 - val_loss: 0.5065 - val_accuracy: 0.8240\n",
      "Epoch 16/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.2251 - accuracy: 0.9057 - val_loss: 0.5226 - val_accuracy: 0.8315\n",
      "Epoch 17/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.2153 - accuracy: 0.9098 - val_loss: 0.4975 - val_accuracy: 0.8250\n",
      "Epoch 18/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.2061 - accuracy: 0.9141 - val_loss: 0.4447 - val_accuracy: 0.8442\n",
      "Epoch 19/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.1972 - accuracy: 0.9185 - val_loss: 0.7771 - val_accuracy: 0.7579\n",
      "Epoch 20/100\n",
      "1240/1240 [==============================] - 285s 230ms/step - loss: 0.1875 - accuracy: 0.9243 - val_loss: 0.5782 - val_accuracy: 0.7678\n",
      "Epoch 21/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.1732 - accuracy: 0.9301 - val_loss: 0.6807 - val_accuracy: 0.7843\n",
      "Epoch 22/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.1642 - accuracy: 0.9332 - val_loss: 1.0874 - val_accuracy: 0.6344\n",
      "Epoch 23/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.1586 - accuracy: 0.9364 - val_loss: 0.6034 - val_accuracy: 0.8298\n",
      "Epoch 24/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.1461 - accuracy: 0.9411 - val_loss: 0.6815 - val_accuracy: 0.8251\n",
      "Epoch 25/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.1363 - accuracy: 0.9468 - val_loss: 0.6517 - val_accuracy: 0.7979\n",
      "Epoch 26/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.1337 - accuracy: 0.9479 - val_loss: 0.7783 - val_accuracy: 0.8177\n",
      "Epoch 27/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.1274 - accuracy: 0.9486 - val_loss: 0.8670 - val_accuracy: 0.8179\n",
      "Epoch 28/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.1174 - accuracy: 0.9545 - val_loss: 0.6699 - val_accuracy: 0.8000\n",
      "Epoch 29/100\n",
      "1240/1240 [==============================] - 283s 229ms/step - loss: 0.1083 - accuracy: 0.9571 - val_loss: 0.6150 - val_accuracy: 0.8189\n",
      "Epoch 30/100\n",
      "1240/1240 [==============================] - 286s 231ms/step - loss: 0.1037 - accuracy: 0.9594 - val_loss: 0.6500 - val_accuracy: 0.8415\n",
      "Epoch 31/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0975 - accuracy: 0.9628 - val_loss: 0.7263 - val_accuracy: 0.7942\n",
      "Epoch 32/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0911 - accuracy: 0.9649 - val_loss: 0.6643 - val_accuracy: 0.8281\n",
      "Epoch 33/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0845 - accuracy: 0.9682 - val_loss: 0.6590 - val_accuracy: 0.7827\n",
      "Epoch 34/100\n",
      "1240/1240 [==============================] - 287s 231ms/step - loss: 0.0774 - accuracy: 0.9708 - val_loss: 0.7197 - val_accuracy: 0.7986\n",
      "Epoch 35/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0779 - accuracy: 0.9713 - val_loss: 0.8682 - val_accuracy: 0.7388\n",
      "Epoch 36/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0674 - accuracy: 0.9750 - val_loss: 0.7257 - val_accuracy: 0.8232\n",
      "Epoch 37/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0669 - accuracy: 0.9750 - val_loss: 0.6858 - val_accuracy: 0.8313\n",
      "Epoch 38/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0601 - accuracy: 0.9780 - val_loss: 0.8793 - val_accuracy: 0.7661\n",
      "Epoch 39/100\n",
      "1240/1240 [==============================] - 283s 229ms/step - loss: 0.0556 - accuracy: 0.9801 - val_loss: 1.0398 - val_accuracy: 0.7767\n",
      "Epoch 40/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0535 - accuracy: 0.9802 - val_loss: 0.9101 - val_accuracy: 0.7766\n",
      "Epoch 41/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0486 - accuracy: 0.9826 - val_loss: 0.7842 - val_accuracy: 0.8205\n",
      "Epoch 42/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0455 - accuracy: 0.9830 - val_loss: 0.9310 - val_accuracy: 0.8317\n",
      "Epoch 43/100\n",
      "1240/1240 [==============================] - 282s 227ms/step - loss: 0.0417 - accuracy: 0.9846 - val_loss: 1.8268 - val_accuracy: 0.6616\n",
      "Epoch 44/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0433 - accuracy: 0.9846 - val_loss: 0.7946 - val_accuracy: 0.8361\n",
      "Epoch 45/100\n",
      "1240/1240 [==============================] - 283s 229ms/step - loss: 0.0410 - accuracy: 0.9849 - val_loss: 0.8345 - val_accuracy: 0.7914\n",
      "Epoch 46/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0476 - accuracy: 0.9831 - val_loss: 0.8884 - val_accuracy: 0.7876\n",
      "Epoch 47/100\n",
      "1240/1240 [==============================] - 290s 234ms/step - loss: 0.0401 - accuracy: 0.9853 - val_loss: 0.8268 - val_accuracy: 0.8292\n",
      "Epoch 48/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0295 - accuracy: 0.9896 - val_loss: 0.9986 - val_accuracy: 0.7864\n",
      "Epoch 49/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0303 - accuracy: 0.9894 - val_loss: 0.8560 - val_accuracy: 0.8305\n",
      "Epoch 50/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 1.0076 - val_accuracy: 0.8341\n",
      "Epoch 51/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0289 - accuracy: 0.9897 - val_loss: 1.0413 - val_accuracy: 0.7749\n",
      "Epoch 52/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0274 - accuracy: 0.9899 - val_loss: 1.1444 - val_accuracy: 0.8285\n",
      "Epoch 53/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 0.8617 - val_accuracy: 0.8274\n",
      "Epoch 54/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0224 - accuracy: 0.9921 - val_loss: 0.8966 - val_accuracy: 0.8276\n",
      "Epoch 55/100\n",
      "1240/1240 [==============================] - 286s 230ms/step - loss: 0.0251 - accuracy: 0.9912 - val_loss: 0.8682 - val_accuracy: 0.8191\n",
      "Epoch 56/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0214 - accuracy: 0.9927 - val_loss: 0.8614 - val_accuracy: 0.8264\n",
      "Epoch 57/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0210 - accuracy: 0.9926 - val_loss: 1.0752 - val_accuracy: 0.8242\n",
      "Epoch 58/100\n",
      "1240/1240 [==============================] - 285s 230ms/step - loss: 0.0223 - accuracy: 0.9925 - val_loss: 0.9752 - val_accuracy: 0.8389\n",
      "Epoch 59/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0192 - accuracy: 0.9934 - val_loss: 0.9356 - val_accuracy: 0.8141\n",
      "Epoch 60/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0184 - accuracy: 0.9939 - val_loss: 1.0069 - val_accuracy: 0.8288\n",
      "Epoch 61/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0169 - accuracy: 0.9941 - val_loss: 1.2833 - val_accuracy: 0.8071\n",
      "Epoch 62/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0160 - accuracy: 0.9948 - val_loss: 1.1652 - val_accuracy: 0.8351\n",
      "Epoch 63/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 1.0233 - val_accuracy: 0.7922\n",
      "Epoch 64/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 0.9104 - val_accuracy: 0.8335\n",
      "Epoch 65/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0161 - accuracy: 0.9945 - val_loss: 0.9317 - val_accuracy: 0.8322\n",
      "Epoch 66/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0130 - accuracy: 0.9955 - val_loss: 0.9709 - val_accuracy: 0.8348\n",
      "Epoch 67/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0114 - accuracy: 0.9959 - val_loss: 1.0015 - val_accuracy: 0.8334\n",
      "Epoch 68/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0106 - accuracy: 0.9962 - val_loss: 1.0905 - val_accuracy: 0.8264\n",
      "Epoch 69/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 0.9345 - val_accuracy: 0.8410\n",
      "Epoch 70/100\n",
      "1240/1240 [==============================] - 285s 230ms/step - loss: 0.0160 - accuracy: 0.9946 - val_loss: 0.9122 - val_accuracy: 0.8337\n",
      "Epoch 71/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0115 - accuracy: 0.9961 - val_loss: 1.0425 - val_accuracy: 0.8290\n",
      "Epoch 72/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0123 - accuracy: 0.9958 - val_loss: 1.1095 - val_accuracy: 0.8234\n",
      "Epoch 73/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0104 - accuracy: 0.9962 - val_loss: 0.9892 - val_accuracy: 0.8210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/100\n",
      "1240/1240 [==============================] - 281s 227ms/step - loss: 0.0103 - accuracy: 0.9967 - val_loss: 0.9624 - val_accuracy: 0.8378\n",
      "Epoch 75/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0110 - accuracy: 0.9962 - val_loss: 0.9725 - val_accuracy: 0.8366\n",
      "Epoch 76/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.0948 - val_accuracy: 0.8000\n",
      "Epoch 77/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0094 - accuracy: 0.9968 - val_loss: 1.0259 - val_accuracy: 0.8417\n",
      "Epoch 78/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0104 - accuracy: 0.9963 - val_loss: 0.9650 - val_accuracy: 0.8330\n",
      "Epoch 79/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0082 - accuracy: 0.9974 - val_loss: 1.0221 - val_accuracy: 0.8357\n",
      "Epoch 80/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0077 - accuracy: 0.9973 - val_loss: 1.0017 - val_accuracy: 0.8379\n",
      "Epoch 81/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0071 - accuracy: 0.9977 - val_loss: 1.0103 - val_accuracy: 0.8421\n",
      "Epoch 82/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0101 - accuracy: 0.9967 - val_loss: 1.0078 - val_accuracy: 0.8353\n",
      "Epoch 83/100\n",
      "1240/1240 [==============================] - 283s 229ms/step - loss: 0.0072 - accuracy: 0.9975 - val_loss: 1.0901 - val_accuracy: 0.8420\n",
      "Epoch 84/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0090 - accuracy: 0.9968 - val_loss: 1.0626 - val_accuracy: 0.8234\n",
      "Epoch 85/100\n",
      "1240/1240 [==============================] - 284s 229ms/step - loss: 0.0064 - accuracy: 0.9978 - val_loss: 0.9876 - val_accuracy: 0.8373\n",
      "Epoch 86/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0066 - accuracy: 0.9976 - val_loss: 1.0577 - val_accuracy: 0.8358\n",
      "Epoch 87/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0058 - accuracy: 0.9981 - val_loss: 1.0386 - val_accuracy: 0.8444\n",
      "Epoch 88/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 1.0959 - val_accuracy: 0.8240\n",
      "Epoch 89/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0080 - accuracy: 0.9971 - val_loss: 0.9864 - val_accuracy: 0.8354\n",
      "Epoch 90/100\n",
      "1240/1240 [==============================] - 282s 227ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 1.0700 - val_accuracy: 0.8366\n",
      "Epoch 91/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 1.0606 - val_accuracy: 0.8011\n",
      "Epoch 92/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0078 - accuracy: 0.9974 - val_loss: 1.0443 - val_accuracy: 0.8299\n",
      "Epoch 93/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0119 - accuracy: 0.9957 - val_loss: 1.0210 - val_accuracy: 0.8363\n",
      "Epoch 94/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0136 - accuracy: 0.9955 - val_loss: 1.2763 - val_accuracy: 0.7731\n",
      "Epoch 95/100\n",
      "1240/1240 [==============================] - 282s 227ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.1132 - val_accuracy: 0.8316\n",
      "Epoch 96/100\n",
      "1240/1240 [==============================] - 283s 228ms/step - loss: 0.0248 - accuracy: 0.9915 - val_loss: 1.1064 - val_accuracy: 0.7900\n",
      "Epoch 97/100\n",
      "1240/1240 [==============================] - 282s 228ms/step - loss: 0.0120 - accuracy: 0.9961 - val_loss: 0.9602 - val_accuracy: 0.8346\n",
      "Epoch 98/100\n",
      "1240/1240 [==============================] - 282s 227ms/step - loss: 0.0108 - accuracy: 0.9964 - val_loss: 0.9920 - val_accuracy: 0.8196\n",
      "Epoch 99/100\n",
      "1240/1240 [==============================] - 281s 227ms/step - loss: 0.0091 - accuracy: 0.9972 - val_loss: 0.9697 - val_accuracy: 0.8248\n",
      "Epoch 100/100\n",
      "1240/1240 [==============================] - 282s 227ms/step - loss: 0.0092 - accuracy: 0.9966 - val_loss: 1.0867 - val_accuracy: 0.8231\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shapey</th>\n",
       "      <th>shapex</th>\n",
       "      <th>shapez</th>\n",
       "      <th>train size</th>\n",
       "      <th>test size</th>\n",
       "      <th>num epochs</th>\n",
       "      <th>lenet runtime</th>\n",
       "      <th>lenet test err</th>\n",
       "      <th>lenet history</th>\n",
       "      <th>vgg runtime</th>\n",
       "      <th>vgg test err</th>\n",
       "      <th>vgg history</th>\n",
       "      <th>mobilenet runtime</th>\n",
       "      <th>mobilenet test err</th>\n",
       "      <th>mobilenet history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([[[[0.7764706  0.41960785 0.50196081]\\n [0.77...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>39652</td>\n",
       "      <td>9913</td>\n",
       "      <td>100</td>\n",
       "      <td>1562.525208</td>\n",
       "      <td>0.815898</td>\n",
       "      <td>{'loss': [0.4966748356819153, 0.41883975267410...</td>\n",
       "      <td>32099.639098</td>\n",
       "      <td>0.874609</td>\n",
       "      <td>{'loss': [0.7388870120048523, 0.47940790653228...</td>\n",
       "      <td>28348.39738</td>\n",
       "      <td>0.823061</td>\n",
       "      <td>{'loss': [0.4183903932571411, 0.36975672841072...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  shapey  shapex  shapez  \\\n",
       "0  ([[[[0.7764706  0.41960785 0.50196081]\\n [0.77...      50      50       3   \n",
       "\n",
       "   train size  test size  num epochs  lenet runtime  lenet test err  \\\n",
       "0       39652       9913         100    1562.525208        0.815898   \n",
       "\n",
       "                                       lenet history   vgg runtime  \\\n",
       "0  {'loss': [0.4966748356819153, 0.41883975267410...  32099.639098   \n",
       "\n",
       "   vgg test err                                        vgg history  \\\n",
       "0      0.874609  {'loss': [0.7388870120048523, 0.47940790653228...   \n",
       "\n",
       "   mobilenet runtime  mobilenet test err  \\\n",
       "0        28348.39738            0.823061   \n",
       "\n",
       "                                   mobilenet history  \n",
       "0  {'loss': [0.4183903932571411, 0.36975672841072...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = (bc_train_x,bc_train_y,bc_test_x,bc_test_y)\n",
    "df_bc = evaluate_dataset(data, num_epochs=100)\n",
    "df_bc.to_pickle('df_bcancer.pkl')\n",
    "df_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shapey</th>\n",
       "      <th>shapex</th>\n",
       "      <th>shapez</th>\n",
       "      <th>train size</th>\n",
       "      <th>test size</th>\n",
       "      <th>num epochs</th>\n",
       "      <th>lenet runtime</th>\n",
       "      <th>lenet test err</th>\n",
       "      <th>lenet history</th>\n",
       "      <th>vgg runtime</th>\n",
       "      <th>vgg test err</th>\n",
       "      <th>vgg history</th>\n",
       "      <th>mobilenet runtime</th>\n",
       "      <th>mobilenet test err</th>\n",
       "      <th>mobilenet history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([[[[0.7764706  0.41960785 0.50196081]\\n [0.77...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>39652</td>\n",
       "      <td>9913</td>\n",
       "      <td>100</td>\n",
       "      <td>1562.525208</td>\n",
       "      <td>0.815898</td>\n",
       "      <td>{'loss': [0.4966748356819153, 0.41883975267410...</td>\n",
       "      <td>32099.639098</td>\n",
       "      <td>0.874609</td>\n",
       "      <td>{'loss': [0.7388870120048523, 0.47940790653228...</td>\n",
       "      <td>28348.39738</td>\n",
       "      <td>0.823061</td>\n",
       "      <td>{'loss': [0.4183903932571411, 0.36975672841072...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  shapey  shapex  shapez  \\\n",
       "0  ([[[[0.7764706  0.41960785 0.50196081]\\n [0.77...      50      50       3   \n",
       "\n",
       "   train size  test size  num epochs  lenet runtime  lenet test err  \\\n",
       "0       39652       9913         100    1562.525208        0.815898   \n",
       "\n",
       "                                       lenet history   vgg runtime  \\\n",
       "0  {'loss': [0.4966748356819153, 0.41883975267410...  32099.639098   \n",
       "\n",
       "   vgg test err                                        vgg history  \\\n",
       "0      0.874609  {'loss': [0.7388870120048523, 0.47940790653228...   \n",
       "\n",
       "   mobilenet runtime  mobilenet test err  \\\n",
       "0        28348.39738            0.823061   \n",
       "\n",
       "                                   mobilenet history  \n",
       "0  {'loss': [0.4183903932571411, 0.36975672841072...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load if needed\n",
    "df_fmnist = pd.read_pickle('db_fmnist.pkl')\n",
    "df_cifar = pd.read_pickle('df_cifar.pkl')\n",
    "df_bc = pd.read_pickle('df_bcancer.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>shapey</th>\n",
       "      <th>shapex</th>\n",
       "      <th>shapez</th>\n",
       "      <th>train size</th>\n",
       "      <th>test size</th>\n",
       "      <th>num epochs</th>\n",
       "      <th>lenet runtime</th>\n",
       "      <th>lenet test err</th>\n",
       "      <th>lenet history</th>\n",
       "      <th>vgg runtime</th>\n",
       "      <th>vgg test err</th>\n",
       "      <th>vgg history</th>\n",
       "      <th>mobilenet runtime</th>\n",
       "      <th>mobilenet test err</th>\n",
       "      <th>mobilenet history</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fmnist</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>60000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>874.162244</td>\n",
       "      <td>0.908100</td>\n",
       "      <td>{'loss': [0.6234489679336548, 0.38793143630027...</td>\n",
       "      <td>22434.556872</td>\n",
       "      <td>0.943900</td>\n",
       "      <td>{'loss': [0.5175429582595825, 0.33762103319168...</td>\n",
       "      <td>18973.480170</td>\n",
       "      <td>0.907400</td>\n",
       "      <td>{'loss': [0.6217073202133179, 0.38363438844680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cifar10</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>50000</td>\n",
       "      <td>10000</td>\n",
       "      <td>100</td>\n",
       "      <td>905.454609</td>\n",
       "      <td>0.586200</td>\n",
       "      <td>{'loss': [1.7826309204101562, 1.45772171020507...</td>\n",
       "      <td>19137.917245</td>\n",
       "      <td>0.834800</td>\n",
       "      <td>{'loss': [1.8757611513137817, 1.21302139759063...</td>\n",
       "      <td>15757.714642</td>\n",
       "      <td>0.653400</td>\n",
       "      <td>{'loss': [2.3537964820861816, 1.81646561622619...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>([[[[0.7764706  0.41960785 0.50196081]\\n [0.77...</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "      <td>39652</td>\n",
       "      <td>9913</td>\n",
       "      <td>100</td>\n",
       "      <td>1562.525208</td>\n",
       "      <td>0.815898</td>\n",
       "      <td>{'loss': [0.4966748356819153, 0.41883975267410...</td>\n",
       "      <td>32099.639098</td>\n",
       "      <td>0.874609</td>\n",
       "      <td>{'loss': [0.7388870120048523, 0.47940790653228...</td>\n",
       "      <td>28348.397380</td>\n",
       "      <td>0.823061</td>\n",
       "      <td>{'loss': [0.4183903932571411, 0.36975672841072...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                name  shapey  shapex  shapez  \\\n",
       "0                                             fmnist      32      32       1   \n",
       "0                                            cifar10      32      32       3   \n",
       "0  ([[[[0.7764706  0.41960785 0.50196081]\\n [0.77...      50      50       3   \n",
       "\n",
       "   train size  test size  num epochs  lenet runtime  lenet test err  \\\n",
       "0       60000      10000         100     874.162244        0.908100   \n",
       "0       50000      10000         100     905.454609        0.586200   \n",
       "0       39652       9913         100    1562.525208        0.815898   \n",
       "\n",
       "                                       lenet history   vgg runtime  \\\n",
       "0  {'loss': [0.6234489679336548, 0.38793143630027...  22434.556872   \n",
       "0  {'loss': [1.7826309204101562, 1.45772171020507...  19137.917245   \n",
       "0  {'loss': [0.4966748356819153, 0.41883975267410...  32099.639098   \n",
       "\n",
       "   vgg test err                                        vgg history  \\\n",
       "0      0.943900  {'loss': [0.5175429582595825, 0.33762103319168...   \n",
       "0      0.834800  {'loss': [1.8757611513137817, 1.21302139759063...   \n",
       "0      0.874609  {'loss': [0.7388870120048523, 0.47940790653228...   \n",
       "\n",
       "   mobilenet runtime  mobilenet test err  \\\n",
       "0       18973.480170            0.907400   \n",
       "0       15757.714642            0.653400   \n",
       "0       28348.397380            0.823061   \n",
       "\n",
       "                                   mobilenet history  \n",
       "0  {'loss': [0.6217073202133179, 0.38363438844680...  \n",
       "0  {'loss': [2.3537964820861816, 1.81646561622619...  \n",
       "0  {'loss': [0.4183903932571411, 0.36975672841072...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_fmnist, df_cifar, df_bc])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Runtime of Different Datasets using Different Models')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot accuracy\n",
    "data_err = df[['lenet test err', 'mobilenet test err', 'vgg test err']].to_numpy()\n",
    "data_time = df[['lenet runtime', 'mobilenet runtime', 'vgg runtime']].to_numpy() / 60\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(data_err.T,'-*')\n",
    "plt.legend(['fasion mnist', 'cifar10', 'breast cancer'])\n",
    "plt.xticks(np.arange(3), ['LeNet', 'MiniVGGNet', 'MobileNetV2'])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy of Different Datasets using Different Models')\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(data_time.T,'-*')\n",
    "plt.legend(['fasion mnist', 'cifar10', 'breast cancer'])\n",
    "plt.xticks(np.arange(3), ['LeNet', 'MiniVGGNet', 'MobileNetV2'])\n",
    "plt.ylabel('Time [min]')\n",
    "plt.title('Runtime of Different Datasets using Different Models')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
